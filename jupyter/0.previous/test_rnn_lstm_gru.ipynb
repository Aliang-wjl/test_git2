{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.w_ih = torch.randn(input_size, hidden_size)\n",
    "        self.w_hh = torch.randn(hidden_size, hidden_size)\n",
    "        self.b_ih = torch.randn(1, hidden_size)\n",
    "        self.b_hh = torch.randn(1, hidden_size)\n",
    "        \n",
    "    def forward(self, inputs, h_0):\n",
    "        L,N,d = inputs.shape # 分别对应序列长度、批量大小和特征维度\n",
    "        H = h_0[0]  # 因为h_0的形状为（1，N，h），我们需要使用（N,h）去计算\n",
    "        outputs = torch.zeros(L,N,H.shape[1])\n",
    "        for t in range(L):\n",
    "            X_t = inputs[t]\n",
    "            H = torch.tanh(X_t @ self.w_ih + self.b_ih + H @ self.w_hh + self.b_hh)\n",
    "            outputs[t] = H\n",
    "        h_n = outputs[-1].unsqueeze(0)  # h_n实际上就是h_L，但此时的形状为(N,h)\n",
    "        return outputs,h_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1d14e23c270>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.5428,  0.9207,  0.7060]],\n",
      "\n",
      "        [[-0.2245,  0.2461, -0.4578]],\n",
      "\n",
      "        [[ 0.5950, -0.3390, -0.4598]],\n",
      "\n",
      "        [[ 0.9281, -0.7660,  0.5954]]])\n",
      "tensor([[[ 0.9281, -0.7660,  0.5954]]])\n",
      "tensor([[[-0.5428,  0.9207,  0.7060]],\n",
      "\n",
      "        [[-0.2245,  0.2461, -0.4578]],\n",
      "\n",
      "        [[ 0.5950, -0.3390, -0.4598]],\n",
      "\n",
      "        [[ 0.9281, -0.7660,  0.5954]]], grad_fn=<StackBackward0>)\n",
      "tensor([[[ 0.9281, -0.7660,  0.5954]]], grad_fn=<StackBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-e9d6dd1aa5fd>:8: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matricesor `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at  C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:2985.)\n",
      "  params = [param.data.T for param in rnn.parameters()]\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "seq = torch.randn(4,6)  # L,d\n",
    "inputs = seq.unsqueeze(1)  # batch_first = False  L,N,d\n",
    "h_0 = torch.randn(1,1,3) # D为单向RNN还是双向RNN，D等于1为单向，等于2为双向，  参数：Rnn层数*D，batch_size，hidden_size\n",
    "\n",
    "# 保持RNN内部参数：权重和偏置一致\n",
    "rnn = nn.RNN(6,3)\n",
    "params = [param.data.T for param in rnn.parameters()]\n",
    "my_rnn = RNN(6,3)\n",
    "my_rnn.w_ih = params[0]\n",
    "my_rnn.w_hh = params[1]\n",
    "my_rnn.b_ih[0] = params[2]\n",
    "my_rnn.b_hh[0] = params[3]\n",
    "\n",
    "outputs, h_n = my_rnn(inputs, h_0)\n",
    "print(outputs)\n",
    "print(h_n)\n",
    "\n",
    "outputs2, h_n2 = rnn(inputs, h_0)\n",
    "print(outputs2)\n",
    "print(h_n2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myht:\n",
      "tensor([[[ 0.0427, -0.0507, -0.1051,  0.0558,  0.5496, -0.4055, -0.3267,\n",
      "          -0.2305,  0.0300,  0.4706,  0.5252,  0.5213, -0.5046,  0.1732,\n",
      "           0.2074,  0.4352, -0.6096, -0.2494, -0.2184, -0.4104],\n",
      "         [ 0.0566,  0.4964,  0.1012, -0.4300, -0.1775, -0.0015, -0.5925,\n",
      "          -0.5441, -0.0066,  0.7015,  0.0342,  0.4849, -0.0690, -0.1957,\n",
      "          -0.2227, -0.4780,  0.6217, -0.5629,  0.5687,  0.3895],\n",
      "         [ 0.5041, -0.1209, -0.7399, -0.3278, -0.1692,  0.1554, -0.6658,\n",
      "          -0.0643,  0.5279,  0.4411, -0.1411,  0.3250, -0.4472, -0.3599,\n",
      "          -0.6736, -0.3189,  0.5611, -0.0729, -0.7830, -0.3426]]],\n",
      "       grad_fn=<TanhBackward0>)\n",
      "official_hn:\n",
      "tensor([[[ 0.0427, -0.0507, -0.1051,  0.0558,  0.5496, -0.4055, -0.3267,\n",
      "          -0.2305,  0.0300,  0.4706,  0.5252,  0.5213, -0.5046,  0.1732,\n",
      "           0.2074,  0.4352, -0.6096, -0.2494, -0.2184, -0.4104],\n",
      "         [ 0.0566,  0.4964,  0.1012, -0.4300, -0.1775, -0.0015, -0.5925,\n",
      "          -0.5441, -0.0066,  0.7015,  0.0342,  0.4849, -0.0690, -0.1957,\n",
      "          -0.2227, -0.4780,  0.6217, -0.5629,  0.5687,  0.3895],\n",
      "         [ 0.5041, -0.1209, -0.7399, -0.3278, -0.1692,  0.1554, -0.6658,\n",
      "          -0.0643,  0.5279,  0.4411, -0.1411,  0.3250, -0.4472, -0.3599,\n",
      "          -0.6736, -0.3189,  0.5611, -0.0729, -0.7830, -0.3426]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "--------------------------------------------------------------------------------\n",
      "myoutput:\n",
      "[tensor([[[ 1.6469e-01,  5.0645e-01, -5.5276e-01, -2.5400e-01, -2.4497e-01,\n",
      "           1.8927e-04, -4.3651e-01, -1.0756e-01, -7.0292e-01,  4.9413e-01,\n",
      "           7.7113e-01, -3.0119e-01, -2.4274e-01, -7.3092e-01, -8.4316e-02,\n",
      "          -6.7815e-01,  3.5432e-01, -6.8374e-01, -5.6692e-01, -8.7327e-01],\n",
      "         [-6.2202e-01, -6.2305e-01, -3.7729e-01,  5.8951e-01, -3.3982e-02,\n",
      "          -8.4002e-02, -2.8299e-02, -2.6319e-01, -7.6486e-01,  4.6570e-01,\n",
      "           1.0297e-03,  4.6381e-01, -4.9253e-02,  7.7816e-01,  8.3079e-01,\n",
      "           6.9431e-02, -3.5572e-01,  2.6447e-01, -1.0088e-01,  7.8615e-01],\n",
      "         [-8.1799e-01, -5.8482e-01,  2.0801e-01,  8.5551e-01, -6.8720e-01,\n",
      "          -1.1093e-01, -6.9952e-01,  3.6781e-02,  2.3353e-01,  5.9451e-02,\n",
      "           3.1847e-01,  4.9697e-01, -3.2989e-01, -3.4403e-01, -2.0149e-01,\n",
      "           1.0579e-01, -7.3739e-01, -8.3073e-01,  6.6158e-01, -5.9792e-01]]],\n",
      "       grad_fn=<TanhBackward0>), tensor([[[-0.0087,  0.4215,  0.1573, -0.6976,  0.4052, -0.5180,  0.1789,\n",
      "          -0.6773, -0.0658,  0.6792,  0.7008,  0.4719, -0.0011,  0.1476,\n",
      "           0.1004, -0.0471, -0.5096, -0.5624,  0.2989,  0.2907],\n",
      "         [-0.4976,  0.2753, -0.8746, -0.3116,  0.0578,  0.2657, -0.3287,\n",
      "           0.4849,  0.2729, -0.0055, -0.2329,  0.6352,  0.4301,  0.5049,\n",
      "          -0.3942, -0.2962,  0.0498, -0.7017,  0.1457,  0.0013],\n",
      "         [ 0.3368,  0.1232, -0.2798, -0.2517, -0.3748, -0.1213, -0.7821,\n",
      "          -0.2416,  0.7923, -0.1586, -0.4121,  0.5178, -0.6629,  0.6693,\n",
      "          -0.0391,  0.0122,  0.5248, -0.1780,  0.4721, -0.0996]]],\n",
      "       grad_fn=<TanhBackward0>), tensor([[[-0.2353,  0.2634,  0.0241,  0.4810,  0.3774, -0.4986, -0.6996,\n",
      "          -0.3370, -0.0457,  0.6656,  0.3307,  0.3726, -0.1659,  0.2940,\n",
      "           0.4148,  0.4392, -0.6699,  0.2027,  0.1013, -0.1931],\n",
      "         [ 0.4446, -0.0105, -0.3997, -0.4022,  0.5954,  0.3000, -0.7371,\n",
      "           0.0236, -0.4562,  0.8620, -0.1078,  0.4466, -0.5158, -0.5384,\n",
      "          -0.2731, -0.2605,  0.4217, -0.4684, -0.3182, -0.5288],\n",
      "         [ 0.1012, -0.1759,  0.1606,  0.6676, -0.0474,  0.5755, -0.4026,\n",
      "          -0.5385, -0.1327, -0.4834, -0.4197,  0.0758, -0.2281, -0.2960,\n",
      "          -0.6475, -0.3284,  0.7273,  0.3023, -0.2300, -0.4781]]],\n",
      "       grad_fn=<TanhBackward0>), tensor([[[-0.3961, -0.0045, -0.3202, -0.4278,  0.5850, -0.2628, -0.4734,\n",
      "           0.4988,  0.0456,  0.3741, -0.2297,  0.6842,  0.1212,  0.5026,\n",
      "           0.0949,  0.1188, -0.2996, -0.4968,  0.5472,  0.1602],\n",
      "         [ 0.8329,  0.3288, -0.4175,  0.1187, -0.2601, -0.5042, -0.3561,\n",
      "          -0.5839, -0.0730,  0.6561,  0.4098,  0.1340, -0.3283, -0.5523,\n",
      "           0.4841, -0.5008,  0.0343, -0.3916, -0.5218, -0.7327],\n",
      "         [-0.1332, -0.5373,  0.2860, -0.3494, -0.7566,  0.0923, -0.0976,\n",
      "           0.0105, -0.2509, -0.1830, -0.1428,  0.2780,  0.4539, -0.2241,\n",
      "           0.3315, -0.5178,  0.4519, -0.9225,  0.6297, -0.1347]]],\n",
      "       grad_fn=<TanhBackward0>), tensor([[[ 0.0427, -0.0507, -0.1051,  0.0558,  0.5496, -0.4055, -0.3267,\n",
      "          -0.2305,  0.0300,  0.4706,  0.5252,  0.5213, -0.5046,  0.1732,\n",
      "           0.2074,  0.4352, -0.6096, -0.2494, -0.2184, -0.4104],\n",
      "         [ 0.0566,  0.4964,  0.1012, -0.4300, -0.1775, -0.0015, -0.5925,\n",
      "          -0.5441, -0.0066,  0.7015,  0.0342,  0.4849, -0.0690, -0.1957,\n",
      "          -0.2227, -0.4780,  0.6217, -0.5629,  0.5687,  0.3895],\n",
      "         [ 0.5041, -0.1209, -0.7399, -0.3278, -0.1692,  0.1554, -0.6658,\n",
      "          -0.0643,  0.5279,  0.4411, -0.1411,  0.3250, -0.4472, -0.3599,\n",
      "          -0.6736, -0.3189,  0.5611, -0.0729, -0.7830, -0.3426]]],\n",
      "       grad_fn=<TanhBackward0>)]\n",
      "official_output:\n",
      "tensor([[[ 1.6469e-01,  5.0645e-01, -5.5276e-01, -2.5400e-01, -2.4497e-01,\n",
      "           1.8933e-04, -4.3651e-01, -1.0756e-01, -7.0292e-01,  4.9413e-01,\n",
      "           7.7113e-01, -3.0119e-01, -2.4274e-01, -7.3092e-01, -8.4316e-02,\n",
      "          -6.7815e-01,  3.5432e-01, -6.8374e-01, -5.6692e-01, -8.7327e-01],\n",
      "         [-6.2202e-01, -6.2305e-01, -3.7729e-01,  5.8951e-01, -3.3982e-02,\n",
      "          -8.4002e-02, -2.8299e-02, -2.6319e-01, -7.6486e-01,  4.6570e-01,\n",
      "           1.0296e-03,  4.6381e-01, -4.9253e-02,  7.7816e-01,  8.3079e-01,\n",
      "           6.9431e-02, -3.5572e-01,  2.6447e-01, -1.0088e-01,  7.8615e-01],\n",
      "         [-8.1799e-01, -5.8482e-01,  2.0801e-01,  8.5551e-01, -6.8720e-01,\n",
      "          -1.1093e-01, -6.9952e-01,  3.6781e-02,  2.3353e-01,  5.9451e-02,\n",
      "           3.1847e-01,  4.9697e-01, -3.2989e-01, -3.4403e-01, -2.0149e-01,\n",
      "           1.0579e-01, -7.3739e-01, -8.3073e-01,  6.6158e-01, -5.9792e-01]],\n",
      "\n",
      "        [[-8.6846e-03,  4.2148e-01,  1.5728e-01, -6.9758e-01,  4.0519e-01,\n",
      "          -5.1801e-01,  1.7893e-01, -6.7733e-01, -6.5834e-02,  6.7920e-01,\n",
      "           7.0078e-01,  4.7188e-01, -1.1146e-03,  1.4755e-01,  1.0037e-01,\n",
      "          -4.7106e-02, -5.0960e-01, -5.6240e-01,  2.9892e-01,  2.9066e-01],\n",
      "         [-4.9760e-01,  2.7534e-01, -8.7456e-01, -3.1164e-01,  5.7842e-02,\n",
      "           2.6575e-01, -3.2871e-01,  4.8488e-01,  2.7290e-01, -5.4914e-03,\n",
      "          -2.3294e-01,  6.3520e-01,  4.3007e-01,  5.0488e-01, -3.9423e-01,\n",
      "          -2.9625e-01,  4.9752e-02, -7.0172e-01,  1.4574e-01,  1.2762e-03],\n",
      "         [ 3.3679e-01,  1.2315e-01, -2.7980e-01, -2.5169e-01, -3.7479e-01,\n",
      "          -1.2133e-01, -7.8208e-01, -2.4158e-01,  7.9232e-01, -1.5862e-01,\n",
      "          -4.1208e-01,  5.1785e-01, -6.6294e-01,  6.6926e-01, -3.9115e-02,\n",
      "           1.2172e-02,  5.2478e-01, -1.7802e-01,  4.7213e-01, -9.9582e-02]],\n",
      "\n",
      "        [[-2.3532e-01,  2.6341e-01,  2.4058e-02,  4.8100e-01,  3.7736e-01,\n",
      "          -4.9860e-01, -6.9958e-01, -3.3697e-01, -4.5708e-02,  6.6565e-01,\n",
      "           3.3074e-01,  3.7256e-01, -1.6585e-01,  2.9396e-01,  4.1484e-01,\n",
      "           4.3916e-01, -6.6987e-01,  2.0270e-01,  1.0126e-01, -1.9311e-01],\n",
      "         [ 4.4457e-01, -1.0475e-02, -3.9966e-01, -4.0220e-01,  5.9542e-01,\n",
      "           2.9996e-01, -7.3707e-01,  2.3621e-02, -4.5624e-01,  8.6204e-01,\n",
      "          -1.0777e-01,  4.4657e-01, -5.1582e-01, -5.3840e-01, -2.7314e-01,\n",
      "          -2.6049e-01,  4.2166e-01, -4.6844e-01, -3.1821e-01, -5.2883e-01],\n",
      "         [ 1.0116e-01, -1.7587e-01,  1.6059e-01,  6.6762e-01, -4.7394e-02,\n",
      "           5.7550e-01, -4.0264e-01, -5.3847e-01, -1.3274e-01, -4.8338e-01,\n",
      "          -4.1969e-01,  7.5761e-02, -2.2806e-01, -2.9602e-01, -6.4747e-01,\n",
      "          -3.2841e-01,  7.2729e-01,  3.0234e-01, -2.3003e-01, -4.7815e-01]],\n",
      "\n",
      "        [[-3.9610e-01, -4.5472e-03, -3.2015e-01, -4.2778e-01,  5.8495e-01,\n",
      "          -2.6276e-01, -4.7338e-01,  4.9875e-01,  4.5634e-02,  3.7411e-01,\n",
      "          -2.2972e-01,  6.8420e-01,  1.2119e-01,  5.0261e-01,  9.4859e-02,\n",
      "           1.1883e-01, -2.9960e-01, -4.9684e-01,  5.4719e-01,  1.6020e-01],\n",
      "         [ 8.3294e-01,  3.2875e-01, -4.1752e-01,  1.1866e-01, -2.6013e-01,\n",
      "          -5.0422e-01, -3.5606e-01, -5.8389e-01, -7.2985e-02,  6.5609e-01,\n",
      "           4.0981e-01,  1.3403e-01, -3.2830e-01, -5.5229e-01,  4.8406e-01,\n",
      "          -5.0079e-01,  3.4323e-02, -3.9156e-01, -5.2177e-01, -7.3275e-01],\n",
      "         [-1.3325e-01, -5.3733e-01,  2.8596e-01, -3.4938e-01, -7.5663e-01,\n",
      "           9.2263e-02, -9.7572e-02,  1.0494e-02, -2.5093e-01, -1.8298e-01,\n",
      "          -1.4281e-01,  2.7797e-01,  4.5392e-01, -2.2405e-01,  3.3154e-01,\n",
      "          -5.1775e-01,  4.5188e-01, -9.2245e-01,  6.2967e-01, -1.3473e-01]],\n",
      "\n",
      "        [[ 4.2669e-02, -5.0708e-02, -1.0508e-01,  5.5835e-02,  5.4955e-01,\n",
      "          -4.0546e-01, -3.2671e-01, -2.3047e-01,  3.0014e-02,  4.7060e-01,\n",
      "           5.2521e-01,  5.2134e-01, -5.0463e-01,  1.7319e-01,  2.0740e-01,\n",
      "           4.3522e-01, -6.0958e-01, -2.4944e-01, -2.1836e-01, -4.1043e-01],\n",
      "         [ 5.6576e-02,  4.9638e-01,  1.0124e-01, -4.3004e-01, -1.7752e-01,\n",
      "          -1.5273e-03, -5.9250e-01, -5.4406e-01, -6.5915e-03,  7.0151e-01,\n",
      "           3.4217e-02,  4.8490e-01, -6.9029e-02, -1.9570e-01, -2.2266e-01,\n",
      "          -4.7802e-01,  6.2174e-01, -5.6290e-01,  5.6871e-01,  3.8948e-01],\n",
      "         [ 5.0408e-01, -1.2088e-01, -7.3990e-01, -3.2778e-01, -1.6916e-01,\n",
      "           1.5544e-01, -6.6581e-01, -6.4306e-02,  5.2786e-01,  4.4112e-01,\n",
      "          -1.4106e-01,  3.2500e-01, -4.4723e-01, -3.5991e-01, -6.7359e-01,\n",
      "          -3.1892e-01,  5.6115e-01, -7.2881e-02, -7.8299e-01, -3.4262e-01]]],\n",
      "       grad_fn=<StackBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 网络参数\n",
    "input_size = 10\n",
    "hidden_size = 20\n",
    "num_layers = 1\n",
    "\n",
    "# 数据参数\n",
    "seq_len = 5\n",
    "batch_size = 3\n",
    "data_dim = input_size\n",
    "\n",
    "# 输入数据\n",
    "data = torch.randn(seq_len, batch_size, data_dim)\n",
    "\n",
    "# 官方pytorch中的RNN \n",
    "# nn.Conv1d(in_channels,64,kernel_size=7,stride=2,padding=3,bias=False)\n",
    "ornn = nn.RNN(input_size, hidden_size, num_layers)\n",
    "\n",
    "# init hidden state\n",
    "h0 = torch.randn(num_layers,batch_size,hidden_size)\n",
    "\n",
    "# rnn implemented by myself\n",
    "class MyRNN():\n",
    "    def __init__(self):\n",
    "        # 保证权重和偏差的参数和原始的rnn相同 并将最终的结果和原始rnn进行比较\n",
    "        self.w_ih = torch.nn.Parameter(ornn.weight_ih_l0.T)  # 乘以当前x\n",
    "        self.b_ih = torch.nn.Parameter(ornn.bias_ih_l0)  # 附带偏差\n",
    "        self.w_hh = torch.nn.Parameter(ornn.weight_hh_l0.T)  # 乘以上一时刻h\n",
    "        self.b_hh = torch.nn.Parameter(ornn.bias_hh_l0)\n",
    "        self.ht = torch.nn.Parameter(h0)\n",
    "        self.myoutput = []\n",
    "        \n",
    "    def forward(self, x): # shape:(seq_len, batch_size, data_dim)\n",
    "        for i in range(seq_len): # 这一行是理解RNN的关键\n",
    "            igates = torch.matmul(x[i], self.w_ih) + self.b_ih\n",
    "            hgates = torch.matmul(self.ht, self.w_hh) + self.b_hh\n",
    "            self.ht = torch.tanh(igates + hgates) # 这一行是RNN的公式\n",
    "            self.myoutput.append(self.ht)\n",
    "        return self.ht, self.myoutput\n",
    "\n",
    "myrnn = MyRNN()\n",
    "myht, myoutput = myrnn.forward(data)\n",
    "official_output, official_hn = ornn(data,h0)\n",
    "\n",
    "print ('myht:')\n",
    "print (myht)\n",
    "print ('official_hn:')\n",
    "print (official_hn)\n",
    "\n",
    "print (\"--\" * 40)\n",
    "print ('myoutput:')\n",
    "print (myoutput)\n",
    "print ('official_output:')\n",
    "print (official_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myht:\n",
      "[tensor([[ 5.7555e-01,  6.3959e-02, -4.8237e-04,  3.6376e-01, -2.6510e-01,\n",
      "          4.7944e-02,  2.5967e-01, -3.6259e-01,  8.1449e-01, -7.0938e-01,\n",
      "          6.8870e-01, -8.3581e-01, -6.6371e-01,  5.6467e-01,  6.0072e-01,\n",
      "          1.5433e-01, -4.4449e-01, -3.4524e-02, -7.6776e-01,  5.6837e-02],\n",
      "        [-4.6934e-03, -2.8252e-01,  2.3753e-01, -8.6996e-01, -4.3868e-01,\n",
      "         -2.7403e-02,  5.4931e-01, -1.3780e-01,  1.2170e-02, -2.2654e-01,\n",
      "          7.5068e-01, -9.0088e-01,  1.9875e-01,  3.6503e-01, -9.1360e-01,\n",
      "         -4.6566e-01, -4.4158e-01, -2.4151e-01,  4.4735e-01, -6.7096e-02],\n",
      "        [ 1.3250e-01,  2.9181e-01,  6.0930e-01,  9.4492e-01, -1.2857e-01,\n",
      "         -6.6635e-01, -7.5297e-01, -8.0852e-01,  7.5963e-01,  5.8442e-01,\n",
      "          1.9924e-01,  1.7311e-01, -6.5252e-01,  8.7590e-01, -2.6455e-02,\n",
      "          4.3857e-01, -1.3647e-01, -7.3224e-01, -1.3205e-01,  3.8846e-01]],\n",
      "       grad_fn=<TanhBackward0>), tensor([[-0.4547, -0.5596,  0.3929, -0.0198,  0.4176,  0.0522,  0.1368,  0.1997,\n",
      "         -0.3800,  0.5646, -0.1287, -0.5379,  0.1102, -0.2605, -0.2345,  0.4119,\n",
      "         -0.2135, -0.1133, -0.2430,  0.5699],\n",
      "        [-0.3538, -0.2202,  0.5303, -0.2139,  0.0995, -0.0740, -0.3608,  0.2101,\n",
      "         -0.1457,  0.1126, -0.0243, -0.3223,  0.6898, -0.1396,  0.4855,  0.1080,\n",
      "         -0.0899, -0.4499, -0.1255,  0.3693],\n",
      "        [-0.0519,  0.0299, -0.0712, -0.1760,  0.3659,  0.1934, -0.2153, -0.0246,\n",
      "         -0.6112,  0.1670,  0.2269, -0.1633,  0.0711, -0.2427, -0.3142, -0.0048,\n",
      "         -0.6816,  0.3711, -0.3868, -0.0498]], grad_fn=<TanhBackward0>)]\n",
      "official_hn:\n",
      "tensor([[[ 5.7555e-01,  6.3959e-02, -4.8235e-04,  3.6376e-01, -2.6510e-01,\n",
      "           4.7944e-02,  2.5967e-01, -3.6259e-01,  8.1449e-01, -7.0938e-01,\n",
      "           6.8870e-01, -8.3581e-01, -6.6371e-01,  5.6467e-01,  6.0072e-01,\n",
      "           1.5433e-01, -4.4449e-01, -3.4524e-02, -7.6776e-01,  5.6837e-02],\n",
      "         [-4.6934e-03, -2.8252e-01,  2.3753e-01, -8.6996e-01, -4.3868e-01,\n",
      "          -2.7403e-02,  5.4931e-01, -1.3780e-01,  1.2169e-02, -2.2654e-01,\n",
      "           7.5068e-01, -9.0088e-01,  1.9875e-01,  3.6503e-01, -9.1360e-01,\n",
      "          -4.6566e-01, -4.4158e-01, -2.4151e-01,  4.4735e-01, -6.7096e-02],\n",
      "         [ 1.3250e-01,  2.9181e-01,  6.0930e-01,  9.4492e-01, -1.2857e-01,\n",
      "          -6.6635e-01, -7.5297e-01, -8.0852e-01,  7.5963e-01,  5.8442e-01,\n",
      "           1.9924e-01,  1.7311e-01, -6.5252e-01,  8.7590e-01, -2.6455e-02,\n",
      "           4.3857e-01, -1.3647e-01, -7.3224e-01, -1.3205e-01,  3.8846e-01]],\n",
      "\n",
      "        [[-4.5468e-01, -5.5961e-01,  3.9290e-01, -1.9797e-02,  4.1756e-01,\n",
      "           5.2192e-02,  1.3681e-01,  1.9972e-01, -3.7997e-01,  5.6464e-01,\n",
      "          -1.2874e-01, -5.3788e-01,  1.1019e-01, -2.6052e-01, -2.3452e-01,\n",
      "           4.1189e-01, -2.1350e-01, -1.1331e-01, -2.4296e-01,  5.6992e-01],\n",
      "         [-3.5377e-01, -2.2018e-01,  5.3034e-01, -2.1391e-01,  9.9504e-02,\n",
      "          -7.4026e-02, -3.6084e-01,  2.1007e-01, -1.4572e-01,  1.1265e-01,\n",
      "          -2.4294e-02, -3.2229e-01,  6.8985e-01, -1.3961e-01,  4.8548e-01,\n",
      "           1.0796e-01, -8.9909e-02, -4.4988e-01, -1.2552e-01,  3.6927e-01],\n",
      "         [-5.1861e-02,  2.9902e-02, -7.1185e-02, -1.7596e-01,  3.6591e-01,\n",
      "           1.9343e-01, -2.1535e-01, -2.4604e-02, -6.1121e-01,  1.6700e-01,\n",
      "           2.2687e-01, -1.6334e-01,  7.1115e-02, -2.4274e-01, -3.1419e-01,\n",
      "          -4.7641e-03, -6.8157e-01,  3.7111e-01, -3.8677e-01, -4.9840e-02]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "--------------------------------------------------------------------------------\n",
      "myoutput:\n",
      "[tensor([[ 0.0872,  0.3684, -0.2750, -0.7250,  0.1299, -0.2623,  0.4830,  0.4469,\n",
      "         -0.7843, -0.0315,  0.7142, -0.1470,  0.1728,  0.4476, -0.9311, -0.8421,\n",
      "         -0.6883,  0.3428,  0.3233,  0.1016],\n",
      "        [-0.7850, -0.5535,  0.5543, -0.8709, -0.2431,  0.3295, -0.2630,  0.7164,\n",
      "         -0.1227,  0.3501,  0.6351,  0.1858,  0.1383, -0.2827, -0.1069, -0.5907,\n",
      "          0.3558,  0.1674, -0.0611, -0.0761],\n",
      "        [ 0.2499,  0.0821,  0.0515,  0.2336,  0.5087, -0.5235,  0.0438, -0.1657,\n",
      "         -0.1509, -0.5594,  0.0356, -0.2237, -0.2723, -0.1785,  0.4831, -0.1224,\n",
      "         -0.5301, -0.0465, -0.1315, -0.2628]], grad_fn=<TanhBackward0>), tensor([[ 0.0245, -0.4612,  0.2290,  0.2192,  0.3769, -0.0074, -0.1931, -0.0010,\n",
      "         -0.2083,  0.1142,  0.1856, -0.6943,  0.0529,  0.3909, -0.5522,  0.2627,\n",
      "          0.2170,  0.7974, -0.3810,  0.1605],\n",
      "        [-0.2774, -0.0530,  0.2243, -0.4322, -0.4437,  0.0467, -0.4229, -0.2720,\n",
      "          0.2030, -0.0500,  0.8124, -0.2708,  0.4814,  0.5350, -0.4951, -0.2109,\n",
      "         -0.6126, -0.0886,  0.1951, -0.3549],\n",
      "        [-0.7067, -0.8513,  0.4327,  0.6352,  0.6498,  0.4996, -0.0923, -0.3991,\n",
      "         -0.2886,  0.2373,  0.4156, -0.1195, -0.5332, -0.3906,  0.0720,  0.1342,\n",
      "         -0.1780,  0.0191, -0.3102,  0.1071]], grad_fn=<TanhBackward0>), tensor([[-0.7235, -0.5504,  0.2090,  0.0351, -0.2398, -0.1636,  0.2819, -0.2427,\n",
      "         -0.3981,  0.3372,  0.3241, -0.1222,  0.1654, -0.2165,  0.2550, -0.0287,\n",
      "         -0.3783, -0.4224, -0.6462,  0.4746],\n",
      "        [-0.6836, -0.5916,  0.4398, -0.0899, -0.0469, -0.0051,  0.0072,  0.1513,\n",
      "         -0.1175,  0.6282, -0.3829, -0.5863,  0.1795, -0.4231, -0.0059,  0.5376,\n",
      "         -0.1901, -0.4305, -0.2537,  0.4938],\n",
      "        [-0.5013, -0.3005, -0.0185, -0.4513, -0.3499,  0.1165, -0.6057,  0.7068,\n",
      "          0.2050, -0.6388,  0.1701, -0.3532,  0.3319, -0.3300,  0.2901, -0.2967,\n",
      "         -0.5105,  0.2815, -0.1997, -0.3337]], grad_fn=<TanhBackward0>), tensor([[-0.1707,  0.2202,  0.2718, -0.3320, -0.0394, -0.1782, -0.5120,  0.1592,\n",
      "         -0.3852, -0.1040, -0.2200, -0.3885,  0.7176, -0.1728,  0.0040,  0.0583,\n",
      "         -0.6811,  0.0715, -0.0734, -0.1524],\n",
      "        [-0.6631, -0.5725,  0.1637, -0.1257, -0.2135,  0.1563,  0.3015,  0.3292,\n",
      "          0.1332, -0.1186,  0.0068, -0.5860,  0.0093, -0.3685,  0.3943,  0.2079,\n",
      "         -0.3911, -0.5431, -0.2084,  0.4240],\n",
      "        [ 0.3113, -0.1314,  0.2967, -0.2694,  0.2241, -0.1966, -0.2360, -0.1991,\n",
      "          0.2343, -0.2418,  0.0174, -0.6322,  0.2383,  0.0167, -0.0537, -0.2263,\n",
      "         -0.6970,  0.1103, -0.0630,  0.4280]], grad_fn=<TanhBackward0>), tensor([[-0.4547, -0.5596,  0.3929, -0.0198,  0.4176,  0.0522,  0.1368,  0.1997,\n",
      "         -0.3800,  0.5646, -0.1287, -0.5379,  0.1102, -0.2605, -0.2345,  0.4119,\n",
      "         -0.2135, -0.1133, -0.2430,  0.5699],\n",
      "        [-0.3538, -0.2202,  0.5303, -0.2139,  0.0995, -0.0740, -0.3608,  0.2101,\n",
      "         -0.1457,  0.1126, -0.0243, -0.3223,  0.6898, -0.1396,  0.4855,  0.1080,\n",
      "         -0.0899, -0.4499, -0.1255,  0.3693],\n",
      "        [-0.0519,  0.0299, -0.0712, -0.1760,  0.3659,  0.1934, -0.2153, -0.0246,\n",
      "         -0.6112,  0.1670,  0.2269, -0.1633,  0.0711, -0.2427, -0.3142, -0.0048,\n",
      "         -0.6816,  0.3711, -0.3868, -0.0498]], grad_fn=<TanhBackward0>)]\n",
      "official_output:\n",
      "tensor([[[ 0.0872,  0.3684, -0.2750, -0.7250,  0.1299, -0.2623,  0.4830,\n",
      "           0.4469, -0.7843, -0.0315,  0.7142, -0.1470,  0.1728,  0.4476,\n",
      "          -0.9311, -0.8421, -0.6883,  0.3428,  0.3233,  0.1016],\n",
      "         [-0.7850, -0.5535,  0.5543, -0.8709, -0.2431,  0.3295, -0.2630,\n",
      "           0.7164, -0.1227,  0.3501,  0.6351,  0.1858,  0.1383, -0.2827,\n",
      "          -0.1069, -0.5907,  0.3558,  0.1674, -0.0611, -0.0761],\n",
      "         [ 0.2499,  0.0821,  0.0515,  0.2336,  0.5087, -0.5235,  0.0438,\n",
      "          -0.1657, -0.1509, -0.5594,  0.0356, -0.2237, -0.2723, -0.1785,\n",
      "           0.4831, -0.1224, -0.5301, -0.0465, -0.1315, -0.2628]],\n",
      "\n",
      "        [[ 0.0245, -0.4612,  0.2290,  0.2192,  0.3769, -0.0074, -0.1931,\n",
      "          -0.0010, -0.2083,  0.1142,  0.1856, -0.6943,  0.0529,  0.3909,\n",
      "          -0.5522,  0.2627,  0.2170,  0.7974, -0.3810,  0.1605],\n",
      "         [-0.2774, -0.0530,  0.2243, -0.4322, -0.4437,  0.0467, -0.4229,\n",
      "          -0.2720,  0.2030, -0.0500,  0.8124, -0.2708,  0.4814,  0.5350,\n",
      "          -0.4951, -0.2109, -0.6126, -0.0886,  0.1951, -0.3549],\n",
      "         [-0.7067, -0.8513,  0.4327,  0.6352,  0.6498,  0.4996, -0.0923,\n",
      "          -0.3991, -0.2886,  0.2373,  0.4156, -0.1195, -0.5332, -0.3906,\n",
      "           0.0720,  0.1342, -0.1780,  0.0191, -0.3102,  0.1071]],\n",
      "\n",
      "        [[-0.7235, -0.5504,  0.2090,  0.0351, -0.2398, -0.1636,  0.2819,\n",
      "          -0.2427, -0.3981,  0.3372,  0.3241, -0.1222,  0.1654, -0.2165,\n",
      "           0.2550, -0.0287, -0.3783, -0.4224, -0.6462,  0.4746],\n",
      "         [-0.6836, -0.5916,  0.4398, -0.0899, -0.0469, -0.0051,  0.0072,\n",
      "           0.1513, -0.1175,  0.6282, -0.3829, -0.5863,  0.1795, -0.4231,\n",
      "          -0.0059,  0.5376, -0.1901, -0.4305, -0.2537,  0.4938],\n",
      "         [-0.5013, -0.3005, -0.0185, -0.4513, -0.3499,  0.1165, -0.6057,\n",
      "           0.7068,  0.2050, -0.6388,  0.1701, -0.3532,  0.3319, -0.3300,\n",
      "           0.2901, -0.2967, -0.5105,  0.2815, -0.1997, -0.3337]],\n",
      "\n",
      "        [[-0.1707,  0.2202,  0.2718, -0.3320, -0.0394, -0.1782, -0.5120,\n",
      "           0.1592, -0.3852, -0.1040, -0.2200, -0.3885,  0.7176, -0.1728,\n",
      "           0.0040,  0.0583, -0.6811,  0.0715, -0.0734, -0.1524],\n",
      "         [-0.6631, -0.5725,  0.1637, -0.1257, -0.2135,  0.1563,  0.3015,\n",
      "           0.3292,  0.1332, -0.1186,  0.0068, -0.5860,  0.0093, -0.3685,\n",
      "           0.3943,  0.2079, -0.3911, -0.5431, -0.2084,  0.4240],\n",
      "         [ 0.3113, -0.1314,  0.2967, -0.2694,  0.2241, -0.1966, -0.2360,\n",
      "          -0.1991,  0.2343, -0.2418,  0.0174, -0.6322,  0.2383,  0.0167,\n",
      "          -0.0537, -0.2263, -0.6970,  0.1103, -0.0630,  0.4280]],\n",
      "\n",
      "        [[-0.4547, -0.5596,  0.3929, -0.0198,  0.4176,  0.0522,  0.1368,\n",
      "           0.1997, -0.3800,  0.5646, -0.1287, -0.5379,  0.1102, -0.2605,\n",
      "          -0.2345,  0.4119, -0.2135, -0.1133, -0.2430,  0.5699],\n",
      "         [-0.3538, -0.2202,  0.5303, -0.2139,  0.0995, -0.0740, -0.3608,\n",
      "           0.2101, -0.1457,  0.1126, -0.0243, -0.3223,  0.6898, -0.1396,\n",
      "           0.4855,  0.1080, -0.0899, -0.4499, -0.1255,  0.3693],\n",
      "         [-0.0519,  0.0299, -0.0712, -0.1760,  0.3659,  0.1934, -0.2153,\n",
      "          -0.0246, -0.6112,  0.1670,  0.2269, -0.1633,  0.0711, -0.2427,\n",
      "          -0.3142, -0.0048, -0.6816,  0.3711, -0.3868, -0.0498]]],\n",
      "       grad_fn=<StackBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 网络参数\n",
    "input_size = 10\n",
    "hidden_size = 20\n",
    "num_layers = 2\n",
    "\n",
    "# 数据参数\n",
    "seq_len = 5\n",
    "batch_size = 3\n",
    "data_dim = input_size\n",
    "\n",
    "data = torch.randn(seq_len, batch_size, data_dim)\n",
    "\n",
    "# pytorch中原始的RNN\n",
    "ornn = nn.RNN(input_size, hidden_size, num_layers)\n",
    "h0 = torch.randn(num_layers, batch_size, hidden_size)\n",
    "\n",
    "class MyRNN():\n",
    "    def __init__(self):\n",
    "        # input_size, hidden_size\n",
    "        self.w_ih = torch.nn.Parameter(ornn.weight_ih_l0.T)\n",
    "        self.b_ih = torch.nn.Parameter(ornn.bias_ih_l0)\n",
    "        self.w_hh = torch.nn.Parameter(ornn.weight_hh_l0.T)\n",
    "        self.b_hh = torch.nn.Parameter(ornn.bias_hh_l0)\n",
    "        self.ht = torch.nn.Parameter(h0)\n",
    "        self.myoutput = []\n",
    "        if num_layers == 2:\n",
    "            self.ht = torch.nn.Parameter(h0[0])\n",
    "            self.ht1 = torch.nn.Parameter(h0[1])\n",
    "            self.w_ih_l1 = torch.nn.Parameter(ornn.weight_ih_l1.T)\n",
    "            self.b_ih_l1 = torch.nn.Parameter(ornn.bias_ih_l1)\n",
    "            self.w_hh_l1 = torch.nn.Parameter(ornn.weight_hh_l1.T)\n",
    "            self.b_hh_l1 = torch.nn.Parameter(ornn.bias_hh_l1)\n",
    "            \n",
    "    def forward(self, x): # x:(seq_len, batch_size, data_dim)\n",
    "        for i in range(seq_len):\n",
    "            # 第一层，应用公式\n",
    "            igates = torch.matmul(x[i], self.w_ih) + self.b_ih\n",
    "            hgates = torch.matmul(self.ht, self.w_hh) + self.b_hh\n",
    "            self.ht = torch.tanh(igates + hgates) # ht 更新\n",
    "            if num_layers == 2:\n",
    "                igates = torch.matmul(self.ht, self.w_ih_l1) + self.b_ih_l1\n",
    "                hgates = torch.matmul(self.ht1, self.w_hh_l1) + self.b_hh_l1\n",
    "                self.ht1 = torch.tanh(igates + hgates) # ht1 更新\n",
    "            ht_final_layer = [self.ht, self.ht1]\n",
    "            self.myoutput.append(self.ht1)  # 仅仅保留最后一层的输出\n",
    "        return ht_final_layer, self.myoutput\n",
    "    \n",
    "myrnn = MyRNN()\n",
    "myht, myoutput = myrnn.forward(data)\n",
    "official_output, official_hn = ornn(data, h0)\n",
    "\n",
    "print('myht:')\n",
    "print(myht)\n",
    "print('official_hn:')\n",
    "print(official_hn)\n",
    "\n",
    "print(\"--\" * 40)\n",
    "print('myoutput:')\n",
    "print(myoutput)\n",
    "print('official_output:')\n",
    "print(official_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 40])\n",
      "torch.Size([4, 3, 20])\n",
      "torch.Size([4, 3, 20])\n"
     ]
    }
   ],
   "source": [
    "lstm = nn.LSTM(10,20,num_layers = 2, bidirectional = True)\n",
    "\n",
    "# text:[序列长度，batch_size，词向量的维度 input_size]\n",
    "text = torch.randn(5,3,10) \n",
    "# h_0: [num_layers * num_directions， batch_size, hidden_size]\n",
    "h_0 = torch.randn(4,3,20)\n",
    "# c_0: [num_layers * num_directions, batch_size, hidden_size]\n",
    "c_0 = torch.randn(4,3,20)\n",
    "output, (h_n, c_n) = lstm(text)\n",
    "\n",
    "# output: [seq_length, batch_size, num_directions * hidden_size]\n",
    "print(output.shape)\n",
    "# h_n: [num_layers * num_directions, batch_size, hidden_size]\n",
    "print(h_n.size())\n",
    "# c_n:[num_layers * num_directions, batch_size, hidden_size]\n",
    "print(c_n.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 20])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\noutput: [batch_size, seq_length, num_directions * hidden_size]\\nh_n: [num_layers * num_directions, batch_size, hidden_size]\\nc_n: [num_layers * num_directions, batch_size, hidden_size]\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 20, 18])\n",
      "********************\n",
      "torch.Size([2, 10, 18])\n",
      "********************\n",
      "torch.Size([2, 10, 18])\n",
      "********************\n",
      "tensor([[True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "batch_size = 10\n",
    "seq_length = 20 # 句子的长度\n",
    "dictionary_size = 100 # 词典中词语的数量\n",
    "embedding_dim = 30 # 长度为30的向量表示一个词语\n",
    "hidden_size = 18\n",
    "num_layer = 2\n",
    "\n",
    "# 构造一个batch的数据\n",
    "text = torch.randint(low = 0, high = 100, size = [batch_size, seq_length])\n",
    "print(text.shape)\n",
    "\n",
    "# 数据经过embedding处理\n",
    "embedding = nn.Embedding(dictionary_size, embedding_dim)\n",
    "text_embedded = embedding(text)\n",
    "\n",
    "# 传入LSTM\n",
    "lstm = nn.LSTM(input_size = embedding_dim,\n",
    "              hidden_size = hidden_size,\n",
    "              num_layers = num_layer,\n",
    "              batch_first = True)\n",
    "\n",
    "'''\n",
    "output: [batch_size, seq_length, num_directions * hidden_size]\n",
    "h_n: [num_layers * num_directions, batch_size, hidden_size]\n",
    "c_n: [num_layers * num_directions, batch_size, hidden_size]\n",
    "'''\n",
    "output, (h_n, c_n) = lstm(text_embedded)\n",
    "\n",
    "# output把每一个时间步上的结果在seq_length这一维度上进行了拼接\n",
    "print(output.shape) # torch.Size([10,20,18])\n",
    "print(f\"{'*' * 20}\")\n",
    "\n",
    "# h_n把不同层的隐藏状态在第0个维度上进行了拼接\n",
    "print(h_n.size()) # torch,Size([2,10,18])\n",
    "print(f\"{'*' * 20}\")\n",
    "\n",
    "print(c_n.shape)  # torch.Size([2, 10, 18])\n",
    "print(f\"{'*' * 20}\")\n",
    "\n",
    "# 最后一次的h_1应该和output的最后一个time step的输出是一样的\n",
    "\n",
    "# 获取最后一个时间步上的输出\n",
    "last_output = output[:, -1, :]\n",
    "\n",
    "# 获取最后一次的hidden_state\n",
    "last_hidden_state = h_n[-1, :, :]\n",
    "\n",
    "print(last_output == last_hidden_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 交叉熵损失：把softmax概率传入对数似然损失得到的损失函数称为交叉熵损失：\n",
    "# 在pytorch中有两种方法实现交叉熵损失：\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "loss=criterion(input, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-b0db57ca3d5f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 1、对输出值计算softmax和取对数\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0moutput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# 2、使用torch中带权损失\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "# 1、对输出值计算softmax和取对数\n",
    "output=F.log_softmax(x,dim=-1)\n",
    "# 2、使用torch中带权损失\n",
    "loss=F.nll_loss(output,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 双向LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 20])\n",
      "********************\n",
      "torch.Size([10, 20, 30])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\noutput: [batch_size, seq_length, num_directions * hidden_size]\\nh_n: [num_layers * num_directions, batch_size, hidden_size]\\nc_n: [num_layers * num_directions, batch_size, hidden_size]\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 20, 36])\n",
      "********************\n",
      "torch.Size([2, 10, 18])\n",
      "********************\n",
      "torch.Size([2, 10, 18])\n",
      "********************\n",
      "torch.Size([10, 18])\n",
      "********************\n",
      "torch.Size([10, 18])\n",
      "********************\n",
      "正向output和正向h_n是否相等：tensor([[True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True]])\n",
      "torch.Size([10, 18])\n",
      "********************\n",
      "torch.Size([10, 18])\n",
      "********************\n",
      "反向output和反向h_n是否相等：tensor([[True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "batch_size = 10\n",
    "seq_length = 20\n",
    "dictionary_size = 100\n",
    "embedding_dim = 30\n",
    "hidden_size = 18\n",
    "num_layer = 1\n",
    "\n",
    "# 构造一个batch的数据\n",
    "text = torch.randint(low = 0, high = 100, size = [batch_size, seq_length])\n",
    "print(text.shape)\n",
    "print(f\"{'*' * 20}\")\n",
    "\n",
    "# 数据经过embedding处理\n",
    "embedding = nn.Embedding(dictionary_size, embedding_dim)\n",
    "text_embedded = embedding(text)\n",
    "print(text_embedded.shape)\n",
    "\n",
    "# 传入LSTM\n",
    "lstm = nn.LSTM(input_size = embedding_dim,\n",
    "              hidden_size = hidden_size,\n",
    "              num_layers = num_layer,\n",
    "              batch_first = True, bidirectional = True)\n",
    "\n",
    "\"\"\"\n",
    "output: [batch_size, seq_length, num_directions * hidden_size]\n",
    "h_n: [num_layers * num_directions, batch_size, hidden_size]\n",
    "c_n: [num_layers * num_directions, batch_size, hidden_size]\n",
    "\"\"\"\n",
    "output, (h_n, c_n) = lstm(text_embedded)\n",
    "\n",
    "# output把每一个时间步上的结果在seq_length这一维度上进行了拼接\n",
    "# 如果lstm是双向的，则output的num_directions * hidden_size维度中前面是前hidden_size个数据是正向lstm的输出，\n",
    "# 后hidden_size个数据是反向lstm的输出\n",
    "print(output.shape)  # torch.Size([10, 20, 36])\n",
    "print(f\"{'*' * 20}\")\n",
    "\n",
    "# h_n把不同层的隐层状态在第0个维度上进行了拼接\n",
    "# h_n把双向lstm中正向的hidden_state和反向的hidden_state在第0个维度上进行了拼接\n",
    "print(h_n.size())\n",
    "print(f\"{'*' * 20}\")\n",
    "\n",
    "print(c_n.shape)\n",
    "print(f\"{'*' * 20}\")\n",
    "\n",
    "# 获取双向lstm中正向的最后一个时间步output\n",
    "forward_output = output[:, -1, :18]\n",
    "print(forward_output.shape)\n",
    "print(f\"{'*' * 20}\")\n",
    "\n",
    "# 获取双向lstm中正向的最后一个hidden_state\n",
    "forward_h_n = h_n[-2,:,:]\n",
    "print(forward_h_n.shape)\n",
    "print(f\"{'*' * 20}\")\n",
    "\n",
    "print(f\"正向output和正向h_n是否相等：{forward_output == forward_h_n}\")\n",
    "\n",
    "# 获取双向lstm中反向最后一个时间步的output\n",
    "backward_output = output[:, 0, 18:]\n",
    "print(backward_output.shape)\n",
    "print(f\"{'*' * 20}\")\n",
    "\n",
    "# 获取双向lstm中反向的最后一个hidden_state\n",
    "backward_h_n = h_n[-1, :, :]\n",
    "print(backward_h_n.shape)\n",
    "print(f\"{'*' * 20}\")\n",
    "\n",
    "print(f\"反向output和反向h_n是否相等：{backward_output == backward_h_n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 20])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\noutput: [batch_size, seq_length, num_directions * hidden_size]\\nh_n: [num_layers * num_directions, batch_size, hidden_size]\\nc_n: [num_layers * num_directions, batch_size, hidden_size]\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 20, 36])\n",
      "********************\n",
      "torch.Size([4, 10, 18])\n",
      "********************\n",
      "torch.Size([4, 10, 18])\n",
      "********************\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n-4/1 第一层的正向\\n-3/2 第一层的反向\\n-2/3 第二层的正向    对应的是[:, -1, :18]\\n-1/4 第二层的反向    对应的是[:, 0,  18:]\\n这些相关的方向暂时没有搞懂\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "batch_size = 10\n",
    "seq_length = 20 # 句子的长度\n",
    "dictionary_size = 100 # 词典中词语的数量\n",
    "embedding_dim = 30 # 长度为30的向量表示一个词语\n",
    "hidden_size = 18\n",
    "num_layer = 2\n",
    "\n",
    "# 构造一个batch的数据\n",
    "text = torch.randint(low=0, high=100, size=[batch_size, seq_length])\n",
    "\n",
    "print(text.shape)\n",
    "\n",
    "# 数据经过embedding处理\n",
    "embedding = nn.Embedding(dictionary_size, embedding_dim)\n",
    "text_embedded = embedding(text)\n",
    "\n",
    "# 传入LSTM\n",
    "lstm = nn.LSTM(input_size=embedding_dim,\n",
    "               hidden_size=hidden_size,\n",
    "               num_layers=num_layer,\n",
    "               batch_first=True, bidirectional = True)\n",
    "\n",
    "'''\n",
    "output: [batch_size, seq_length, num_directions * hidden_size]\n",
    "h_n: [num_layers * num_directions, batch_size, hidden_size]\n",
    "c_n: [num_layers * num_directions, batch_size, hidden_size]\n",
    "'''\n",
    "output, (h_n, c_n) = lstm(text_embedded)\n",
    "\n",
    "# output把每一个时间步上的结果在seq_length这一维度上进行了拼接\n",
    "print(output.shape)  # torch.Size([10, 20, 36])\n",
    "print(f\"{'*' * 20}\")\n",
    "\n",
    "# h_n把不同层的隐藏状态在第0个维度上进行了拼接\n",
    "print(h_n.size())  # torch.Size([4, 10, 18])\n",
    "print(f\"{'*' * 20}\")\n",
    "\n",
    "print(c_n.shape)  # torch.Size([4, 10, 18])\n",
    "print(f\"{'*' * 20}\")\n",
    "\n",
    "# 最后一次的h_1应该和output的最后一个time step的输出是一样的\n",
    "\n",
    "# 获取最后一个时间步上的输出\n",
    "last_output = output[:, 0, 18:]\n",
    "\n",
    "# 获取最后一次的hidden_state\n",
    "last_hidden_state = h_n[-1, :, :]\n",
    "\n",
    "'''\n",
    "-4/1 第一层的正向\n",
    "-3/2 第一层的反向\n",
    "-2/3 第二层的正向    对应的是[:, -1, :18]\n",
    "-1/4 第二层的反向    对应的是[:, 0,  18:]\n",
    "这些相关的方向暂时没有搞懂\n",
    "'''\n",
    "\n",
    "print(last_output == last_hidden_state)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用双向LSTM实现文本情感分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 这段代码跑不通"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from dataset import get_dataloader\n",
    "from pkl import ws, MAX_LEN\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class ImdbModule(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(ImdbModule, self).__init__()\n",
    "        self.embedding = nn.Embedding(len(ws), input_size, padding_idx=ws.PAD)\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        '''\n",
    "        nn.LSTM:\n",
    "            Args:\n",
    "                input_size: The number of expected features in the input `x`\n",
    "                hidden_size: The number of features in the hidden state `h`\n",
    "                num_layers: Number of recurrent layers.\n",
    "                bias: If `False`, then the layer does not use bias weights `b_ih` and `b_hh`.\n",
    "                batch_first: If `True`, then the input and output tensors are provided as (batch, seq, feature).\n",
    "                bidirectional: If `True`, becomes a bidirectional LSTM.\n",
    "        '''\n",
    "\n",
    "        '''\n",
    "        input:\n",
    "            x: [seq_length, batch_size, input_size] (tensor containing the features of the input sequence.)\n",
    "            h_0: [num_layers * num_directions, batch_size, hidden_size] (tensor\n",
    "              containing the initial hidden state for each element in the batch.)\n",
    "            c_0: [num_layers * num_directions, batch_size, hidden_size] (tensor\n",
    "              containing the initial cell state for each element in the batch.)\n",
    "        return: output, (h_n, c_n):\n",
    "            output: [seq_length, batch_size, num_directions * hidden_size]\n",
    "            h_n: [num_layers * num_directions, batch_size, hidden_size]\n",
    "            c_n: [num_layers * num_directions, batch_size, hidden_size]\n",
    "        '''\n",
    "        self.lstm = nn.LSTM(input_size=input_size,\n",
    "                            hidden_size=self.hidden_size,\n",
    "                            num_layers=2, bidirectional=True)\n",
    "\n",
    "        self.linear = nn.Linear(2 * self.hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        :param x: [batch_size, seq_length]\n",
    "        :param h_0: [num_layers * num_directions, batch_size, hidden_size]\n",
    "        :param c_0: [num_layers * num_directions, batch_size, hidden_size]\n",
    "        :return:\n",
    "        '''\n",
    "\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # x: [batch_size, seq_length, input_size]\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # x: [seq_length, batch_size, input_size]\n",
    "        x = x.permute(1, 0, 2)\n",
    "\n",
    "        # output: [seq_length, batch_size, num_directions * hidden_size]\n",
    "        # h_n: [num_layers * num_directions, batch_size, hidden_size]\n",
    "        # c_n: [num_layers * num_directions, batch_size, hidden_size]\n",
    "        output, (h_n, c_n) = self.lstm(x)\n",
    "\n",
    "        # 往往会使用LSTM or GRU输出的最后一维结果来代表LSTM、GRU对文本处理的结果\n",
    "        # 使用双向LSTM的时候，往往会使用每个方向最后一次的output，作为当前数据经过双向LSTM的结果\n",
    "\n",
    "        out = torch.cat((h_n[-2, :, :], h_n[-1, :, :]), dim=-1)\n",
    "        out = self.linear(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "TRAIN_BATCH_SIZE = 128\n",
    "TEST_BATCH_SIZE = 128\n",
    "LR = 0.001\n",
    "\n",
    "imdb = ImdbModule(100, 256, 11).to(device)\n",
    "\n",
    "optimizer = optim.Adam(imdb.parameters(), lr=LR)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "\n",
    "def train_test(epoch):\n",
    "    print(f\"{'-' * 10}epoch: {epoch + 1}{'-' * 10}\")\n",
    "\n",
    "    mode = True\n",
    "    imdb.train(mode)\n",
    "\n",
    "    train_dataloader, train_data_length = get_dataloader(mode='train', batch_size=TRAIN_BATCH_SIZE)\n",
    "\n",
    "    for idx, (text, label) in enumerate(train_dataloader):\n",
    "        text = text.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 第一次调用LSTM模型之前，需要初始化隐藏状态，如果不初始化，默认创建全为0的隐藏状态\n",
    "        output = imdb(text)\n",
    "\n",
    "        loss = criterion(output, label)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if idx % 50 == 0:\n",
    "            print(f\"第{epoch}轮训练次数为{idx}的误差：{loss.item()}\")\n",
    "\n",
    "    print(f\"{'-' * 10}测试开始{'-' * 10}\")\n",
    "\n",
    "    imdb.eval()\n",
    "\n",
    "    test_dataloader, len_test_data = get_dataloader('test', batch_size=TEST_BATCH_SIZE)\n",
    "\n",
    "    sum_loss = 0\n",
    "    total_accuracy = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for text, label in tqdm(test_dataloader):\n",
    "            text = text.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            output = imdb(text)\n",
    "\n",
    "            loss = criterion(output, label)\n",
    "            sum_loss += loss\n",
    "\n",
    "            predicted = output.argmax(1)\n",
    "            accuracy = (predicted == label).sum()\n",
    "\n",
    "            total_accuracy += accuracy\n",
    "\n",
    "    print(f\"测试集上的loss：{sum_loss}\")\n",
    "\n",
    "    correct_accuracy = total_accuracy / len_test_data\n",
    "    print(f\"整体测试集上的正确率：{correct_accuracy}%\")\n",
    "\n",
    "    print(\"模型保存成功\")\n",
    "    torch.save(imdb.state_dict(), f'./model/lstm_{epoch}.pth')\n",
    "\n",
    "    now = datetime.now()\n",
    "    now = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    content = f\"time：{now}\\tlstm模型在测试集上的准确率：{correct_accuracy}\"\n",
    "\n",
    "    with open('./accuracy.txt', 'a+', encoding='utf-8') as file:\n",
    "        file.write(content + '\\n')\n",
    "\n",
    "for epoch in range(100):\n",
    "    train_test(epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pytorch代码实现（GRU）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nGRU:\\n    Applies a multi-layer gated recurrent unit (GRU) RNN to an input sequence.\\n\\n    args:\\n        input_size: The number of expected features in the input `x`\\n        hidden_size: The number of features in the hidden state `h`\\n        num_layers: Number of recurrent layers.\\n        bias: If `False`, then the layer does not use bias weights\\n        bidirectional: If `True`, becomes a bidirectional GRU.\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'\\nInputs: input, h_0\\n    input: [seq_length, batch_size, input_size]\\n    h_0: [num_layers * num_directions, batch_size, hidden_size]\\n\\nOutputs: output, h_n\\n    output: [seq_length, batch_size, num_directions * hidden_size]\\n    h_n: [num_layers * num_directions, batch_size, hidden_size]\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'\\noutput: [seq_length, batch_size, num_directions * hidden_size]\\nh_n: [num_layers * num_directions, batch_size, hidden_size]\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 20])\n",
      "********************\n",
      "torch.Size([3, 20])\n",
      "********************\n",
      "正向output和正向h_n是否相等：tensor([[True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True]])\n",
      "torch.Size([3, 20])\n",
      "********************\n",
      "torch.Size([3, 20])\n",
      "********************\n",
      "反向output和反向h_n是否相等：tensor([[True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "'''\n",
    "GRU:\n",
    "    Applies a multi-layer gated recurrent unit (GRU) RNN to an input sequence.\n",
    "\n",
    "    args:\n",
    "        input_size: The number of expected features in the input `x`\n",
    "        hidden_size: The number of features in the hidden state `h`\n",
    "        num_layers: Number of recurrent layers.\n",
    "        bias: If `False`, then the layer does not use bias weights\n",
    "        bidirectional: If `True`, becomes a bidirectional GRU.\n",
    "'''\n",
    "\n",
    "'''\n",
    "Inputs: input, h_0\n",
    "    input: [seq_length, batch_size, input_size]\n",
    "    h_0: [num_layers * num_directions, batch_size, hidden_size]\n",
    "\n",
    "Outputs: output, h_n\n",
    "    output: [seq_length, batch_size, num_directions * hidden_size]\n",
    "    h_n: [num_layers * num_directions, batch_size, hidden_size]\n",
    "'''\n",
    "\n",
    "# 双层双向GRU\n",
    "gru = nn.GRU(input_size=10, hidden_size=20, num_layers=2, bidirectional=True)\n",
    "\n",
    "# text: [seq_length, batch_size, input_size] \n",
    "text = torch.randn(5, 3, 10)\n",
    "\n",
    "# h_0: [num_layers * num_directions, batch_size, hidden_size]\n",
    "h_0 = torch.randn(4, 3, 20)\n",
    "\n",
    "'''\n",
    "output: [seq_length, batch_size, num_directions * hidden_size]\n",
    "h_n: [num_layers * num_directions, batch_size, hidden_size]\n",
    "'''\n",
    "output, h_n = gru(text, h_0)\n",
    "\n",
    "# 获取双向gru中正向最后一个时间步的output\n",
    "forward_output = output[-1,:,:20]\n",
    "print(forward_output.shape) # [batch_size, hidden_size]\n",
    "print(f\"{'*' * 20}\")\n",
    "\n",
    "# 获取双向gru中正向的最后一个hidden_state\n",
    "forward_h_n=h_n[-2,:,:]\n",
    "print(forward_h_n.shape) # [batch_size, hidden_size]\n",
    "print(f\"{'*' * 20}\")\n",
    "\n",
    "print(f\"正向output和正向h_n是否相等：{forward_output == forward_h_n}\")\n",
    "\n",
    "# 获取双向gru中反向最后一个时间步的output  正向的为前20，反向的为后20\n",
    "backward_output=output[0,:,20:]\n",
    "print(backward_output.shape) # [batch_size, hidden_size]\n",
    "print(f\"{'*' * 20}\")\n",
    "\n",
    "# 获取双向gru中反向的最后一个hidden_state\n",
    "backward_h_n=h_n[-1,:,:]\n",
    "print(backward_h_n.shape)\n",
    "print(f\"{'*' * 20}\")\n",
    "\n",
    "print(f\"反向output和反向h_n是否相等：{backward_output == backward_h_n}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用双向GRU实现文本情感分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from dataset import get_dataloader\n",
    "from pkl import ws, MAX_LEN\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "class ImdbModule(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(ImdbModule, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(len(ws), input_size, padding_idx=ws.PAD)\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        '''\n",
    "        GRU:\n",
    "            Applies a multi-layer gated recurrent unit (GRU) RNN to an input sequence.\n",
    "            \n",
    "            args:\n",
    "                input_size: The number of expected features in the input `x`\n",
    "                hidden_size: The number of features in the hidden state `h`\n",
    "                num_layers: Number of recurrent layers.\n",
    "                bias: If `False`, then the layer does not use bias weights\n",
    "                bidirectional: If `True`, becomes a bidirectional GRU.\n",
    "        '''\n",
    "\n",
    "        '''\n",
    "        Inputs: input, h_0\n",
    "            input: [seq_length, batch, input_size]\n",
    "            h_0: [num_layers * num_directions, batch_size, hidden_size]\n",
    "            \n",
    "        Outputs: output, h_n\n",
    "            output: [seq_length, batch_size, num_directions * hidden_size]\n",
    "            h_n: [num_layers * num_directions, batch_size, hidden_size]\n",
    "        '''\n",
    "\n",
    "        self.gru = nn.GRU(input_size=input_size,\n",
    "                          hidden_size=self.hidden_size,\n",
    "                          num_layers=2,\n",
    "                          bidirectional=True,\n",
    "                          dropout=0.5)\n",
    "\n",
    "        self.linear = nn.Linear(in_features=2 * hidden_size, out_features=output_size)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        :param x: [batch_size, seq_length]\n",
    "        :return:\n",
    "        '''\n",
    "\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # x: [batch_size, seq_length, embedding_dim]\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # x: [seq_length, batch_size, input_size]\n",
    "        x = x.permute(1, 0, 2)\n",
    "\n",
    "        '''\n",
    "        output: [seq_length, batch_size, num_directions * hidden_size]\n",
    "        h_n: [num_layers * num_directions, batch_size, hidden_size]\n",
    "        '''\n",
    "        output, h_n = self.gru(x)\n",
    "\n",
    "        h_n = torch.cat((h_n[-2, :, :], h_n[-1, :, :]), dim=-1)\n",
    "\n",
    "        out = self.linear(h_n)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "TRAIN_BATCH_SIZE = 128\n",
    "TEST_BATCH_SIZE = 128\n",
    "LR = 0.001\n",
    "\n",
    "imdb = ImdbModule(256, 256, 11).to(device)\n",
    "\n",
    "optimizer = optim.Adam(imdb.parameters(), lr=LR)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "\n",
    "def train_test(epoch):\n",
    "    print(f\"{'-' * 10}epoch: {epoch + 1}{'-' * 10}\")\n",
    "\n",
    "    mode = True\n",
    "    imdb.train(mode)\n",
    "\n",
    "    train_dataloader, train_data_length = get_dataloader(mode='train', batch_size=TRAIN_BATCH_SIZE)\n",
    "\n",
    "    for idx, (text, label) in enumerate(train_dataloader):\n",
    "        text = text.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 第一次调用LSTM模型之前，需要初始化隐藏状态，如果不初始化，默认创建全为0的隐藏状态\n",
    "        output = imdb(text)\n",
    "\n",
    "        loss = criterion(output, label)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if idx % 50 == 0:\n",
    "            print(f\"第{epoch}轮训练次数为{idx}的误差：{loss.item()}\")\n",
    "\n",
    "    print(f\"{'-' * 10}测试开始{'-' * 10}\")\n",
    "\n",
    "    imdb.eval()\n",
    "\n",
    "    test_dataloader, len_test_data = get_dataloader('test', batch_size=TEST_BATCH_SIZE)\n",
    "\n",
    "    sum_loss = 0\n",
    "    total_accuracy = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for text, label in tqdm(test_dataloader):\n",
    "            text = text.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            output = imdb(text)\n",
    "\n",
    "            loss = criterion(output, label)\n",
    "            sum_loss += loss\n",
    "\n",
    "            predicted = output.argmax(1)\n",
    "            accuracy = (predicted == label).sum()\n",
    "\n",
    "            total_accuracy += accuracy\n",
    "\n",
    "    print(f\"测试集上的loss：{sum_loss}\")\n",
    "\n",
    "    correct_accuracy = total_accuracy / len_test_data\n",
    "    print(f\"整体测试集上的正确率：{correct_accuracy}%\")\n",
    "\n",
    "    print(\"模型保存成功\")\n",
    "    torch.save(imdb.state_dict(), f'./model/lstm_{epoch}.pth')\n",
    "\n",
    "    now = datetime.now()\n",
    "    now = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    content = f\"time：{now}\\tlstm模型在测试集上的准确率：{correct_accuracy}\"\n",
    "\n",
    "    with open('./accuracy.txt', 'a+', encoding='utf-8') as file:\n",
    "        file.write(content + '\\n')\n",
    "\n",
    "\n",
    "for epoch in range(100):\n",
    "    train_test(epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
