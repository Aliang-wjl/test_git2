{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48e6523c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from start1 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18fbf326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集获取\n",
    "def get_cifar10(data_path, batch_size):\n",
    "    # 定义数据变换\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),  # 将图片转换为Tensor\n",
    "         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])  # 归一化\n",
    "    # 下载CIFAR10数据集\n",
    "    # #训练集\n",
    "    trainset=datasets.CIFAR10(root=data_path,train=True,download=False,transform=transform)\n",
    "    # 测试集\n",
    "    testset=datasets.CIFAR10(root=data_path,train=False,download=False,transform=transform)\n",
    "\n",
    "    #练习集 封装成DataLoader的形式 batch_size 按照批次传 shuffle 将数据打散 num_workers 线程\n",
    "    # 创建DataLoader对象\n",
    "    train_loader=torch.utils.data.DataLoader(trainset,batch_size=batch_size,shuffle=True)\n",
    "    test_loader=torch.utils.data.DataLoader(testset,batch_size=batch_size,shuffle=False)\n",
    "\n",
    "    return train_loader,test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4474d610",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = r'../data'\n",
    "batch_size=512\n",
    "lr= 1e-1 * (batch_size/256) # 当batch_size过大时，通过增大学习率降低梯度中的噪声\n",
    "weight_decay = 0.\n",
    "warmup = True\n",
    "num_epochs = 20\n",
    "warmup_epochs = 5\n",
    "num_classes = 10\n",
    "data_type = 0  # 数据是否具有时间维度，0表示没有，1表示有\n",
    "T = 4 # 静态数据需要的时间步\n",
    "T_data = 0 # 代表数据本身已经有时间维度或者网络对数据添加时间维度了，不需要自己再加了,一般会在网络中直接加入时间步，所以基本上这个值都是0\n",
    "\n",
    "train_loader,test_loader = get_cifar10(root_dir, batch_size = batch_size)\n",
    "# 设备选择使用GPU   数据的维度  B, T , 2, 128, 128\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "net = sew_resnet18(input_channels = 3,num_classes = num_classes, connect_f = 'ADD',T = T).to(device)\n",
    "# (block, layers, input_channels = 3, num_classes=1000, zero_init_residual=False,groups=1, \n",
    "#  width_per_group=64, replace_stride_with_dilation=None,norm_layer=None, T=4, connect_f=None, \n",
    "#  drops = [0,0,0,0], p = [0.5,0.5,0.5,0.5], data_type = 0, net_type = 0)\n",
    "pg = get_params_groups(net, weight_decay=weight_decay)  # 进行了简单分组的权重 确定了哪些参数需要权重衰减，哪些不需要\n",
    "optimizer = optim.AdamW(pg, lr=lr, weight_decay=weight_decay)\n",
    "lr_scheduler = create_lr_scheduler(optimizer, len(train_loader), num_epochs,\n",
    "                                   warmup=warmup, warmup_epochs=warmup_epochs)\n",
    "loss_function = F.mse_loss\n",
    "loss_function = nn.CrossEntropyLoss(label_smoothing = 0.1)\n",
    "# scaler = None\n",
    "scaler = amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1356a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accs,train_losss,test_accs,test_losss = trains(num_epochs, net, train_loader,\n",
    "        test_loader, optimizer, device, loss_function, scaler = scaler, \n",
    "        encoder = encoding.PoissonEncoder(), T = T_data, num_classes = num_classes, \n",
    "        data_type = data_type, save_model = \"./save_models/test_cifar10.pt\", lr_scheduler = lr_scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8a6141",
   "metadata": {},
   "source": [
    "##### 1.标签平滑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "00996b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最终得到的就是标签平滑后的张量，使用独热编码\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "class LSR(nn.Module):\n",
    "    def __init__(self, e=0.1, reduction='mean'):\n",
    "            super().__init__()\n",
    "            self.log_softmax = nn.LogSoftmax(dim=1)\n",
    "            self.e = e\n",
    "            self.reduction = reduction\n",
    "    def _one_hot(self, labels, classes, value=1):\n",
    "        \"\"\"\n",
    "            Convert labels to one hot vectors\n",
    "            思路就是：首先创建一个二维张量，接着按照标签的个数创建一个值为1的列，使二维张量对应的标签位置加上这个值。\n",
    "        Args:\n",
    "            labels: torch tensor in format [label1, label2, label3, ...]\n",
    "            classes: int, number of classes\n",
    "            value: label value in one hot vector, default to 1\n",
    "        Returns:\n",
    "            return one hot format labels in shape [batchsize, classes]\n",
    "        \"\"\"\n",
    "        one_hot = torch.zeros(labels.size(0), classes)\n",
    "#         labels and value_added  size must match\n",
    "        labels = labels.view(labels.size(0), -1)\n",
    "        value_added = torch.Tensor(labels.size(0), 1).fill_(value)\n",
    "        value_added = value_added.to(labels.device)\n",
    "        one_hot = one_hot.to(labels.device)\n",
    "        # (dim, index, src)\n",
    "        one_hot.scatter_add_(1, labels, value_added)\n",
    "        return one_hot\n",
    "\n",
    "    def _smooth_label(self, target, length, smooth_factor):\n",
    "        \"\"\"convert targets to one-hot format, and smooth\n",
    "        them.\n",
    "        Args:\n",
    "            target: target in form with [label1, label2, label_batchsize]\n",
    "            length: length of one-hot format(number of classes)\n",
    "            smooth_factor: smooth factor for label smooth\n",
    "        Returns:\n",
    "            smoothed labels in one hot format\n",
    "        \"\"\"\n",
    "        one_hot = self._one_hot(target, length, value=1- smooth_factor)\n",
    "        one_hot += smooth_factor / length\n",
    "        return one_hot.to(target.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "38a32e4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2036)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = torch.FloatTensor([[0, 0.2, 0.7, 0.1, 0],\n",
    "                             [0, 0.9, 0.2, 0.2, 1],\n",
    "                             [1, 0.2, 0.7, 0.9, 1]])\n",
    "target = torch.LongTensor([2,1,0])\n",
    "classes = 5 # 类别数量是target最大值 + 1\n",
    "smooth_factor = 0.3\n",
    "target = LSR()._smooth_label(target, classes,smooth_factor)\n",
    "loss_func = F.mse_loss\n",
    "loss = loss_func(predict,target)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5a1a77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d723008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用交叉熵损失函数时，如何使用标签平滑\n",
    "class LabelSmoothing(nn.Module):\n",
    "    \"\"\"NLL loss with label smoothing.\n",
    "    \"\"\"\n",
    "    def __init__(self, smoothing=0.0):\n",
    "        \"\"\"Constructor for the LabelSmoothing module.\n",
    "        :param smoothing: label smoothing factor\n",
    "        \"\"\"\n",
    "        super(LabelSmoothing, self).__init__()\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "\n",
    "    def forward(self, x, target):\n",
    "        logprobs = torch.nn.functional.log_softmax(x, dim=-1)\n",
    "        nll_loss = -logprobs.gather(dim=-1, index=target.unsqueeze(1))\n",
    "        nll_loss = nll_loss.squeeze(1)\n",
    "        smooth_loss = -logprobs.mean(dim=-1)\n",
    "        loss = self.confidence * nll_loss + self.smoothing * smooth_loss\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c8f4fdb7",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.8469, -1.6469, -1.1469, -1.7469, -1.8469],\n",
       "        [-2.1542, -1.2542, -1.9542, -1.9542, -1.1542],\n",
       "        [-1.4098, -2.2098, -1.7098, -1.5098, -1.4098]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.1469],\n",
       "        [1.2542],\n",
       "        [1.4098]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.6469, 1.6942, 1.6498])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.1969, 1.2017, 1.1972],\n",
       "        [1.2934, 1.2982, 1.2937],\n",
       "        [1.4335, 1.4382, 1.4338]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.FloatTensor([[0, 0.2, 0.7, 0.1, 0],\n",
    "                     [0, 0.9, 0.2, 0.2, 1],\n",
    "                     [1, 0.2, 0.7, 0.9, 1]])\n",
    "\n",
    "target = torch.LongTensor([2, 1, 0])\n",
    "logprobs = torch.nn.functional.log_softmax(x, dim=-1)\n",
    "logprobs\n",
    "nll_loss = -logprobs.gather(dim=-1, index=target.unsqueeze(1))\n",
    "nll_loss\n",
    "smooth_loss = -logprobs.mean(dim=-1)\n",
    "smooth_loss\n",
    "loss = 0.9 * nll_loss + 0.1 * smooth_loss\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "471e0a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3883)\n"
     ]
    }
   ],
   "source": [
    "# NVIDIA \n",
    "crit = LabelSmoothing(smoothing=0.3)\n",
    "predict = torch.FloatTensor([[0, 0.2, 0.7, 0.1, 0],\n",
    "                             [0, 0.9, 0.2, 0.2, 1],\n",
    "                             [1, 0.2, 0.7, 0.9, 1]])\n",
    "v = crit(predict,torch.LongTensor([2, 1, 0]))\n",
    "print(v)\n",
    "\n",
    "# tensor(1.3883)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cb85da2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.3883)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用CrossEntropyLoss 可以直接设置标签\n",
    "loss_func = nn.CrossEntropyLoss(label_smoothing = 0.3)\n",
    "v = torch.LongTensor([2, 1, 0])\n",
    "loss_func(predict ,v)\n",
    "# tensor(1.3883)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83565dbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3d8cfd8",
   "metadata": {},
   "source": [
    "##### Random image cropping and patching  图像的随机裁剪和拼接\n",
    "挑选k张图像，在每一张图片上裁剪对应位置的图像，之后把裁剪完的图像进行拼接，保证拼接完图像的长和宽与原来一样即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "93bd99cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = r'../data'\n",
    "batch_size = 512\n",
    "train_loader,test_loader = get_cifar10(root_dir, batch_size = 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c0e63605",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 13, 32])\n",
      "torch.Size([3, 19, 32])\n",
      "torch.Size([3, 13, 0])\n",
      "torch.Size([3, 19, 0])\n",
      "torch.Size([3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "beta = 0.3# hyperparameter\n",
    "for(images, targets) in train_loader:\n",
    "    # get the image size,长和宽\n",
    "    I_x, I_y = images.size()[2:]\n",
    "    # draw a boundry position (w, h)\n",
    "    w = int(np.round(I_x * np.random.beta(beta, beta)))\n",
    "    h = int(np.round(I_y * np.random.beta(beta, beta)))\n",
    "    w_ = [w, I_x - w, w, I_x - w]\n",
    "    h_ = [h, h, I_y - h, I_y - h]\n",
    "    # select and crop four images\n",
    "    cropped_images = {}\n",
    "    c_ = {}\n",
    "    W_ = {}\n",
    "    index = torch.randperm(images.size(0))\n",
    "    for k in range(4):\n",
    "        # 每次随机挑选四张图片进行训练\n",
    "        x_k = np.random.randint(0, I_x - w_[k] + 1)\n",
    "        y_k = np.random.randint(0, I_y - h_[k] + 1)\n",
    "        cropped_images[k] = images[index[k]][:, x_k:x_k + w_[k], y_k:y_k + h_[k]]\n",
    "        print(cropped_images[k].shape)\n",
    "        c_[k] = targets[index[k]].cuda()\n",
    "        W_[k] = w_[k] * h_[k] / (I_x * I_y)\n",
    "    # patch cropped images\n",
    "    patched_images = torch.cat((torch.cat((cropped_images[0], cropped_images[1]), 1),\n",
    "                torch.cat((cropped_images[2], cropped_images[3]), 1)), 2)\n",
    "    print(patched_images.shape) \n",
    "    break\n",
    "#     #patched_images = patched_images.cuda()\n",
    "#     # get output\n",
    "#     output = model(patched_images)\n",
    "#     # calculate loss and accuracy\n",
    "#     loss = sum([W_[k] * criterion(output, c_[k]) for k in range(4)])\n",
    "#     acc = sum([W_[k] * accuracy(output, c_[k])[0] for k in range(4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "dead3cd9",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 100x100 with 0 Axes>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.9372549..0.94509804].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x222800337a0>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(-0.5, 31.5, 31.5, -0.5)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = patched_images.permute(1, 2, 0)\n",
    "# 绘制图像\n",
    "plt.figure(figsize=(1,1))\n",
    "plt.imshow(image)\n",
    "plt.axis('off')  # 关闭坐标轴\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8cc7802e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 100x100 with 0 Axes>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.8509804..0.8901961].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x22267ed2930>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(-0.5, 31.5, 31.5, -0.5)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = images[index[0]].permute(1, 2, 0)\n",
    "# 绘制图像\n",
    "plt.figure(figsize=(1,1))\n",
    "plt.imshow(image)\n",
    "plt.axis('off')  # 关闭坐标轴\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a3aa48c0",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 100x100 with 0 Axes>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.9607843..0.94509804].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x222688fa240>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(-0.5, 31.5, 31.5, -0.5)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = images[index[1]].permute(1, 2, 0)\n",
    "# 绘制图像\n",
    "plt.figure(figsize=(1,1))\n",
    "plt.imshow(image)\n",
    "plt.axis('off')  # 关闭坐标轴\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "93e95eca",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 100x100 with 0 Axes>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.99215686..1.0].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2220f526ab0>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(-0.5, 31.5, 31.5, -0.5)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = images[index[2]].permute(1, 2, 0)\n",
    "# 绘制图像\n",
    "plt.figure(figsize=(1,1))\n",
    "plt.imshow(image)\n",
    "plt.axis('off')  # 关闭坐标轴\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "40f512be",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 100x100 with 0 Axes>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.5921569..0.9843137].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2220f54e1b0>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(-0.5, 31.5, 31.5, -0.5)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = images[index[3]].permute(1, 2, 0)\n",
    "# 绘制图像\n",
    "plt.figure(figsize=(1,1))\n",
    "plt.imshow(image)\n",
    "plt.axis('off')  # 关闭坐标轴\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109a0603",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de24e389",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d67ccaa4",
   "metadata": {},
   "source": [
    "##### Cutout，训练时把图像的一部分减掉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf2ad2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = r'../data'\n",
    "batch_size = 512\n",
    "train_loader,test_loader = get_cifar10(root_dir, batch_size = 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "297a22e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "class Cutout(object):\n",
    "    \"\"\"\n",
    "    Randomly mask out one or more patches from an image.\n",
    "    Args:\n",
    "        n_holes (int): Number of patches to cut out of each image.\n",
    "        length (int): The length (in pixels) of each square patch.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_holes, length):\n",
    "        self.n_holes = n_holes\n",
    "        self.length = length\n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (Tensor): Tensor image of size (C, H, W).\n",
    "        Returns:\n",
    "            Tensor: Image with n_holes of dimension length x length cut out of it.\n",
    "        \"\"\"\n",
    "        h = img.size(1)\n",
    "        w = img.size(2)\n",
    "        mask = np.ones((h, w), np.float32)\n",
    "        for n in range(self.n_holes):\n",
    "            y = np.random.randint(h)  # 在 0到h之间产生一个随机整数\n",
    "            x = np.random.randint(w)\n",
    "            y1 = np.clip(y - self.length // 2, 0, h) # 确保y1在0到y之间，下同\n",
    "            y2 = np.clip(y + self.length // 2, 0, h)\n",
    "            x1 = np.clip(x - self.length // 2, 0, w)\n",
    "            x2 = np.clip(x + self.length // 2, 0, w)\n",
    "            mask[y1: y2, x1: x2] = 0.  # 将这部分图像的像素置为0\n",
    "            mask = torch.from_numpy(mask) # NumPy 数组转换为 PyTorch 张量 (tensor)\n",
    "            mask = mask.expand_as(img) # mask 张量的形状扩展为与 img 张量相同的形状\n",
    "            img = img * mask # 执行逐元素乘法操作，即将两个张量 img 和 mask 中对应位置的元素相乘\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fcb7a3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 3, 32, 32])\n",
      "torch.Size([512])\n"
     ]
    }
   ],
   "source": [
    "# for image,y in train_loader:\n",
    "#     print(image.shape)\n",
    "#     print(y.shape)\n",
    "#     break\n",
    "# length = 10\n",
    "# h = image[0].size(1)\n",
    "# w = image[0].size(2)\n",
    "# mask = np.ones((h, w), np.float32)\n",
    "# print(mask.shape)\n",
    "# y = np.random.randint(h)  # 在 0到h之间产生一个随机整数\n",
    "# x = np.random.randint(w)\n",
    "# y1 = np.clip(y - length // 2, 0, h) # 确保y1在0到y之间，下同\n",
    "# y2 = np.clip(y + length // 2, 0, h)\n",
    "# x1 = np.clip(x - length // 2, 0, w)\n",
    "# x2 = np.clip(x + length // 2, 0, w)\n",
    "# mask[y1: y2, x1: x2] = 0.  # 将这部分图像的像素置为0\n",
    "# mask = torch.from_numpy(mask) # NumPy 数组转换为 PyTorch 张量 (tensor)\n",
    "# mask = mask.expand_as(image[0]) # mask 张量的形状扩展为与 img 张量相同的形状\n",
    "# print(mask.shape) \n",
    "# img = img * mask  # 执行逐元素乘法操作，即将两个张量 img 和 mask 中对应位置的元素相乘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ca6ff6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0698a72",
   "metadata": {},
   "source": [
    "##### Random erasing  \n",
    "cutout是把图片中随机抽中的矩形区域的像素值置为0，相当于裁剪掉，random erasing是用随机数或者数据集中像素的平均值替换原来的像素值。而且，cutout每次裁剪掉的区域大小是固定的，Random erasing替换掉的区域大小是随机的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c71e13d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomErasing(object):\n",
    "    '''\n",
    "    probability: The probability that the operation will be performed.\n",
    "    sl: min erasing area\n",
    "    sh: max erasing area\n",
    "    r1: min aspect ratio 最小高宽比，一般指的是宽高比\n",
    "    mean: erasing value\n",
    "    '''\n",
    "    def __init__(self, probability = 0.5, sl = 0.02, sh = 0.4, r1 = 0.3, mean=[0.4914, 0.4822, 0.4465]):\n",
    "        self.probability = probability\n",
    "        self.mean = mean\n",
    "        self.sl = sl\n",
    "        self.sh = sh\n",
    "        self.r1 = r1\n",
    "    def __call__(self, img):\n",
    "        if random.uniform(0, 1) > self.probability:\n",
    "            return img\n",
    "        for attempt in range(100):\n",
    "            # 总区域大小\n",
    "            area = img.size()[1] * img.size()[2]\n",
    "            # 目标区域大小  比例*总区域大小\n",
    "            target_area = random.uniform(self.sl, self.sh) * area\n",
    "            # 让高宽比在 这两个值之间\n",
    "            aspect_ratio = random.uniform(self.r1, 1/self.r1)\n",
    "            # 擦除区域的高\n",
    "            h = int(round(math.sqrt(target_area * aspect_ratio)))\n",
    "            # 擦除区域的宽\n",
    "            w = int(round(math.sqrt(target_area / aspect_ratio)))\n",
    "            # 挑选擦除区域 高和宽的 起始点\n",
    "            if w < img.size()[2] and h < img.size()[1]:\n",
    "                # 高的起始点\n",
    "                x1 = random.randint(0, img.size()[1] - h)\n",
    "                # 宽的起始点\n",
    "                y1 = random.randint(0, img.size()[2] - w)\n",
    "                # 如果图像是三通道\n",
    "                if img.size()[0] == 3:\n",
    "                    img[0, x1:x1+h, y1:y1+w] = self.mean[0]\n",
    "                    img[1, x1:x1+h, y1:y1+w] = self.mean[1]\n",
    "                    img[2, x1:x1+h, y1:y1+w] = self.mean[2]\n",
    "                # 图像是单通道\n",
    "                else:\n",
    "                    img[0, x1:x1+h, y1:y1+w] = self.mean[0]\n",
    "                # 返回擦除的图像\n",
    "                return img\n",
    "        # 尝试100次都没有找到需要擦除的图像后就返回原图像\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cd9bd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d598cb4d",
   "metadata": {},
   "source": [
    "##### mixup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e40802",
   "metadata": {},
   "outputs": [],
   "source": [
    "for(images, labels) in train_loader:\n",
    "    l = np.random.beta(mixup_alpha, mixup_alpha)\n",
    "    index = torch.randperm(images.size(0))\n",
    "    images_a, images_b = images, images[index]\n",
    "    labels_a, labels_b = labels, labels[index]\n",
    "    mixed_images = l * images_a + (1- l) * images_b\n",
    "    outputs = model(mixed_images)\n",
    "    loss = l * criterion(outputs, labels_a) + (1- l) * criterion(outputs, labels_b)\n",
    "    acc = l * accuracy(outputs, labels_a)[0] + (1- l) * accuracy(outputs, labels_b)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac526f18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e5bac0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95e3f720",
   "metadata": {},
   "source": [
    "##### ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1928a835",
   "metadata": {},
   "source": [
    "## 汇总 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbee7575",
   "metadata": {},
   "outputs": [],
   "source": [
    "from start1 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7406a2a5",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f73fc12",
   "metadata": {},
   "source": [
    "#### 1. 数据集读取  \n",
    "基本不使用transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcfab9d",
   "metadata": {},
   "source": [
    "DVS128Gesture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "05da246e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集获取   DVS128Gesture 11种类别，分别包含：Swipe left  Swipe right  Swipe up   Swipe down   Circle left   Circle right   Tap\n",
    "# Double tap    Forward     Backward    Stop\n",
    "def get_dvs128Gesture(data_path = r'../data/DVS128Gesture', batch_size = 16, T = 20):\n",
    "    train_set = DVS128Gesture(root=data_path, train=True, data_type='frame', frames_number=T, split_by='number')\n",
    "    test_set = DVS128Gesture(root=data_path, train=False, data_type='frame', frames_number=T, split_by='number')\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "    return train_loader,test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "711b46bf",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The directory [../data/DVS128Gesture\\frames_number_20_split_by_number] already exists.\n",
      "The directory [../data/DVS128Gesture\\frames_number_20_split_by_number] already exists.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader,test_loader = get_dvs128Gesture()\n",
    "len(train_loader)\n",
    "len(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011f6752",
   "metadata": {},
   "source": [
    "CIFAR10DVS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "42de9c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集获取  CIFAR10DVS  10个类别\n",
    "def get_cifar10dvs(train_path = r'../data/CIFAR10DVS/split/t20/train0.8.pth', \n",
    "                   test_path = r'../data/CIFAR10DVS/split/t20/test0.2.pth',\n",
    "                   batch_size = 64, T = 20):\n",
    "    train_set = torch.load(train_path, weights_only=False)\n",
    "    test_set = torch.load(test_path, weights_only=False)\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "    return train_loader,test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef1a9487",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader,test_loader = get_cifar10dvs()\n",
    "len(train_loader)\n",
    "len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0894bef4",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 20, 2, 128, 128])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "           [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "          [[1., 2., 1.,  ..., 1., 2., 1.],\n",
       "           [2., 1., 2.,  ..., 2., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 2., 1.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "           [1., 1., 0.,  ..., 0., 0., 1.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 1.,  ..., 0., 1., 0.],\n",
       "           [1., 2., 0.,  ..., 0., 0., 1.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 1.]]],\n",
       "\n",
       "\n",
       "         [[[0., 1., 1.,  ..., 0., 0., 0.],\n",
       "           [1., 0., 0.,  ..., 0., 0., 1.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [1., 0., 1.,  ..., 0., 0., 0.],\n",
       "           [0., 1., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "          [[1., 2., 1.,  ..., 0., 0., 0.],\n",
       "           [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "           [1., 0., 1.,  ..., 0., 0., 0.],\n",
       "           [0., 1., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "         ...,\n",
       "\n",
       "\n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 1.,  ..., 0., 0., 0.]],\n",
       "\n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 1.]],\n",
       "\n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[0., 0., 1.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 1., 1.],\n",
       "           [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [2., 0., 2.,  ..., 0., 1., 1.],\n",
       "           [1., 0., 0.,  ..., 1., 2., 2.],\n",
       "           [0., 1., 1.,  ..., 1., 1., 1.]],\n",
       "\n",
       "          [[0., 0., 2.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 1., 1.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [2., 1., 1.,  ..., 0., 0., 0.],\n",
       "           [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "           [0., 1., 1.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "         [[[0., 0., 1.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 1., 1., 4.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 1., 1., 1.],\n",
       "           [0., 0., 0.,  ..., 1., 0., 1.],\n",
       "           [0., 0., 0.,  ..., 1., 1., 1.]],\n",
       "\n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 1., 1., 5.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [1., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "         [[[0., 0., 0.,  ..., 0., 1., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 2., 0., 0.]],\n",
       "\n",
       "          [[0., 0., 0.,  ..., 0., 1., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 1., 1.],\n",
       "           [1., 0., 0.,  ..., 1., 0., 1.],\n",
       "           [0., 0., 0.,  ..., 4., 2., 1.]]],\n",
       "\n",
       "\n",
       "         ...,\n",
       "\n",
       "\n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "           [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 2., 1., 2.],\n",
       "           [0., 0., 0.,  ..., 1., 1., 1.],\n",
       "           [0., 0., 0.,  ..., 2., 1., 1.]],\n",
       "\n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "           [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 1., 0., 0.]]],\n",
       "\n",
       "\n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 2., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 2.]],\n",
       "\n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 2., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 1.]]],\n",
       "\n",
       "\n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "           [0., 0., 0.,  ..., 0., 1., 1.],\n",
       "           [0., 0., 0.,  ..., 0., 1., 0.]],\n",
       "\n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 1., 2., 2.],\n",
       "           [0., 0., 0.,  ..., 1., 2., 2.],\n",
       "           [0., 0., 1.,  ..., 1., 1., 1.]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[0., 1., 2.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 0., 0.],\n",
       "           [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [2., 0., 1.,  ..., 1., 1., 1.],\n",
       "           [0., 0., 2.,  ..., 1., 2., 1.],\n",
       "           [2., 3., 3.,  ..., 1., 2., 2.]],\n",
       "\n",
       "          [[0., 0., 0.,  ..., 1., 1., 1.],\n",
       "           [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "           ...,\n",
       "           [2., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "         [[[2., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [0., 1., 0.,  ..., 1., 1., 3.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [1., 1., 1.,  ..., 2., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 0., 1., 0.],\n",
       "           [1., 1., 1.,  ..., 0., 1., 0.]],\n",
       "\n",
       "          [[0., 1., 2.,  ..., 2., 1., 1.],\n",
       "           [0., 1., 0.,  ..., 1., 1., 4.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 1., 1., 1.],\n",
       "           [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 2., 1.]]],\n",
       "\n",
       "\n",
       "         [[[1., 1., 2.,  ..., 1., 0., 0.],\n",
       "           [1., 1., 3.,  ..., 0., 0., 0.],\n",
       "           [0., 1., 1.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 1.,  ..., 1., 0., 1.],\n",
       "           [0., 0., 0.,  ..., 0., 3., 2.],\n",
       "           [0., 1., 0.,  ..., 2., 0., 1.]],\n",
       "\n",
       "          [[2., 1., 1.,  ..., 0., 0., 0.],\n",
       "           [2., 1., 3.,  ..., 0., 0., 1.],\n",
       "           [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 1.,  ..., 2., 2., 3.],\n",
       "           [0., 0., 1.,  ..., 1., 4., 4.],\n",
       "           [0., 2., 1.,  ..., 3., 2., 2.]]],\n",
       "\n",
       "\n",
       "         ...,\n",
       "\n",
       "\n",
       "         [[[0., 0., 1.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [1., 0., 0.,  ..., 0., 1., 1.],\n",
       "           [3., 1., 1.,  ..., 1., 0., 0.],\n",
       "           [0., 0., 1.,  ..., 0., 0., 0.]],\n",
       "\n",
       "          [[0., 1., 1.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [1., 1., 0.,  ..., 0., 0., 0.],\n",
       "           [3., 2., 2.,  ..., 1., 0., 0.],\n",
       "           [1., 2., 2.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "         [[[0., 0., 1.,  ..., 1., 1., 0.],\n",
       "           [2., 0., 0.,  ..., 1., 1., 0.],\n",
       "           [2., 0., 1.,  ..., 0., 1., 0.],\n",
       "           ...,\n",
       "           [0., 0., 1.,  ..., 1., 2., 1.],\n",
       "           [1., 0., 0.,  ..., 1., 1., 2.],\n",
       "           [0., 0., 0.,  ..., 4., 2., 2.]],\n",
       "\n",
       "          [[1., 0., 1.,  ..., 0., 0., 0.],\n",
       "           [2., 0., 1.,  ..., 0., 0., 0.],\n",
       "           [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "           [2., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [1., 1., 0.,  ..., 3., 0., 0.]]],\n",
       "\n",
       "\n",
       "         [[[1., 1., 1.,  ..., 0., 1., 0.],\n",
       "           [1., 1., 1.,  ..., 1., 0., 0.],\n",
       "           [0., 2., 1.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 1., 1., 1.],\n",
       "           [1., 0., 1.,  ..., 1., 2., 1.],\n",
       "           [1., 1., 2.,  ..., 1., 1., 1.]],\n",
       "\n",
       "          [[0., 0., 0.,  ..., 1., 1., 0.],\n",
       "           [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 1.,  ..., 0., 0., 0.]]]],\n",
       "\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "\n",
       "        [[[[1., 0., 1.,  ..., 0., 1., 0.],\n",
       "           [1., 1., 0.,  ..., 1., 1., 1.],\n",
       "           [0., 0., 1.,  ..., 0., 0., 1.],\n",
       "           ...,\n",
       "           [1., 1., 0.,  ..., 1., 1., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 1., 2.],\n",
       "           [1., 1., 0.,  ..., 1., 0., 1.]],\n",
       "\n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "           ...,\n",
       "           [2., 1., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [1., 1., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "           ...,\n",
       "           [2., 1., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [2., 1., 1.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "         ...,\n",
       "\n",
       "\n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 1., 0.]],\n",
       "\n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 1., 0.]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[0., 0., 1.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 1., 1., 1.],\n",
       "           [1., 0., 0.,  ..., 2., 2., 2.]],\n",
       "\n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 1., 1.],\n",
       "           [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 1.,  ..., 0., 0., 0.]],\n",
       "\n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "           ...,\n",
       "           [0., 0., 1.,  ..., 0., 1., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 1., 0., 0.]],\n",
       "\n",
       "          [[0., 0., 2.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "           [0., 0., 0.,  ..., 1., 0., 0.]]],\n",
       "\n",
       "\n",
       "         ...,\n",
       "\n",
       "\n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "           [0., 0., 0.,  ..., 2., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 1., 0., 1.]],\n",
       "\n",
       "          [[0., 0., 0.,  ..., 1., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "         [[[0., 0., 0.,  ..., 1., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 4., 0.]],\n",
       "\n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 4., 0.]]],\n",
       "\n",
       "\n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 1., 4.]],\n",
       "\n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 1., 1.],\n",
       "           [0., 0., 0.,  ..., 1., 1., 1.],\n",
       "           [0., 0., 0.,  ..., 1., 2., 5.]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[0., 1., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 2.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [2., 2., 2.,  ..., 1., 1., 1.],\n",
       "           [1., 2., 2.,  ..., 1., 1., 1.]],\n",
       "\n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "         [[[1., 0., 1.,  ..., 1., 2., 1.],\n",
       "           [1., 0., 1.,  ..., 1., 0., 1.],\n",
       "           [1., 1., 1.,  ..., 0., 1., 1.],\n",
       "           ...,\n",
       "           [1., 2., 1.,  ..., 0., 0., 1.],\n",
       "           [0., 0., 1.,  ..., 0., 0., 1.],\n",
       "           [1., 0., 0.,  ..., 0., 0., 1.]],\n",
       "\n",
       "          [[0., 0., 0.,  ..., 0., 1., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "         [[[0., 0., 0.,  ..., 1., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "           [0., 0., 0.,  ..., 5., 1., 1.]],\n",
       "\n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 1., 1., 1.],\n",
       "           [0., 0., 0.,  ..., 5., 1., 1.]]],\n",
       "\n",
       "\n",
       "         ...,\n",
       "\n",
       "\n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 2., 0., 2.],\n",
       "           [0., 0., 0.,  ..., 0., 1., 5.]],\n",
       "\n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 2., 1., 2.],\n",
       "           [0., 0., 0.,  ..., 1., 2., 6.]]],\n",
       "\n",
       "\n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 1.]],\n",
       "\n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 2.]]],\n",
       "\n",
       "\n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "           [0., 0., 0.,  ..., 0., 1., 0.]],\n",
       "\n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]]]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# datas = iter(train_loader)\n",
    "# a,b = next(datas)\n",
    "# a.shape\n",
    "# a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c6e60a",
   "metadata": {},
   "source": [
    "NMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2d3be61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集获取   NMNIST  10个类别\n",
    "def get_nmnist(data_path = r'../data/NMNIST', batch_size = 512, T = 20):\n",
    "    train_set = NMNIST(root=data_path, train=True, data_type='frame', frames_number=T, split_by='number')\n",
    "    test_set = NMNIST(root=data_path, train=False, data_type='frame', frames_number=T, split_by='number')\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "    return train_loader,test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ddf00385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The directory [../data/NMNIST\\frames_number_20_split_by_number] already exists.\n",
      "The directory [../data/NMNIST\\frames_number_20_split_by_number] already exists.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader,test_loader = get_nmnist()\n",
    "len(train_loader)\n",
    "len(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6493600d",
   "metadata": {},
   "source": [
    "NCaltech101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "675aead0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集获取  NCaltech101    包含 101 个类别。这些类别主要是不同的物体，如动物、植物、物品等。\n",
    "def get_NCaltech101(train_path = r'../data/NCaltech101/split/t20/train0.8.pth', \n",
    "                   test_path = r'../data/NCaltech101/split/t20/test0.2.pth',\n",
    "                   batch_size = 64, T = 20):\n",
    "    train_set = torch.load(train_path, weights_only=False)\n",
    "    test_set = torch.load(test_path, weights_only=False)\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "    return train_loader,test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c7fe2632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader,test_loader = get_NCaltech101()\n",
    "len(train_loader)\n",
    "len(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffca0bea",
   "metadata": {},
   "source": [
    "MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "04406205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集获取  MNIST   10个类别\n",
    "def get_mnist(data_path = r'../data', batch_size = 512):\n",
    "    # Define a transform\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=1),  # 将图像转为灰度\n",
    "        transforms.ToTensor(),  # 将图像转为张量\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "\n",
    "    mnist_train = datasets.MNIST(data_path, train=True, download=False, transform=transform)\n",
    "    mnist_test = datasets.MNIST(data_path, train=False, download=False, transform=transform)\n",
    "\n",
    "    train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "    \n",
    "    return train_loader,test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "533f71a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader,test_loader = get_mnist()\n",
    "len(train_loader)\n",
    "len(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781fe081",
   "metadata": {},
   "source": [
    "Cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a2726cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集获取  Cifar10   10个类别\n",
    "def get_cifar10(data_path = r'../data', batch_size = 512):\n",
    "    # 定义数据变换\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),  # 将图片转换为Tensor\n",
    "         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])  # 归一化\n",
    "    trainset=datasets.CIFAR10(root=data_path,train=True,download=False,transform=transform)\n",
    "    testset=datasets.CIFAR10(root=data_path,train=False,download=False,transform=transform)\n",
    "    train_loader=torch.utils.data.DataLoader(trainset,batch_size=batch_size,shuffle=True,drop_last=True,\n",
    "                                            pin_memory=True, persistent_workers = True, num_workers = 1)\n",
    "    test_loader=torch.utils.data.DataLoader(testset,batch_size=batch_size,shuffle=False,drop_last=True,\n",
    "                                           pin_memory=True, persistent_workers = True, num_workers = 1)\n",
    "    return train_loader,test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b5d97390",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader,test_loader = get_cifar10()\n",
    "len(train_loader)\n",
    "len(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a737f6",
   "metadata": {},
   "source": [
    "cifar100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e2b44150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集获取  cifar100   100个类别\n",
    "def get_cifar100(data_path = r'../data', batch_size = 512):\n",
    "    # 定义数据变换\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),  # 将图片转换为Tensor\n",
    "         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])  # 归一化\n",
    "    # 下载CIFAR10数据集\n",
    "    # #训练集\n",
    "    trainset=datasets.CIFAR100(root=data_path,train=True,download=False,transform=transform)\n",
    "    # 测试集\n",
    "    testset=datasets.CIFAR100(root=data_path,train=False,download=False,transform=transform)\n",
    "\n",
    "    #练习集 封装成DataLoader的形式 batch_size 按照批次传 shuffle 将数据打散 num_workers 线程\n",
    "    # 创建DataLoader对象\n",
    "    train_loader=torch.utils.data.DataLoader(trainset,batch_size=batch_size,shuffle=True,drop_last=True,\n",
    "                                            pin_memory=True, persistent_workers = True, num_workers = 1)\n",
    "    test_loader=torch.utils.data.DataLoader(testset,batch_size=batch_size,shuffle=False,drop_last=True,\n",
    "                                           pin_memory=True, persistent_workers = True, num_workers = 1)\n",
    "\n",
    "    return train_loader,test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "595a4a65",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader,test_loader = get_cifar100()\n",
    "len(train_loader)\n",
    "len(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdba2b2",
   "metadata": {},
   "source": [
    "imagenet1k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fb105984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集获取  imagenet_1k   1000个类别\n",
    "def get_imagenet(data_path = r'../data/Imagenet2012/imagenet', batch_size = 32):\n",
    "    \n",
    "    traindir = os.path.join(data_path, 'train')\n",
    "    valdir = os.path.join(data_path, 'val')\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "\n",
    "    train_dataset = datasets.ImageFolder(\n",
    "        traindir,\n",
    "        transforms.Compose([\n",
    "            transforms.RandomResizedCrop(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]))\n",
    "\n",
    "    val_dataset = datasets.ImageFolder(\n",
    "        valdir,\n",
    "        transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]))\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,shuffle=True,drop_last = True,\n",
    "                                               pin_memory=True, persistent_workers = True, num_workers = 1)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size,shuffle=False,drop_last = True,\n",
    "                                             pin_memory=True, persistent_workers = True, num_workers = 1)\n",
    "    return train_loader,val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "82d2696f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40036"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1562"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.335187673568726\n"
     ]
    }
   ],
   "source": [
    "# num_workers = 2 或 4 速度差不多，均为8.2s左右\n",
    "start = time.time()\n",
    "train_loader,test_loader = get_imagenet()\n",
    "len(train_loader)\n",
    "len(test_loader)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead1c48b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f87f4cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787cdb9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cee2c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b2f43d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from start1 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d29a963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集获取   DVS128Gesture 11种类别，分别包含：Swipe left  Swipe right  Swipe up   Swipe down   Circle left   Circle right   Tap\n",
    "# Double tap    Forward     Backward    Stop\n",
    "def get_dvs128Gesture(data_path = r'../data/DVS128Gesture', batch_size = 16, T = 20):\n",
    "    train_set = DVS128Gesture(root=data_path, train=True, data_type='frame', frames_number=T, split_by='number')\n",
    "    test_set = DVS128Gesture(root=data_path, train=False, data_type='frame', frames_number=T, split_by='number')\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "    return train_loader,test_loader\n",
    "\n",
    "# 数据集获取  CIFAR10DVS  10个类别\n",
    "def get_cifar10dvs(train_path = r'../data/CIFAR10DVS/split/t20/train0.8.pth', \n",
    "                   test_path = r'../data/CIFAR10DVS/split/t20/test0.2.pth',\n",
    "                   batch_size = 64, T = 20):\n",
    "    train_set = torch.load(train_path, weights_only=False)\n",
    "    test_set = torch.load(test_path, weights_only=False)\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "    return train_loader,test_loader\n",
    "\n",
    "# 数据集获取   NMNIST  10个类别\n",
    "def get_nmnist(data_path = r'../data/NMNIST', batch_size = 512, T = 20):\n",
    "    train_set = NMNIST(root=data_path, train=True, data_type='frame', frames_number=T, split_by='number')\n",
    "    test_set = NMNIST(root=data_path, train=False, data_type='frame', frames_number=T, split_by='number')\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "    return train_loader,test_loader\n",
    "\n",
    "# 数据集获取  NCaltech101    包含 101 个类别。这些类别主要是不同的物体，如动物、植物、物品等。\n",
    "def get_NCaltech101(train_path = r'../data/NCaltech101/split/t20/train0.8.pth', \n",
    "                   test_path = r'../data/NCaltech101/split/t20/test0.2.pth',\n",
    "                   batch_size = 64, T = 20):\n",
    "    train_set = torch.load(train_path, weights_only=False)\n",
    "    test_set = torch.load(test_path, weights_only=False)\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "    return train_loader,test_loader\n",
    "\n",
    "# 数据集获取  MNIST   10个类别\n",
    "def get_mnist(data_path = r'../data', batch_size = 512):\n",
    "    # Define a transform\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=1),  # 将图像转为灰度\n",
    "        transforms.ToTensor(),  # 将图像转为张量\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "\n",
    "    mnist_train = datasets.MNIST(data_path, train=True, download=False, transform=transform)\n",
    "    mnist_test = datasets.MNIST(data_path, train=False, download=False, transform=transform)\n",
    "\n",
    "    train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "    \n",
    "    return train_loader,test_loader\n",
    "\n",
    "# 数据集获取  Cifar10   10个类别\n",
    "def get_cifar10(data_path = r'../data', batch_size = 512):\n",
    "    # 定义数据变换\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),  # 将图片转换为Tensor\n",
    "         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])  # 归一化\n",
    "    trainset=datasets.CIFAR10(root=data_path,train=True,download=False,transform=transform)\n",
    "    testset=datasets.CIFAR10(root=data_path,train=False,download=False,transform=transform)\n",
    "    train_loader=torch.utils.data.DataLoader(trainset,batch_size=batch_size,shuffle=True,drop_last=True,\n",
    "                                            pin_memory=True, persistent_workers = True, num_workers = 1)\n",
    "    test_loader=torch.utils.data.DataLoader(testset,batch_size=batch_size,shuffle=False,drop_last=True,\n",
    "                                           pin_memory=True, persistent_workers = True, num_workers = 1)\n",
    "    return train_loader,test_loader\n",
    "\n",
    "# 数据集获取  cifar100   100个类别\n",
    "def get_cifar100(data_path = r'../data', batch_size = 512):\n",
    "    # 定义数据变换\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),  # 将图片转换为Tensor\n",
    "         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])  # 归一化\n",
    "    # 下载CIFAR10数据集\n",
    "    # #训练集\n",
    "    trainset=datasets.CIFAR100(root=data_path,train=True,download=False,transform=transform)\n",
    "    # 测试集\n",
    "    testset=datasets.CIFAR100(root=data_path,train=False,download=False,transform=transform)\n",
    "\n",
    "    #练习集 封装成DataLoader的形式 batch_size 按照批次传 shuffle 将数据打散 num_workers 线程\n",
    "    # 创建DataLoader对象\n",
    "    train_loader=torch.utils.data.DataLoader(trainset,batch_size=batch_size,shuffle=True,drop_last=True,\n",
    "                                            pin_memory=True, persistent_workers = True, num_workers = 1)\n",
    "    test_loader=torch.utils.data.DataLoader(testset,batch_size=batch_size,shuffle=False,drop_last=True,\n",
    "                                           pin_memory=True, persistent_workers = True, num_workers = 1)\n",
    "\n",
    "    return train_loader,test_loader\n",
    "\n",
    "# 数据集获取  imagenet_1k   1000个类别\n",
    "def get_imagenet(data_path = r'../data/Imagenet2012/imagenet', batch_size = 32):\n",
    "    \n",
    "    traindir = os.path.join(data_path, 'train')\n",
    "    valdir = os.path.join(data_path, 'val')\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "\n",
    "    train_dataset = datasets.ImageFolder(\n",
    "        traindir,\n",
    "        transforms.Compose([\n",
    "            transforms.RandomResizedCrop(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]))\n",
    "\n",
    "    val_dataset = datasets.ImageFolder(\n",
    "        valdir,\n",
    "        transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]))\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,shuffle=True,drop_last = True,\n",
    "                                               pin_memory=True, persistent_workers = True, num_workers = 1)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size,shuffle=False,drop_last = True,\n",
    "                                             pin_memory=True, persistent_workers = True, num_workers = 1)\n",
    "    return train_loader,val_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc40f48",
   "metadata": {},
   "source": [
    "#### 2 数据集训练"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4c9194",
   "metadata": {},
   "source": [
    "cifar10DVS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "622fe397",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = r'../data/CIFAR10DVS'\n",
    "T = 20 # 对于非DVS执行的时间步，该数据集在划分的时候默认为5\n",
    "batch_size=64\n",
    "lr=1e-2\n",
    "weight_decay = 1e-5\n",
    "warmup = True\n",
    "num_epochs = 5\n",
    "warmup_epochs = 2\n",
    "num_classes = 10\n",
    "inp_channels = 2  # DVS系列的数据集貌似都是2\n",
    "data_type = 1 # 0表示数据没有时间维度，1表示数据有时间维度\n",
    "if_lrsche = 1  # 是否使用学习率调度策略\n",
    "T_data = 0 # 该参数轻易不用，一般的，数据中没有时间步，网络中也会自动添加时间步\n",
    "\n",
    "train_loader,test_loader = get_cifar10dvs()\n",
    "\n",
    "# 设备选择使用GPU   数据的维度  B, T , 2, 128, 128\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "net = sew_resnet18(input_channels = inp_channels,num_classes = num_classes, connect_f = 'ADD',T = T, data_type = data_type).to(device)\n",
    "# (block, layers, input_channels = 3, num_classes=1000, zero_init_residual=False,groups=1, \n",
    "#  width_per_group=64, replace_stride_with_dilation=None,norm_layer=None, T=4, connect_f=None, \n",
    "#  drops = [0,0,0,0], p = [0.5,0.5,0.5,0.5], data_type = 0, net_type = 0)\n",
    "\n",
    "# # 使用Adam优化器\n",
    "# optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "# # 学习率优化\n",
    "# lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epochs)\n",
    "\n",
    "pg = get_params_groups(net, weight_decay=weight_decay)  # 进行了简单分组的权重 确定了哪些参数需要权重衰减，哪些不需要\n",
    "optimizer = optim.AdamW(pg, lr=lr, weight_decay=weight_decay)\n",
    "lr_scheduler = create_lr_scheduler(optimizer, len(train_loader), num_epochs,\n",
    "                                   warmup=warmup, warmup_epochs=warmup_epochs)\n",
    "\n",
    "# loss_function = nn.CrossEntropyLoss()\n",
    "loss_function = F.mse_loss\n",
    "\n",
    "# scaler = None\n",
    "scaler = amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076a2848",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accs,train_losss,test_accs,test_losss = trains(num_epochs, net, train_loader,\n",
    "        test_loader, optimizer, device, loss_function, scaler = scaler, \n",
    "        encoder = encoding.PoissonEncoder(), T = T_data, num_classes = num_classes, \n",
    "        data_type = data_type, save_model = \"./save_models/test_cifar10DVS.pt\", lr_scheduler = lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c510647f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56f8704",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e206225",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc97e615",
   "metadata": {},
   "source": [
    "#### 3 重新更改训练函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb550029",
   "metadata": {},
   "source": [
    "将所有超参数使用函数进行包装,依然是使用 CIFAR10DVS 进行训练  \n",
    "注意只有CIFAR10DVS 和 NCaltech10 这两个数据集 需要手动划分 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a470cb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from start2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9f4ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NCaltech101数据集的手动划分\n",
    "# data_path = r'../data/NCaltech101'\n",
    "# T = 20\n",
    "# num_classes = 101\n",
    "# data = NCaltech101(root=data_path, data_type='frame', frames_number=T, split_by='number')\n",
    "\n",
    "# train_set, test_set = sptt(train_ratio = 0.8,origin_dataset = data,num_classes = num_classes,random_split =True)\n",
    "# torch.save(train_set, r'../data/NCaltech101/split/t20/train0.8.pth')\n",
    "# torch.save(test_set, r'../data/NCaltech101/split/t20/test0.2.pth')\n",
    "# train_data = torch.load(r'../data/NCaltech101/split/t20/train0.8.pth')\n",
    "# test_set = torch.load(r'../data/NCaltech101/split/t20/test0.2.pth')\n",
    "# print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea926e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # CIFAR10DVS数据集的手动划分\n",
    "# data_path = r'../data/CIFAR10DVS'\n",
    "# T = 20\n",
    "# num_classes = 10\n",
    "# data = CIFAR10DVS(root = data_path, data_type='frame', frames_number=T, split_by='number')\n",
    "\n",
    "# train_set, test_set = sptt(train_ratio = 0.8,origin_dataset = data,num_classes = num_classes,random_split = False)\n",
    "# torch.save(train_set, r'../data/CIFAR10DVS/split/t20/train0.8.pth')\n",
    "# torch.save(test_set, r'../data/CIFAR10DVS/split/t20/test0.2.pth')\n",
    "# train_data = torch.load(r'../data/CIFAR10DVS/split/t20/train0.8.pth')\n",
    "# test_data = torch.load(r'../data/CIFAR10DVS/split/t20/test0.2.pth')\n",
    "# print(len(train_data), len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54733b26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7b19ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38cf15a3",
   "metadata": {},
   "source": [
    "各个数据集的获取方式，包括4个DVS数据集，4个静态图片数据集  \n",
    "nmnist，NCaltech101，dvs128Gesture，cifar10dvs，mnist，cifar10，cifar100，imagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5eee8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from start2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f10949a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 数据集获取   NMNIST  10个类别\n",
    "# def get_nmnist_2(batch_size = 16, num_workers = 4, T = 20,\n",
    "#                data_path = r'E:\\mycode\\jupyter\\0.SNN\\data\\NMNIST',\n",
    "#               ):\n",
    "#     train_set = NMNIST(root=data_path, train=True, data_type='frame', frames_number=T, split_by='number')\n",
    "#     test_set = NMNIST(root=data_path, train=False, data_type='frame', frames_number=T, split_by='number')\n",
    "#     train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, \n",
    "#                               drop_last=True,num_workers=num_workers,pin_memory=True,persistent_workers = True)\n",
    "#     test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, \n",
    "#                              drop_last=False,num_workers=num_workers,pin_memory=True,persistent_workers = True)\n",
    "#     return train_loader,test_loader\n",
    "\n",
    "# # 数据集获取  NCaltech101    包含 101 个类别。这些类别主要是不同的物体，如动物、植物、物品等。\n",
    "# def get_NCaltech101_2(batch_size = 16, num_workers = 4, T = 20,\n",
    "#                     train_path = r'E:\\mycode\\jupyter\\0.SNN\\data\\NCaltech101\\split\\t20\\train0.8.pth', \n",
    "#                     test_path = r'E:\\mycode\\jupyter\\0.SNN\\data\\NCaltech101\\split\\t20\\test0.2.pth',\n",
    "#                        ):\n",
    "#     train_set = torch.load(train_path, weights_only=False)\n",
    "#     test_set = torch.load(test_path, weights_only=False)\n",
    "#     train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, \n",
    "#                               drop_last=True,num_workers=num_workers,pin_memory=True,persistent_workers = True)\n",
    "#     test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, \n",
    "#                              drop_last=False,num_workers=num_workers,pin_memory=True,persistent_workers = True)\n",
    "#     return train_loader,test_loader\n",
    "\n",
    "# # 数据集获取   DVS128Gesture 11种类别，分别包含：Swipe left  Swipe right  Swipe up   Swipe down   Circle left   Circle right   Tap\n",
    "# # Double tap    Forward     Backward    Stop\n",
    "# def get_dvs128Gesture_2(batch_size = 16,num_workers = 4,T = 20,\n",
    "#                       data_path = r'E:\\mycode\\jupyter\\0.SNN\\data\\DVS128Gesture',\n",
    "#                      ):\n",
    "#     train_set = DVS128Gesture(root=data_path, train=True, data_type='frame', frames_number=T, split_by='number')\n",
    "#     test_set = DVS128Gesture(root=data_path, train=False, data_type='frame', frames_number=T, split_by='number')\n",
    "#     train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, \n",
    "#                               drop_last=True,num_workers=num_workers,pin_memory=True,persistent_workers = True)\n",
    "#     test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, \n",
    "#                              drop_last=False,num_workers=num_workers,pin_memory=True,persistent_workers = True)\n",
    "#     return train_loader,test_loader\n",
    "\n",
    "\n",
    "# def get_cifar10dvs_2(batch_size = 16,num_workers = 4,T = 20,\n",
    "#                    train_path = r'E:\\mycode\\jupyter\\0.SNN\\data\\CIFAR10DVS\\split\\t20\\train0.8.pth', \n",
    "#                    test_path = r'E:\\mycode\\jupyter\\0.SNN\\data\\CIFAR10DVS\\split\\t20\\test0.2.pth'):\n",
    "#     train_set = torch.load(train_path, weights_only=False)\n",
    "#     test_set = torch.load(test_path, weights_only=False)\n",
    "#     train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, \n",
    "#                               drop_last=True,num_workers=num_workers,pin_memory=True,persistent_workers = True)\n",
    "#     test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, \n",
    "#                              drop_last=False,num_workers=num_workers,pin_memory=True,persistent_workers = True)\n",
    "#     return train_loader,test_loader\n",
    "\n",
    "# # ---------------------------------------------各类不具有时间步的图像数据集-------------------------------------------------\n",
    "\n",
    "# # 数据集获取  MNIST   10个类别\n",
    "# def get_mnist_2(data_path = r'E:\\mycode\\jupyter\\0.SNN\\data', batch_size = 512,num_workers = 4, ):\n",
    "#     # Define a transform\n",
    "#     transform = transforms.Compose([\n",
    "#         transforms.Grayscale(num_output_channels=1),  # 将图像转为灰度\n",
    "#         transforms.ToTensor(),  # 将图像转为张量\n",
    "#         transforms.Normalize((0.1307,), (0.3081,))\n",
    "#         ])\n",
    "\n",
    "#     mnist_train = datasets.MNIST(data_path, train=True, download=False, transform=transform)\n",
    "#     mnist_test = datasets.MNIST(data_path, train=False, download=False, transform=transform)\n",
    "\n",
    "#     train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, \n",
    "#                               drop_last=True,num_workers=num_workers,pin_memory=True,persistent_workers = True)\n",
    "#     test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, \n",
    "#                              drop_last=False,num_workers=num_workers,pin_memory=True,persistent_workers = True)\n",
    "    \n",
    "#     return train_loader,test_loader\n",
    "\n",
    "# # 数据集获取  Cifar10   10个类别\n",
    "# def get_cifar10_2(data_path = r'E:\\mycode\\jupyter\\0.SNN\\data', batch_size = 512,num_workers = 4, ):\n",
    "#     # 定义数据变换\n",
    "#     transform = transforms.Compose(\n",
    "#         [transforms.ToTensor(),  # 将图片转换为Tensor\n",
    "#          transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])  # 归一化\n",
    "#     trainset=datasets.CIFAR10(root=data_path,train=True,download=False,transform=transform)\n",
    "#     testset=datasets.CIFAR10(root=data_path,train=False,download=False,transform=transform)\n",
    "#     train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, \n",
    "#                               drop_last=True,num_workers=num_workers,pin_memory=True,persistent_workers = True)\n",
    "#     test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, \n",
    "#                              drop_last=False,num_workers=num_workers,pin_memory=True,persistent_workers = True)\n",
    "#     return train_loader,test_loader\n",
    "\n",
    "# # 数据集获取  cifar100   100个类别\n",
    "# def get_cifar100_2(data_path = r'E:\\mycode\\jupyter\\0.SNN\\data', batch_size = 512,num_workers = 4, ):\n",
    "#     # 定义数据变换\n",
    "#     transform = transforms.Compose(\n",
    "#         [transforms.ToTensor(),  # 将图片转换为Tensor\n",
    "#          transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])  # 归一化\n",
    "#     # 下载CIFAR10数据集\n",
    "#     # #训练集\n",
    "#     trainset=datasets.CIFAR100(root=data_path,train=True,download=False,transform=transform)\n",
    "#     # 测试集\n",
    "#     testset=datasets.CIFAR100(root=data_path,train=False,download=False,transform=transform)\n",
    "\n",
    "#     #练习集 封装成DataLoader的形式 batch_size 按照批次传 shuffle 将数据打散 num_workers 线程\n",
    "#     # 创建DataLoader对象\n",
    "#     train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, \n",
    "#                               drop_last=True,num_workers=num_workers,pin_memory=True,persistent_workers = True)\n",
    "#     test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, \n",
    "#                              drop_last=False,num_workers=num_workers,pin_memory=True,persistent_workers = True)\n",
    "\n",
    "#     return train_loader,test_loader\n",
    "\n",
    "# # 数据集获取  imagenet_1k   1000个类别\n",
    "# def get_imagenet_2(data_path = r'E:\\mycode\\jupyter\\0.SNN\\data\\Imagenet2012\\imagenet', batch_size = 32，num_workers = 4, ):\n",
    "    \n",
    "#     traindir = os.path.join(data_path, 'train')\n",
    "#     valdir = os.path.join(data_path, 'val')\n",
    "#     normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "\n",
    "#     train_dataset = datasets.ImageFolder(\n",
    "#         traindir,\n",
    "#         transforms.Compose([\n",
    "#             transforms.RandomResizedCrop(224),\n",
    "#             transforms.RandomHorizontalFlip(),\n",
    "#             transforms.ToTensor(),\n",
    "#             normalize,\n",
    "#         ]))\n",
    "\n",
    "#     val_dataset = datasets.ImageFolder(\n",
    "#         valdir,\n",
    "#         transforms.Compose([\n",
    "#             transforms.Resize(256),\n",
    "#             transforms.CenterCrop(224),\n",
    "#             transforms.ToTensor(),\n",
    "#             normalize,\n",
    "#         ]))\n",
    "\n",
    "#     train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, \n",
    "#                               drop_last=True,num_workers=num_workers,pin_memory=True,persistent_workers = True)\n",
    "#     test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, \n",
    "#                              drop_last=False,num_workers=num_workers,pin_memory=True,persistent_workers = True)\n",
    "#     return train_loader,val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f10f27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ---------------------------------------------各类具有时间步的图像数据集-------------------------------------------------\n",
    "\n",
    "# # 数据集获取   NMNIST  10个类别\n",
    "# def get_nmnist(batch_size = 16, num_workers = 4, T = 20,\n",
    "#                data_path = r'../data/NMNIST',\n",
    "#               ):\n",
    "#     train_set = NMNIST(root=data_path, train=True, data_type='frame', frames_number=T, split_by='number')\n",
    "#     test_set = NMNIST(root=data_path, train=False, data_type='frame', frames_number=T, split_by='number')\n",
    "#     train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, \n",
    "#                               drop_last=True,num_workers=num_workers,pin_memory=True,persistent_workers = True)\n",
    "#     test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, \n",
    "#                              drop_last=False,num_workers=num_workers,pin_memory=True,persistent_workers = True)\n",
    "#     return train_loader,test_loader\n",
    "\n",
    "# # 数据集获取  NCaltech101    包含 101 个类别。这些类别主要是不同的物体，如动物、植物、物品等。\n",
    "# def get_NCaltech101(batch_size = 16, num_workers = 4, T = 20,\n",
    "#                     train_path = r'../data/NCaltech101/split/t20/train0.8.pth', \n",
    "#                     test_path = r'../data/NCaltech101/split/t20/test0.2.pth',\n",
    "#                        ):\n",
    "#     train_set = torch.load(train_path, weights_only=False)\n",
    "#     test_set = torch.load(test_path, weights_only=False)\n",
    "#     train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, \n",
    "#                               drop_last=True,num_workers=num_workers,pin_memory=True,persistent_workers = True)\n",
    "#     test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, \n",
    "#                              drop_last=False,num_workers=num_workers,pin_memory=True,persistent_workers = True)\n",
    "#     return train_loader,test_loader\n",
    "\n",
    "# # 数据集获取   DVS128Gesture 11种类别，分别包含：Swipe left  Swipe right  Swipe up   Swipe down   Circle left   Circle right   Tap\n",
    "# # Double tap    Forward     Backward    Stop\n",
    "# def get_dvs128Gesture(batch_size = 16,num_workers = 4,T = 20,\n",
    "#                       data_path = r'../data/DVS128Gesture',\n",
    "#                      ):\n",
    "#     train_set = DVS128Gesture(root=data_path, train=True, data_type='frame', frames_number=T, split_by='number')\n",
    "#     test_set = DVS128Gesture(root=data_path, train=False, data_type='frame', frames_number=T, split_by='number')\n",
    "#     train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, \n",
    "#                               drop_last=True,num_workers=num_workers,pin_memory=True,persistent_workers = True)\n",
    "#     test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, \n",
    "#                              drop_last=False,num_workers=num_workers,pin_memory=True,persistent_workers = True)\n",
    "#     return train_loader,test_loader\n",
    "\n",
    "# # 数据集获取  CIFAR10DVS  10个类别\n",
    "# def get_cifar10dvs(batch_size = 16,num_workers = 4,T = 20,\n",
    "#                    train_path = r'../data/CIFAR10DVS/split/t20/train0.8.pth', \n",
    "#                    test_path = r'../data/CIFAR10DVS/split/t20/test0.2.pth',\n",
    "#                    ):\n",
    "#     train_set = torch.load(train_path, weights_only=False)\n",
    "#     test_set = torch.load(test_path, weights_only=False)\n",
    "#     train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, \n",
    "#                               drop_last=True,num_workers=num_workers,pin_memory=True,persistent_workers = True)\n",
    "#     test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, \n",
    "#                              drop_last=False,num_workers=num_workers,pin_memory=True,persistent_workers = True)\n",
    "#     return train_loader,test_loader\n",
    "\n",
    "\n",
    "# # ---------------------------------------------各类不具有时间步的图像数据集-------------------------------------------------\n",
    "\n",
    "# # 数据集获取  MNIST   10个类别\n",
    "# def get_mnist(data_path = r'../data', batch_size = 512,num_workers = 4,):\n",
    "#     # Define a transform\n",
    "#     transform = transforms.Compose([\n",
    "#         transforms.Grayscale(num_output_channels=1),  # 将图像转为灰度\n",
    "#         transforms.ToTensor(),  # 将图像转为张量\n",
    "#         transforms.Normalize((0.1307,), (0.3081,))\n",
    "#         ])\n",
    "\n",
    "#     mnist_train = datasets.MNIST(data_path, train=True, download=False, transform=transform)\n",
    "#     mnist_test = datasets.MNIST(data_path, train=False, download=False, transform=transform)\n",
    "\n",
    "#     train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, \n",
    "#                               drop_last=True,num_workers=num_workers,pin_memory=True,persistent_workers = True)\n",
    "#     test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, \n",
    "#                              drop_last=False,num_workers=num_workers,pin_memory=True,persistent_workers = True)\n",
    "    \n",
    "#     return train_loader,test_loader\n",
    "\n",
    "# # 数据集获取  Cifar10   10个类别\n",
    "# def get_cifar10(data_path = r'../data', batch_size = 512,num_workers = 4,):\n",
    "#     # 定义数据变换\n",
    "#     transform = transforms.Compose(\n",
    "#         [transforms.ToTensor(),  # 将图片转换为Tensor\n",
    "#          transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])  # 归一化\n",
    "#     trainset=datasets.CIFAR10(root=data_path,train=True,download=False,transform=transform)\n",
    "#     testset=datasets.CIFAR10(root=data_path,train=False,download=False,transform=transform)\n",
    "#     train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, \n",
    "#                               drop_last=True,num_workers=num_workers,pin_memory=True,persistent_workers = True)\n",
    "#     test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, \n",
    "#                              drop_last=False,num_workers=num_workers,pin_memory=True,persistent_workers = True)\n",
    "#     return train_loader,test_loader\n",
    "\n",
    "# # 数据集获取  cifar100   100个类别\n",
    "# def get_cifar100(data_path = r'../data', batch_size = 512,num_workers = 4,):\n",
    "#     # 定义数据变换\n",
    "#     transform = transforms.Compose(\n",
    "#         [transforms.ToTensor(),  # 将图片转换为Tensor\n",
    "#          transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])  # 归一化\n",
    "#     # 下载CIFAR10数据集\n",
    "#     # #训练集\n",
    "#     trainset=datasets.CIFAR100(root=data_path,train=True,download=False,transform=transform)\n",
    "#     # 测试集\n",
    "#     testset=datasets.CIFAR100(root=data_path,train=False,download=False,transform=transform)\n",
    "\n",
    "#     #练习集 封装成DataLoader的形式 batch_size 按照批次传 shuffle 将数据打散 num_workers 线程\n",
    "#     # 创建DataLoader对象\n",
    "#     train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, \n",
    "#                               drop_last=True,num_workers=num_workers,pin_memory=True,persistent_workers = True)\n",
    "#     test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, \n",
    "#                              drop_last=False,num_workers=num_workers,pin_memory=True,persistent_workers = True)\n",
    "\n",
    "#     return train_loader,test_loader\n",
    "\n",
    "# # 数据集获取  imagenet_1k   1000个类别\n",
    "# def get_imagenet(data_path = r'../data/Imagenet2012/imagenet', batch_size = 32,num_workers = 4):\n",
    "    \n",
    "#     traindir = os.path.join(data_path, 'train')\n",
    "#     valdir = os.path.join(data_path, 'val')\n",
    "#     normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "\n",
    "#     train_dataset = datasets.ImageFolder(\n",
    "#         traindir,\n",
    "#         transforms.Compose([\n",
    "#             transforms.RandomResizedCrop(224),\n",
    "#             transforms.RandomHorizontalFlip(),\n",
    "#             transforms.ToTensor(),\n",
    "#             normalize,\n",
    "#         ]))\n",
    "\n",
    "#     val_dataset = datasets.ImageFolder(\n",
    "#         valdir,\n",
    "#         transforms.Compose([\n",
    "#             transforms.Resize(256),\n",
    "#             transforms.CenterCrop(224),\n",
    "#             transforms.ToTensor(),\n",
    "#             normalize,\n",
    "#         ]))\n",
    "\n",
    "#     train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, \n",
    "#                               drop_last=True,num_workers=num_workers,pin_memory=True,persistent_workers = True)\n",
    "#     test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, \n",
    "#                              drop_last=False,num_workers=num_workers,pin_memory=True,persistent_workers = True)\n",
    "#     return train_loader,val_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14adfe87",
   "metadata": {},
   "source": [
    "##### 测试数据集的获取情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a22796d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader,test_loader = get_nmnist()\n",
    "# print(len(train_loader), len(test_loader))\n",
    "# for x,y in train_loader:\n",
    "#     print(x.shape, y.shape)\n",
    "#     break\n",
    "    \n",
    "# train_loader,test_loader = get_NCaltech101()\n",
    "# print(len(train_loader), len(test_loader))\n",
    "# for x,y in train_loader:\n",
    "#     print(x.shape, y.shape)\n",
    "#     break\n",
    "    \n",
    "# train_loader,test_loader = get_dvs128Gesture()\n",
    "# print(len(train_loader), len(test_loader))\n",
    "# for x,y in train_loader:\n",
    "#     print(x.shape, y.shape)\n",
    "#     break\n",
    "    \n",
    "    \n",
    "# train_loader,test_loader = get_cifar10dvs()\n",
    "# print(len(train_loader), len(test_loader))\n",
    "# for x,y in train_loader:\n",
    "#     print(x.shape, y.shape)\n",
    "#     break\n",
    "    \n",
    "# train_loader,test_loader = get_mnist()\n",
    "# print(len(train_loader), len(test_loader))\n",
    "# for x,y in train_loader:\n",
    "#     print(x.shape, y.shape)\n",
    "#     break\n",
    "    \n",
    "# train_loader,test_loader = get_cifar10()\n",
    "# print(len(train_loader), len(test_loader))\n",
    "# for x,y in train_loader:\n",
    "#     print(x.shape, y.shape)\n",
    "#     break\n",
    "    \n",
    "# train_loader,test_loader = get_cifar100()\n",
    "# print(len(train_loader), len(test_loader))\n",
    "# for x,y in train_loader:\n",
    "#     print(x.shape, y.shape)\n",
    "#     break\n",
    "    \n",
    "# train_loader,test_loader = get_imagenet()\n",
    "# print(len(train_loader), len(test_loader))\n",
    "# for x,y in train_loader:\n",
    "#     print(x.shape, y.shape)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d154d3",
   "metadata": {},
   "source": [
    "##### 测试2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aaeb05f5",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The directory [E:\\mycode\\jupyter\\0.SNN\\data\\NMNIST\\frames_number_20_split_by_number] already exists.\n",
      "The directory [E:\\mycode\\jupyter\\0.SNN\\data\\NMNIST\\frames_number_20_split_by_number] already exists.\n",
      "3750 625\n",
      "torch.Size([16, 20, 2, 34, 34]) torch.Size([16])\n",
      "438 107\n",
      "torch.Size([16, 20, 2, 180, 240]) torch.Size([16])\n",
      "The directory [E:\\mycode\\jupyter\\0.SNN\\data\\DVS128Gesture\\frames_number_20_split_by_number] already exists.\n",
      "The directory [E:\\mycode\\jupyter\\0.SNN\\data\\DVS128Gesture\\frames_number_20_split_by_number] already exists.\n",
      "73 18\n",
      "torch.Size([16, 20, 2, 128, 128]) torch.Size([16])\n",
      "500 125\n",
      "torch.Size([16, 20, 2, 128, 128]) torch.Size([16])\n",
      "117 19\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "97 19\n",
      "torch.Size([512, 3, 32, 32]) torch.Size([512])\n",
      "97 19\n",
      "torch.Size([512, 3, 32, 32]) torch.Size([512])\n",
      "40036 1562\n",
      "torch.Size([32, 3, 224, 224]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "# train_loader,test_loader = get_nmnist_2()\n",
    "# print(len(train_loader), len(test_loader))\n",
    "# for x,y in train_loader:\n",
    "#     print(x.shape, y.shape)\n",
    "#     break\n",
    "    \n",
    "# train_loader,test_loader = get_NCaltech101_2()\n",
    "# print(len(train_loader), len(test_loader))\n",
    "# for x,y in train_loader:\n",
    "#     print(x.shape, y.shape)\n",
    "#     break\n",
    "    \n",
    "# train_loader,test_loader = get_dvs128Gesture_2()\n",
    "# print(len(train_loader), len(test_loader))\n",
    "# for x,y in train_loader:\n",
    "#     print(x.shape, y.shape)\n",
    "#     break\n",
    "    \n",
    "    \n",
    "# train_loader,test_loader = get_cifar10dvs_2()\n",
    "# print(len(train_loader), len(test_loader))\n",
    "# for x,y in train_loader:\n",
    "#     print(x.shape, y.shape)\n",
    "#     break\n",
    "    \n",
    "# train_loader,test_loader = get_mnist_2()\n",
    "# print(len(train_loader), len(test_loader))\n",
    "# for x,y in train_loader:\n",
    "#     print(x.shape, y.shape)\n",
    "#     break\n",
    "    \n",
    "# train_loader,test_loader = get_cifar10_2()\n",
    "# print(len(train_loader), len(test_loader))\n",
    "# for x,y in train_loader:\n",
    "#     print(x.shape, y.shape)\n",
    "#     break\n",
    "    \n",
    "# train_loader,test_loader = get_cifar100_2()\n",
    "# print(len(train_loader), len(test_loader))\n",
    "# for x,y in train_loader:\n",
    "#     print(x.shape, y.shape)\n",
    "#     break\n",
    "    \n",
    "# train_loader,test_loader = get_imagenet_2()\n",
    "# print(len(train_loader), len(test_loader))\n",
    "# for x,y in train_loader:\n",
    "#     print(x.shape, y.shape)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c4f7de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9a4f14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eeb51f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01b4c910",
   "metadata": {},
   "source": [
    "### 网络训练测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6570a5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from start2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c136515",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_param():\n",
    "    parser = argparse.ArgumentParser(description='Classify CIFAR10DVS')\n",
    "    parser.add_argument('-dataset', default='CIFAR10DVS', type=str, help='本次分类的数据集')\n",
    "    parser.add_argument('-num_classes', default=10, type=int, help='数据类别')\n",
    "    parser.add_argument('-in_channel', default=2, type=int, help='输入数据的通道数')\n",
    "    parser.add_argument('-T', default=20, type=int, help='simulating time-steps')\n",
    "    parser.add_argument('-data_type', default=1, type=int, help='0表示数据没有时间维度，1表示数据有时间维度')\n",
    "    parser.add_argument('-j', default=4, type=int, metavar='N',\n",
    "                        help='number of data loading workers (default: 4)')\n",
    "\n",
    "    \n",
    "    parser.add_argument('-b', default=16, type=int, help='batch size')  \n",
    "    parser.add_argument('-epochs', default=20, type=int, metavar='N',\n",
    "                        help='number of total epochs to run')\n",
    "    parser.add_argument('-weight_decay', type=float, default=1e-5, help=\"权重衰减因子\")\n",
    "    parser.add_argument('-lr_scheduler', default='mylrsh', type=str, help='use which schedule. StepLR or CosALR')\n",
    "    parser.add_argument('-warmup', default=True, help='是否使用学习率预热')\n",
    "    parser.add_argument('-warmup_epochs', default=10, type=float, help='学习率预热的迭代次数')\n",
    "\n",
    "    # ---------在服务器需要修改的路径\n",
    "    parser.add_argument('-data_dir', type=str, default='../data/CIFAR10DVS',help=\"数据路径\")\n",
    "    parser.add_argument('-out_dir', type=str,default = \"../save_models/CIFAR10DVS\",help='root dir for saving logs and checkpoint')\n",
    "    # 更改训练需要的时间步长\n",
    "#     parser.add_argument('-T_train', default=None, type=int,\n",
    "#                         help='训练时是否要对时间步进行选择，也就是只用几个时间步，而不是全部的时间步')\n",
    "#     parser.add_argument('-T_test', default=None, type=int,\n",
    "#                         help='测试时是否要对时间步进行选择，也就是只用几个时间步，而不是全部的时间步')\n",
    "    parser.add_argument('-T_train', default=4, type=int)\n",
    "    parser.add_argument('-T_test', default=4, type=int)\n",
    "\n",
    "    # 用于模型的训练恢复\n",
    "    parser.add_argument('-resume', type=str, help='resume from the checkpoint path')\n",
    "    # parser.add_argument('-resume', default=r'E:\\mycode\\jupyter\\0.SNN\\test_git2\\sew_resnet\\save_models',\n",
    "    #                     type=str, help='resume from the checkpoint path')\n",
    "\n",
    "    parser.add_argument('-opt', type=str, help='use which optimizer. SDG or Adam or AdamW', default='AdamW')\n",
    "    parser.add_argument('-lr', default=0.1, type=float, help='learning rate')\n",
    "\n",
    "\n",
    "    parser.add_argument('-momentum', default=0.9, type=float, help='momentum for SGD')\n",
    "    parser.add_argument('-step_size', default=32, type=float, help='step_size for StepLR')\n",
    "    parser.add_argument('-gamma', default=0.1, type=float, help='gamma for StepLR')\n",
    "    parser.add_argument('-T_max', default=64, type=int, help='T_max for CosineAnnealingLR')\n",
    "\n",
    "    args = parser.parse_args([])\n",
    "    return args\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "063290c8",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Current CUDA device: 0\n",
      "Number of GPU devices available: 1\n",
      "Namespace(dataset='CIFAR10DVS', num_classes=10, in_channel=2, T=20, data_type=1, b=16, epochs=64, j=4, weight_decay=1e-05, lr_scheduler='mylrsh', warmup=True, warmup_epochs=10, data_dir='../data/CIFAR10DVS', out_dir='../save_models/CIFAR10DVS', T_train=4, T_test=4, resume=None, opt='AdamW', lr=0.1, momentum=0.9, step_size=32, gamma=0.1, T_max=64)\n",
      "Mkdir ../save_models/CIFAR10DVS\\B_16_T_20_O_AdamW_lr_0.1_wd_1e-05_epoch_64_Ttrain_4_mylrsh_10_amp.\n",
      "Mkdir ../save_models/CIFAR10DVS\\B_16_T_20_O_AdamW_lr_0.1_wd_1e-05_epoch_64_Ttrain_4_mylrsh_10_amp_pt.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "348"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "# 查看当前cuda设备号\n",
    "print(\"Current CUDA device:\", torch.cuda.current_device())\n",
    "# 查看可以用的设备数量\n",
    "print(\"Number of GPU devices available:\", torch.cuda.device_count())\n",
    "# 打印初始参数\n",
    "args = init_param()\n",
    "print(args)\n",
    "\n",
    "start_epoch = 0\n",
    "max_test_acc = 0\n",
    "# device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_loader, test_loader = get_cifar10dvs(batch_size=args.b, num_workers = args.j)\n",
    "\n",
    "net = sew_resnet18(input_channels=args.in_channel, num_classes=args.num_classes, connect_f='ADD', T=args.T,\n",
    "                   drops=[1, 1, 1, 1],data_type=args.data_type).to(device)\n",
    "# 如果有多个gpu，就并行训练\n",
    "if torch.cuda.device_count() > 1:\n",
    "    # net = nn.DataParallel(net.to(device), device_ids=[0,1], output_device=[0])\n",
    "    net = nn.DataParallel(net).to(device)\n",
    "    print(f\"使用了{torch.cuda.device_count()}个gpu\")\n",
    "\n",
    "pg = get_params_groups(net, weight_decay=args.weight_decay)  # 进行了简单分组的权重 确定了哪些参数需要权重衰减，哪些不需要\n",
    "optimizer = None\n",
    "if args.opt == 'SGD':\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=args.lr, momentum=args.momentum)\n",
    "elif args.opt == 'Adam':\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=args.lr)\n",
    "elif args.opt == 'AdamW':\n",
    "    optimizer = optim.AdamW(pg, lr=args.lr, weight_decay=args.weight_decay)\n",
    "else:\n",
    "    raise NotImplementedError(args.opt)\n",
    "\n",
    "lr_scheduler = None\n",
    "if args.lr_scheduler == 'StepLR':\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=args.step_size, gamma=args.gamma)\n",
    "elif args.lr_scheduler == 'CosALR':\n",
    "    lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.T_max)\n",
    "elif args.lr_scheduler == 'mylrsh':\n",
    "    lr_scheduler = create_lr_scheduler(optimizer, len(train_loader), args.epochs,\n",
    "                                       warmup=args.warmup, warmup_epochs=args.warmup_epochs)\n",
    "else:\n",
    "    raise NotImplementedError(args.lr_scheduler)\n",
    "\n",
    "# loss_function = nn.CrossEntropyLoss()\n",
    "loss_function = F.mse_loss\n",
    "\n",
    "# scaler = None\n",
    "scaler = amp.GradScaler()\n",
    "\n",
    "# 如果之前有训练到一半的模型，就加载这个模型并开始进行训练\n",
    "if args.resume:\n",
    "    checkpoint = torch.load(args.resume, map_location='cpu')\n",
    "    net.load_state_dict(checkpoint['net'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    lr_scheduler.load_state_dict(checkpoint['lr_scheduler'])\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    max_test_acc = checkpoint['max_test_acc']\n",
    "\n",
    "# 创建模型日志记录保存的路径\n",
    "out_dir = os.path.join(args.out_dir, f'B_{args.b}_T_{args.T}_O_{args.opt}_lr_{args.lr}_wd_{args.weight_decay}_epoch_{args.epochs}_Ttrain_{args.T_train}_')\n",
    "if args.lr_scheduler == 'CosALR':\n",
    "    out_dir += f'CosALR_{args.T_max}'\n",
    "elif args.lr_scheduler == 'StepLR':\n",
    "    out_dir += f'StepLR_{args.step_size}_{args.gamma}'\n",
    "elif args.lr_scheduler == 'mylrsh':\n",
    "    out_dir += f'mylrsh_{args.warmup_epochs}'\n",
    "else:\n",
    "    raise NotImplementedError(args.lr_scheduler)\n",
    "# 是否使用混合精度求导\n",
    "if scaler:\n",
    "    out_dir += '_amp'\n",
    "# 判断路径是否存在\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "    print(f'Mkdir {out_dir}.')\n",
    "else:\n",
    "    print(out_dir)\n",
    "#     assert args.resume is not None\n",
    "\n",
    "# 创建模型保存的路径\n",
    "pt_dir = out_dir + '_pt'\n",
    "if not os.path.exists(pt_dir):\n",
    "    os.makedirs(pt_dir)\n",
    "    print(f'Mkdir {pt_dir}.')\n",
    "\n",
    "# 保存训练参数\n",
    "with open(os.path.join(out_dir, 'args.txt'), 'w', encoding='utf-8') as args_txt:\n",
    "    args_txt.write(str(args))\n",
    "# 使用日志进行记录，可以在tensorboard中可视化查看\n",
    "experiment_id = time.strftime(\"%Y%m%d-%H%M%S\")  # 或任何唯一标识\n",
    "writer = SummaryWriter(os.path.join(out_dir, 'logs', experiment_id), purge_step=start_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89f445f8",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [01:24<00:00,  5.90it/s]\n",
      "epoch = 0, current_lr = 0.010090000000000002\n",
      "train_single_time = 100.4457\n",
      "loss = 0.0991\n",
      "acc = 15.34%\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 125/125 [00:18<00:00,  6.60it/s]\n",
      "test All Acc: 20.45%\n",
      "test All Loss: 0.09\n",
      "2 save_max model param\n",
      "1 save_latest model param\n",
      "D:\\software\\anaconda\\envs\\my_torch\\Lib\\site-packages\\ipykernel_launcher.py -f C:\\Users\\ALiang\\AppData\\Roaming\\jupyter\\runtime\\kernel-6ad9e1de-112e-4fa8-a28b-d63e87a003ec.json escape time = 2024-10-21 11:31:20\n",
      "\n",
      "\n",
      "\n",
      "  5%|████                                                                             | 25/500 [00:04<01:23,  5.71it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_accs,train_losss,test_accs,test_losss \u001b[38;5;241m=\u001b[39m \u001b[43mtrains\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mmax_test_acc\u001b[49m\u001b[43m,\u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdata_type\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mpt_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpt_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\mycode\\jupyter\\0.SNN\\1.my_snn\\start2.py:323\u001b[0m, in \u001b[0;36mtrains\u001b[1;34m(num_epochs, net, train_loader, test_loader, optimizer, device, loss_function, writer, T_train, T_test, max_test_acc, scaler, encoder, T, num_classes, data_type, pt_dir, lr_scheduler)\u001b[0m\n\u001b[0;32m    321\u001b[0m             loss \u001b[38;5;241m=\u001b[39m loss_function(out_fr, label)\n\u001b[0;32m    322\u001b[0m     scaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m--> 323\u001b[0m     scaler\u001b[38;5;241m.\u001b[39mstep(optimizer)\n\u001b[0;32m    324\u001b[0m     scaler\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\software\\anaconda\\envs\\my_torch\\Lib\\site-packages\\torch\\_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    580\u001b[0m     )\n\u001b[1;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\software\\anaconda\\envs\\my_torch\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\software\\anaconda\\envs\\my_torch\\Lib\\site-packages\\torch\\autograd\\graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_accs,train_losss,test_accs,test_losss = trains(args.epochs,net,train_loader,test_loader, optimizer, \n",
    "                                                     device, loss_function,writer, args.T_train, args.T_test,\n",
    "                                                     max_test_acc,scaler,num_classes = args.num_classes,data_type = args.data_type,\n",
    "                                                     pt_dir = pt_dir,lr_scheduler = lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "deb6e115",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "541"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      | 387622 KiB |   1123 MiB |   3042 GiB |   3041 GiB |\n",
      "|       from large pool | 351104 KiB |   1018 MiB |   2701 GiB |   2700 GiB |\n",
      "|       from small pool |  36518 KiB |    124 MiB |    340 GiB |    340 GiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         | 387622 KiB |   1123 MiB |   3042 GiB |   3041 GiB |\n",
      "|       from large pool | 351104 KiB |   1018 MiB |   2701 GiB |   2700 GiB |\n",
      "|       from small pool |  36518 KiB |    124 MiB |    340 GiB |    340 GiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      | 382345 KiB |   1113 MiB |   3004 GiB |   3004 GiB |\n",
      "|       from large pool | 345856 KiB |   1008 MiB |   2664 GiB |   2663 GiB |\n",
      "|       from small pool |  36489 KiB |    124 MiB |    340 GiB |    340 GiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |    810 MiB |   1314 MiB |   1314 MiB | 516096 KiB |\n",
      "|       from large pool |    736 MiB |   1188 MiB |   1188 MiB | 462848 KiB |\n",
      "|       from small pool |     74 MiB |    126 MiB |    126 MiB |  53248 KiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory | 441818 KiB | 499246 KiB |   2555 GiB |   2555 GiB |\n",
      "|       from large pool | 402560 KiB | 459904 KiB |   2203 GiB |   2202 GiB |\n",
      "|       from small pool |  39258 KiB |  40283 KiB |    352 GiB |    352 GiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |     389    |     638    |    1119 K  |    1119 K  |\n",
      "|       from large pool |      69    |     200    |     511 K  |     511 K  |\n",
      "|       from small pool |     320    |     440    |     608 K  |     607 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |     389    |     638    |    1119 K  |    1119 K  |\n",
      "|       from large pool |      69    |     200    |     511 K  |     511 K  |\n",
      "|       from small pool |     320    |     440    |     608 K  |     607 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |      73    |     115    |     115    |      42    |\n",
      "|       from large pool |      36    |      52    |      52    |      16    |\n",
      "|       from small pool |      37    |      63    |      63    |      26    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |     106    |     109    |  744039    |  743933    |\n",
      "|       from large pool |      58    |      60    |  337063    |  337005    |\n",
      "|       from small pool |      48    |      51    |  406976    |  406928    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "writer.close()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()  # 强制进行一次垃圾回收\n",
    "    print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f4c468",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c958c58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f8d892f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_channels, out_channels):\n",
    "    \"\"\"\n",
    "    一个3x3卷积 + BN + LIFNode\n",
    "    \"\"\"\n",
    "    layers = nn.Sequential(\n",
    "        layer.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, stride=1, bias=False),\n",
    "        layer.BatchNorm2d(out_channels),\n",
    "        neuron.LIFNode(detach_reset=True)\n",
    "    )\n",
    "#     functional.set_step_mode(layers, step_mode='m')\n",
    "    return layers\n",
    "\n",
    "def conv1x1(in_channels, out_channels):\n",
    "    \"\"\"\n",
    "    一个1x1卷积 + BN + LIFNode\n",
    "    \"\"\"\n",
    "    layers = nn.Sequential(\n",
    "        layer.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False),\n",
    "        layer.BatchNorm2d(out_channels),\n",
    "        neuron.LIFNode(detach_reset=True), \n",
    "    )\n",
    "#     functional.set_step_mode(layers, step_mode='m')\n",
    "    return layers\n",
    "\n",
    "\n",
    "class SEWBlock_2(nn.Module):\n",
    "    \"\"\"\n",
    "    两个conv3x3 + 残差连接（连接的就是原来的输入）  \n",
    "    也就是在默认输入的脉冲神经元，那么就将输入直接相加到上面，也就是残差连接在lif神经元之后\n",
    "    --------这是sew残差\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, mid_channels, connect_f=None):\n",
    "        super(SEWBlock_2, self).__init__()\n",
    "        self.connect_f = connect_f\n",
    "        self.conv = nn.Sequential(\n",
    "            conv3x3(in_channels, mid_channels),\n",
    "            conv3x3(mid_channels, in_channels),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        out = self.conv(x)\n",
    "        if self.connect_f == 'ADD':\n",
    "            out += x\n",
    "        elif self.connect_f == 'AND':\n",
    "            out *= x\n",
    "        elif self.connect_f == 'IAND':\n",
    "            out = x * (1. - out)\n",
    "        else:\n",
    "            raise NotImplementedError(self.connect_f)\n",
    "        return out\n",
    "\n",
    "\n",
    "class PlainBlock_2(nn.Module):\n",
    "    \"\"\"\n",
    "    两个conv3x3\n",
    "    ----------没有残差连接的块\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, mid_channels):\n",
    "        super(PlainBlock_2, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            conv3x3(in_channels, mid_channels),\n",
    "            conv3x3(mid_channels, in_channels),\n",
    "        )\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class BasicBlock_2(nn.Module):\n",
    "    \"\"\"\n",
    "    一个conv3x3 + 一个3x3卷积 + 一个 bn + 输入x + LIF\n",
    "    也就是残差连接在lif神经元之前\n",
    "    ------------这是spiking残差\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, mid_channels):\n",
    "        super(BasicBlock_2, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            conv3x3(in_channels, mid_channels),\n",
    "            layer.Conv2d(mid_channels, in_channels, kernel_size=3, padding=1, stride=1, bias=False),\n",
    "            layer.BatchNorm2d(in_channels),\n",
    "            )\n",
    "        self.sn = neuron.LIFNode(detach_reset=True)\n",
    "#         functional.set_step_mode(self, step_mode='m')\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.sn(x + self.conv(x))\n",
    "    \n",
    "class ResNetN_2(nn.Module):\n",
    "    \"\"\"\n",
    "    精简完以后的 训练 cifar10DVS 数据集的网络\n",
    "    \"\"\"\n",
    "    def __init__(self, layer_list,in_channels,num_classes,connect_f,block_type,T):\n",
    "        super(ResNetN_2, self).__init__()\n",
    "        conv = []\n",
    "        self.T = T\n",
    "        for cfg_dict in layer_list:\n",
    "            # 每进行一次循环，都要判断当前通道数（in_channels）是否和即将要进行操作的通道数（cfg_dict[0]）是否相同\n",
    "            channels = cfg_dict[0]\n",
    "            mid_channels = cfg_dict[2]\n",
    "            num_blocks = cfg_dict[3]\n",
    "            # 如果当前网络的输入通道数 不等于 预设的输入的通道数，就进行变换，一般都使用的是1x1卷积层进行通道的变换\n",
    "            if in_channels != channels:\n",
    "                if cfg_dict[1] == 3:\n",
    "                    conv.append(conv3x3(in_channels, channels))\n",
    "                elif cfg_dict[1] == 1:\n",
    "                    conv.append(conv1x1(in_channels, channels))\n",
    "                else:\n",
    "                    raise NotImplementedError\n",
    "\n",
    "            in_channels = channels\n",
    "            # 选择不同的模型加载\n",
    "            if block_type == 'sew':\n",
    "                for _ in range(num_blocks):\n",
    "                    conv.append(SEWBlock_2(in_channels, mid_channels, connect_f))\n",
    "                    conv.append(layer.MaxPool2d(cfg_dict[4], cfg_dict[4])) if len(cfg_dict) > 4 else None\n",
    "            elif block_type == 'plain':\n",
    "                for _ in range(num_blocks):\n",
    "                    conv.append(PlainBlock_2(in_channels, mid_channels))\n",
    "                    conv.append(layer.MaxPool2d(cfg_dict[4], cfg_dict[4])) if len(cfg_dict) > 4 else None\n",
    "            elif block_type == 'basic':\n",
    "                for _ in range(num_blocks):\n",
    "                    conv.append(BasicBlock_2(in_channels, mid_channels))\n",
    "                    conv.append(layer.MaxPool2d(cfg_dict[4], cfg_dict[4])) if len(cfg_dict) > 4 else None\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "            \n",
    "#             # 是否使用池化层进行尺寸的减小,将池化层集成到了上面\n",
    "#             if len(cfg_dict) > 4:\n",
    "#                 k_pool = cfg_dict[4]\n",
    "#                 conv.append(layer.MaxPool2d(k_pool, k_pool))\n",
    "        \n",
    "        # 循环完了加一层 nn.Flatten     \n",
    "        # 假设输入的张量维度是 (T, C, H, W)，其中 T 是时间步，C 是通道数，H 是高度，W 是宽度：\n",
    "        # 如果使用 nn.Flatten(2)，前两个维度保持不变，张量将被展平为 (T, C, H * W)。这意味着只会展平 H 和 W 这两个维度，而 T 和 C 将保持不变。\n",
    "        conv.append(nn.Flatten(2))\n",
    "        self.conv = nn.Sequential(*conv)\n",
    "        functional.set_step_mode(self, step_mode='m')\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            x = torch.zeros([1,1, 1, 128, 128])\n",
    "            for m in self.conv.modules():\n",
    "                if isinstance(m, layer.MaxPool2d):\n",
    "                    x = m(x)\n",
    "            out_features = x.numel() * in_channels\n",
    "        self.out = nn.Linear(out_features, num_classes, bias=True)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        if x.dim() == 4:\n",
    "            x = x.repeat(self.T, 1, 1, 1, 1)  # T,N,C,H,W\n",
    "        else:\n",
    "            x = x.permute(1, 0, 2, 3, 4)  # [T, N, C, H, W]\n",
    "        x = self.conv(x)\n",
    "        return self.out(x.mean(0))\n",
    "\n",
    "def SEWResNet_2(in_channels = 2,num_classes = 10,connect_f = 'ADD',block_type = 'sew',T = 4):\n",
    "    '''\n",
    "    block_type 可设置的参数有三个：'sew' ， 'basic' ， 'plain'\n",
    "    layer_list含义：{'channels': 64, 'up_kernel_size': 1, 'mid_channels': 64, 'num_blocks': 1, 'k_pool': 2}\n",
    "    \n",
    "    '''\n",
    "    layer_list = [[64,1,64,3,2],\n",
    "              [128,1,128,2,2],\n",
    "              ]\n",
    "    return ResNetN_2(layer_list,in_channels,num_classes,connect_f,block_type,T)\n",
    "\n",
    "\n",
    "# class ResNetN_2(nn.Module):\n",
    "#     \"\"\"\n",
    "    \n",
    "#     \"\"\"\n",
    "#     def __init__(self, in_channels,layer_list, num_classes, connect_f=None):\n",
    "#         super(ResNetN_2, self).__init__()\n",
    "#         conv = []\n",
    "#         for cfg_dict in layer_list:\n",
    "#             channels = cfg_dict['channels']\n",
    "#             # 如果存在中间通道数，就使用，否则中间通道数就等于输入通道数\n",
    "#             if 'mid_channels' in cfg_dict:\n",
    "#                 mid_channels = cfg_dict['mid_channels']\n",
    "#             else:\n",
    "#                 mid_channels = channels\n",
    "#             # 如果当前网络的输入通道数 不等于 预设的输入的通道数，就进行变换\n",
    "#             if in_channels != channels:\n",
    "#                 if cfg_dict['up_kernel_size'] == 3:\n",
    "#                     conv.append(conv3x3(in_channels, channels))\n",
    "#                 elif cfg_dict['up_kernel_size'] == 1:\n",
    "#                     conv.append(conv1x1(in_channels, channels))\n",
    "#                 else:\n",
    "#                     raise NotImplementedError\n",
    "\n",
    "#             in_channels = channels\n",
    "\n",
    "#             # 选择不同的模型加载\n",
    "#             if 'num_blocks' in cfg_dict:\n",
    "#                 num_blocks = cfg_dict['num_blocks']\n",
    "#                 if cfg_dict['block_type'] == 'sew':\n",
    "#                     for _ in range(num_blocks):\n",
    "#                         conv.append(SEWBlock_2(in_channels, mid_channels, connect_f))\n",
    "#                 elif cfg_dict['block_type'] == 'plain':\n",
    "#                     for _ in range(num_blocks):\n",
    "#                         conv.append(PlainBlock_2(in_channels, mid_channels))\n",
    "#                 elif cfg_dict['block_type'] == 'basic':\n",
    "#                     for _ in range(num_blocks):\n",
    "#                         conv.append(BasicBlock_2(in_channels, mid_channels))\n",
    "#                 else:\n",
    "#                     raise NotImplementedError\n",
    "#             # 是否使用池化层进行尺寸的减小\n",
    "#             if 'k_pool' in cfg_dict:\n",
    "#                 k_pool = cfg_dict['k_pool']\n",
    "#                 conv.append(layer.MaxPool2d(k_pool, k_pool))\n",
    "        \n",
    "#         # 循环完了加一层 nn.Flatten     \n",
    "#         # 假设输入的张量维度是 (T, C, H, W)，其中 T 是时间步，C 是通道数，H 是高度，W 是宽度：\n",
    "#         # 如果使用 nn.Flatten(2)，前两个维度保持不变，张量将被展平为 (T, C, H * W)。这意味着只会展平 H 和 W 这两个维度，而 T 和 C 将保持不变。\n",
    "#         conv.append(nn.Flatten(2))\n",
    "#         self.conv = nn.Sequential(*conv)\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             x = torch.zeros([1, 1, 128, 128])\n",
    "#             for m in self.conv.modules():\n",
    "#                 if isinstance(m, layer.MaxPool2d):\n",
    "#                     x = m(x)\n",
    "#             out_features = x.numel() * in_channels\n",
    "#         self.out = nn.Linear(out_features, num_classes, bias=True)\n",
    "\n",
    "#     def forward(self, x: torch.Tensor):\n",
    "#         x = x.permute(1, 0, 2, 3, 4)  # [T, N, 2, *, *]\n",
    "#         x = self.conv(x)\n",
    "#         return self.out(x.mean(0))\n",
    "\n",
    "# def SEWResNet_2(in_channels,num_classes,connect_f):\n",
    "#     layer_list = [\n",
    "#         {'channels': 64, 'up_kernel_size': 1, 'mid_channels': 64, 'num_blocks': 1, 'block_type': 'sew', 'k_pool': 2},\n",
    "#         {'channels': 64, 'up_kernel_size': 1, 'mid_channels': 64, 'num_blocks': 1, 'block_type': 'sew', 'k_pool': 2},\n",
    "#         {'channels': 64, 'up_kernel_size': 1, 'mid_channels': 64, 'num_blocks': 1, 'block_type': 'sew', 'k_pool': 2},\n",
    "#         {'channels': 64, 'up_kernel_size': 1, 'mid_channels': 64, 'num_blocks': 1, 'block_type': 'sew', 'k_pool': 2},\n",
    "#         {'channels': 128, 'up_kernel_size': 1, 'mid_channels': 128, 'num_blocks': 1, 'block_type': 'sew', 'k_pool': 2},\n",
    "#         {'channels': 128, 'up_kernel_size': 1, 'mid_channels': 128, 'num_blocks': 1, 'block_type': 'sew', 'k_pool': 2},\n",
    "#         {'channels': 128, 'up_kernel_size': 1, 'mid_channels': 128, 'num_blocks': 1, 'block_type': 'sew', 'k_pool': 2},\n",
    "#     ]\n",
    "    \n",
    "#     layer_list2 = [\n",
    "#         {'channels': 64, 'up_kernel_size': 1, 'mid_channels': 64, 'num_blocks': 1, 'block_type': 'plain', 'k_pool': 2},\n",
    "#         {'channels': 64, 'up_kernel_size': 1, 'mid_channels': 64, 'num_blocks': 1, 'block_type': 'plain', 'k_pool': 2},\n",
    "#         {'channels': 64, 'up_kernel_size': 1, 'mid_channels': 64, 'num_blocks': 1, 'block_type': 'plain', 'k_pool': 2},\n",
    "#         {'channels': 64, 'up_kernel_size': 1, 'mid_channels': 64, 'num_blocks': 1, 'block_type': 'plain', 'k_pool': 2},\n",
    "#         {'channels': 128, 'up_kernel_size': 1, 'mid_channels': 128, 'num_blocks': 1, 'block_type': 'plain', 'k_pool': 2},\n",
    "#         {'channels': 128, 'up_kernel_size': 1, 'mid_channels': 128, 'num_blocks': 1, 'block_type': 'plain', 'k_pool': 2},\n",
    "#         {'channels': 128, 'up_kernel_size': 1, 'mid_channels': 128, 'num_blocks': 1, 'block_type': 'plain', 'k_pool': 2},\n",
    "#     ]\n",
    "    \n",
    "    \n",
    "#     layer_list3 = [\n",
    "#         {'channels': 64, 'up_kernel_size': 1, 'mid_channels': 64, 'num_blocks': 1, 'block_type': 'basic', 'k_pool': 2},\n",
    "#         {'channels': 64, 'up_kernel_size': 1, 'mid_channels': 64, 'num_blocks': 1, 'block_type': 'basic', 'k_pool': 2},\n",
    "#         {'channels': 64, 'up_kernel_size': 1, 'mid_channels': 64, 'num_blocks': 1, 'block_type': 'basic', 'k_pool': 2},\n",
    "#         {'channels': 64, 'up_kernel_size': 1, 'mid_channels': 64, 'num_blocks': 1, 'block_type': 'basic', 'k_pool': 2},\n",
    "#         {'channels': 128, 'up_kernel_size': 1, 'mid_channels': 128, 'num_blocks': 1, 'block_type': 'basic', 'k_pool': 2},\n",
    "#         {'channels': 128, 'up_kernel_size': 1, 'mid_channels': 128, 'num_blocks': 1, 'block_type': 'basic', 'k_pool': 2},\n",
    "#         {'channels': 128, 'up_kernel_size': 1, 'mid_channels': 128, 'num_blocks': 1, 'block_type': 'basic', 'k_pool': 2},\n",
    "#     ]\n",
    "#     return ResNetN_2(in_channels,layer_list, num_classes, connect_f)\n",
    "\n",
    "# net = SEWResNet_2(in_channels = 2,num_classes = 10, connect_f = 'ADD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3e1f4def",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SEWResNet_2(in_channels = 2,num_classes = 10, connect_f = 'ADD',block_type = 'sew').cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3268f72a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 torch.Size([4, 2, 2, 128, 128])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1       [2, 2, 64, 128, 128]             128\n",
      "       BatchNorm2d-2       [2, 2, 64, 128, 128]             128\n",
      "           Sigmoid-3          [2, 64, 128, 128]               0\n",
      "           Sigmoid-4          [2, 64, 128, 128]               0\n",
      "           Sigmoid-5          [2, 64, 128, 128]               0\n",
      "           Sigmoid-6          [2, 64, 128, 128]               0\n",
      "           Sigmoid-7          [2, 64, 128, 128]               0\n",
      "           Sigmoid-8          [2, 64, 128, 128]               0\n",
      "           Sigmoid-9          [2, 64, 128, 128]               0\n",
      "          Sigmoid-10          [2, 64, 128, 128]               0\n",
      "          Sigmoid-11          [2, 64, 128, 128]               0\n",
      "          Sigmoid-12          [2, 64, 128, 128]               0\n",
      "          Sigmoid-13          [2, 64, 128, 128]               0\n",
      "          Sigmoid-14          [2, 64, 128, 128]               0\n",
      "          Sigmoid-15          [2, 64, 128, 128]               0\n",
      "          Sigmoid-16          [2, 64, 128, 128]               0\n",
      "          Sigmoid-17          [2, 64, 128, 128]               0\n",
      "          Sigmoid-18          [2, 64, 128, 128]               0\n",
      "          Sigmoid-19          [2, 64, 128, 128]               0\n",
      "          Sigmoid-20          [2, 64, 128, 128]               0\n",
      "          Sigmoid-21          [2, 64, 128, 128]               0\n",
      "          Sigmoid-22          [2, 64, 128, 128]               0\n",
      "          Sigmoid-23          [2, 64, 128, 128]               0\n",
      "          Sigmoid-24          [2, 64, 128, 128]               0\n",
      "          Sigmoid-25          [2, 64, 128, 128]               0\n",
      "          Sigmoid-26          [2, 64, 128, 128]               0\n",
      "          Sigmoid-27          [2, 64, 128, 128]               0\n",
      "          Sigmoid-28          [2, 64, 128, 128]               0\n",
      "          Sigmoid-29          [2, 64, 128, 128]               0\n",
      "          Sigmoid-30          [2, 64, 128, 128]               0\n",
      "          Sigmoid-31          [2, 64, 128, 128]               0\n",
      "          Sigmoid-32          [2, 64, 128, 128]               0\n",
      "          Sigmoid-33          [2, 64, 128, 128]               0\n",
      "          Sigmoid-34          [2, 64, 128, 128]               0\n",
      "          Sigmoid-35          [2, 64, 128, 128]               0\n",
      "          Sigmoid-36          [2, 64, 128, 128]               0\n",
      "          Sigmoid-37          [2, 64, 128, 128]               0\n",
      "          Sigmoid-38          [2, 64, 128, 128]               0\n",
      "          Sigmoid-39          [2, 64, 128, 128]               0\n",
      "          Sigmoid-40          [2, 64, 128, 128]               0\n",
      "          Sigmoid-41          [2, 64, 128, 128]               0\n",
      "          Sigmoid-42          [2, 64, 128, 128]               0\n",
      "          Sigmoid-43          [2, 64, 128, 128]               0\n",
      "          Sigmoid-44          [2, 64, 128, 128]               0\n",
      "          Sigmoid-45          [2, 64, 128, 128]               0\n",
      "          Sigmoid-46          [2, 64, 128, 128]               0\n",
      "          Sigmoid-47          [2, 64, 128, 128]               0\n",
      "          Sigmoid-48          [2, 64, 128, 128]               0\n",
      "          Sigmoid-49          [2, 64, 128, 128]               0\n",
      "          Sigmoid-50          [2, 64, 128, 128]               0\n",
      "          LIFNode-51       [2, 2, 64, 128, 128]               0\n",
      "           Conv2d-52       [2, 2, 64, 128, 128]          36,864\n",
      "      BatchNorm2d-53       [2, 2, 64, 128, 128]             128\n",
      "          Sigmoid-54          [2, 64, 128, 128]               0\n",
      "          Sigmoid-55          [2, 64, 128, 128]               0\n",
      "          Sigmoid-56          [2, 64, 128, 128]               0\n",
      "          Sigmoid-57          [2, 64, 128, 128]               0\n",
      "          Sigmoid-58          [2, 64, 128, 128]               0\n",
      "          Sigmoid-59          [2, 64, 128, 128]               0\n",
      "          Sigmoid-60          [2, 64, 128, 128]               0\n",
      "          Sigmoid-61          [2, 64, 128, 128]               0\n",
      "          Sigmoid-62          [2, 64, 128, 128]               0\n",
      "          Sigmoid-63          [2, 64, 128, 128]               0\n",
      "          Sigmoid-64          [2, 64, 128, 128]               0\n",
      "          Sigmoid-65          [2, 64, 128, 128]               0\n",
      "          Sigmoid-66          [2, 64, 128, 128]               0\n",
      "          Sigmoid-67          [2, 64, 128, 128]               0\n",
      "          Sigmoid-68          [2, 64, 128, 128]               0\n",
      "          Sigmoid-69          [2, 64, 128, 128]               0\n",
      "          Sigmoid-70          [2, 64, 128, 128]               0\n",
      "          Sigmoid-71          [2, 64, 128, 128]               0\n",
      "          Sigmoid-72          [2, 64, 128, 128]               0\n",
      "          Sigmoid-73          [2, 64, 128, 128]               0\n",
      "          Sigmoid-74          [2, 64, 128, 128]               0\n",
      "          Sigmoid-75          [2, 64, 128, 128]               0\n",
      "          Sigmoid-76          [2, 64, 128, 128]               0\n",
      "          Sigmoid-77          [2, 64, 128, 128]               0\n",
      "          Sigmoid-78          [2, 64, 128, 128]               0\n",
      "          Sigmoid-79          [2, 64, 128, 128]               0\n",
      "          Sigmoid-80          [2, 64, 128, 128]               0\n",
      "          Sigmoid-81          [2, 64, 128, 128]               0\n",
      "          Sigmoid-82          [2, 64, 128, 128]               0\n",
      "          Sigmoid-83          [2, 64, 128, 128]               0\n",
      "          Sigmoid-84          [2, 64, 128, 128]               0\n",
      "          Sigmoid-85          [2, 64, 128, 128]               0\n",
      "          Sigmoid-86          [2, 64, 128, 128]               0\n",
      "          Sigmoid-87          [2, 64, 128, 128]               0\n",
      "          Sigmoid-88          [2, 64, 128, 128]               0\n",
      "          Sigmoid-89          [2, 64, 128, 128]               0\n",
      "          Sigmoid-90          [2, 64, 128, 128]               0\n",
      "          Sigmoid-91          [2, 64, 128, 128]               0\n",
      "          Sigmoid-92          [2, 64, 128, 128]               0\n",
      "          Sigmoid-93          [2, 64, 128, 128]               0\n",
      "          Sigmoid-94          [2, 64, 128, 128]               0\n",
      "          Sigmoid-95          [2, 64, 128, 128]               0\n",
      "          Sigmoid-96          [2, 64, 128, 128]               0\n",
      "          Sigmoid-97          [2, 64, 128, 128]               0\n",
      "          Sigmoid-98          [2, 64, 128, 128]               0\n",
      "          Sigmoid-99          [2, 64, 128, 128]               0\n",
      "         Sigmoid-100          [2, 64, 128, 128]               0\n",
      "         Sigmoid-101          [2, 64, 128, 128]               0\n",
      "         LIFNode-102       [2, 2, 64, 128, 128]               0\n",
      "          Conv2d-103       [2, 2, 64, 128, 128]          36,864\n",
      "     BatchNorm2d-104       [2, 2, 64, 128, 128]             128\n",
      "         Sigmoid-105          [2, 64, 128, 128]               0\n",
      "         Sigmoid-106          [2, 64, 128, 128]               0\n",
      "         Sigmoid-107          [2, 64, 128, 128]               0\n",
      "         Sigmoid-108          [2, 64, 128, 128]               0\n",
      "         Sigmoid-109          [2, 64, 128, 128]               0\n",
      "         Sigmoid-110          [2, 64, 128, 128]               0\n",
      "         Sigmoid-111          [2, 64, 128, 128]               0\n",
      "         Sigmoid-112          [2, 64, 128, 128]               0\n",
      "         Sigmoid-113          [2, 64, 128, 128]               0\n",
      "         Sigmoid-114          [2, 64, 128, 128]               0\n",
      "         Sigmoid-115          [2, 64, 128, 128]               0\n",
      "         Sigmoid-116          [2, 64, 128, 128]               0\n",
      "         Sigmoid-117          [2, 64, 128, 128]               0\n",
      "         Sigmoid-118          [2, 64, 128, 128]               0\n",
      "         Sigmoid-119          [2, 64, 128, 128]               0\n",
      "         Sigmoid-120          [2, 64, 128, 128]               0\n",
      "         Sigmoid-121          [2, 64, 128, 128]               0\n",
      "         Sigmoid-122          [2, 64, 128, 128]               0\n",
      "         Sigmoid-123          [2, 64, 128, 128]               0\n",
      "         Sigmoid-124          [2, 64, 128, 128]               0\n",
      "         Sigmoid-125          [2, 64, 128, 128]               0\n",
      "         Sigmoid-126          [2, 64, 128, 128]               0\n",
      "         Sigmoid-127          [2, 64, 128, 128]               0\n",
      "         Sigmoid-128          [2, 64, 128, 128]               0\n",
      "         Sigmoid-129          [2, 64, 128, 128]               0\n",
      "         Sigmoid-130          [2, 64, 128, 128]               0\n",
      "         Sigmoid-131          [2, 64, 128, 128]               0\n",
      "         Sigmoid-132          [2, 64, 128, 128]               0\n",
      "         Sigmoid-133          [2, 64, 128, 128]               0\n",
      "         Sigmoid-134          [2, 64, 128, 128]               0\n",
      "         Sigmoid-135          [2, 64, 128, 128]               0\n",
      "         Sigmoid-136          [2, 64, 128, 128]               0\n",
      "         Sigmoid-137          [2, 64, 128, 128]               0\n",
      "         Sigmoid-138          [2, 64, 128, 128]               0\n",
      "         Sigmoid-139          [2, 64, 128, 128]               0\n",
      "         Sigmoid-140          [2, 64, 128, 128]               0\n",
      "         Sigmoid-141          [2, 64, 128, 128]               0\n",
      "         Sigmoid-142          [2, 64, 128, 128]               0\n",
      "         Sigmoid-143          [2, 64, 128, 128]               0\n",
      "         Sigmoid-144          [2, 64, 128, 128]               0\n",
      "         Sigmoid-145          [2, 64, 128, 128]               0\n",
      "         Sigmoid-146          [2, 64, 128, 128]               0\n",
      "         Sigmoid-147          [2, 64, 128, 128]               0\n",
      "         Sigmoid-148          [2, 64, 128, 128]               0\n",
      "         Sigmoid-149          [2, 64, 128, 128]               0\n",
      "         Sigmoid-150          [2, 64, 128, 128]               0\n",
      "         Sigmoid-151          [2, 64, 128, 128]               0\n",
      "         Sigmoid-152          [2, 64, 128, 128]               0\n",
      "         LIFNode-153       [2, 2, 64, 128, 128]               0\n",
      "      SEWBlock_2-154       [2, 2, 64, 128, 128]               0\n",
      "       MaxPool2d-155         [2, 2, 64, 64, 64]               0\n",
      "          Conv2d-156         [2, 2, 64, 64, 64]          36,864\n",
      "     BatchNorm2d-157         [2, 2, 64, 64, 64]             128\n",
      "         Sigmoid-158            [2, 64, 64, 64]               0\n",
      "         Sigmoid-159            [2, 64, 64, 64]               0\n",
      "         Sigmoid-160            [2, 64, 64, 64]               0\n",
      "         Sigmoid-161            [2, 64, 64, 64]               0\n",
      "         Sigmoid-162            [2, 64, 64, 64]               0\n",
      "         Sigmoid-163            [2, 64, 64, 64]               0\n",
      "         Sigmoid-164            [2, 64, 64, 64]               0\n",
      "         Sigmoid-165            [2, 64, 64, 64]               0\n",
      "         Sigmoid-166            [2, 64, 64, 64]               0\n",
      "         Sigmoid-167            [2, 64, 64, 64]               0\n",
      "         Sigmoid-168            [2, 64, 64, 64]               0\n",
      "         Sigmoid-169            [2, 64, 64, 64]               0\n",
      "         Sigmoid-170            [2, 64, 64, 64]               0\n",
      "         Sigmoid-171            [2, 64, 64, 64]               0\n",
      "         Sigmoid-172            [2, 64, 64, 64]               0\n",
      "         Sigmoid-173            [2, 64, 64, 64]               0\n",
      "         Sigmoid-174            [2, 64, 64, 64]               0\n",
      "         Sigmoid-175            [2, 64, 64, 64]               0\n",
      "         Sigmoid-176            [2, 64, 64, 64]               0\n",
      "         Sigmoid-177            [2, 64, 64, 64]               0\n",
      "         Sigmoid-178            [2, 64, 64, 64]               0\n",
      "         Sigmoid-179            [2, 64, 64, 64]               0\n",
      "         Sigmoid-180            [2, 64, 64, 64]               0\n",
      "         Sigmoid-181            [2, 64, 64, 64]               0\n",
      "         Sigmoid-182            [2, 64, 64, 64]               0\n",
      "         Sigmoid-183            [2, 64, 64, 64]               0\n",
      "         Sigmoid-184            [2, 64, 64, 64]               0\n",
      "         Sigmoid-185            [2, 64, 64, 64]               0\n",
      "         Sigmoid-186            [2, 64, 64, 64]               0\n",
      "         Sigmoid-187            [2, 64, 64, 64]               0\n",
      "         Sigmoid-188            [2, 64, 64, 64]               0\n",
      "         Sigmoid-189            [2, 64, 64, 64]               0\n",
      "         Sigmoid-190            [2, 64, 64, 64]               0\n",
      "         Sigmoid-191            [2, 64, 64, 64]               0\n",
      "         Sigmoid-192            [2, 64, 64, 64]               0\n",
      "         Sigmoid-193            [2, 64, 64, 64]               0\n",
      "         Sigmoid-194            [2, 64, 64, 64]               0\n",
      "         Sigmoid-195            [2, 64, 64, 64]               0\n",
      "         Sigmoid-196            [2, 64, 64, 64]               0\n",
      "         Sigmoid-197            [2, 64, 64, 64]               0\n",
      "         Sigmoid-198            [2, 64, 64, 64]               0\n",
      "         Sigmoid-199            [2, 64, 64, 64]               0\n",
      "         Sigmoid-200            [2, 64, 64, 64]               0\n",
      "         Sigmoid-201            [2, 64, 64, 64]               0\n",
      "         Sigmoid-202            [2, 64, 64, 64]               0\n",
      "         Sigmoid-203            [2, 64, 64, 64]               0\n",
      "         Sigmoid-204            [2, 64, 64, 64]               0\n",
      "         Sigmoid-205            [2, 64, 64, 64]               0\n",
      "         LIFNode-206         [2, 2, 64, 64, 64]               0\n",
      "          Conv2d-207         [2, 2, 64, 64, 64]          36,864\n",
      "     BatchNorm2d-208         [2, 2, 64, 64, 64]             128\n",
      "         Sigmoid-209            [2, 64, 64, 64]               0\n",
      "         Sigmoid-210            [2, 64, 64, 64]               0\n",
      "         Sigmoid-211            [2, 64, 64, 64]               0\n",
      "         Sigmoid-212            [2, 64, 64, 64]               0\n",
      "         Sigmoid-213            [2, 64, 64, 64]               0\n",
      "         Sigmoid-214            [2, 64, 64, 64]               0\n",
      "         Sigmoid-215            [2, 64, 64, 64]               0\n",
      "         Sigmoid-216            [2, 64, 64, 64]               0\n",
      "         Sigmoid-217            [2, 64, 64, 64]               0\n",
      "         Sigmoid-218            [2, 64, 64, 64]               0\n",
      "         Sigmoid-219            [2, 64, 64, 64]               0\n",
      "         Sigmoid-220            [2, 64, 64, 64]               0\n",
      "         Sigmoid-221            [2, 64, 64, 64]               0\n",
      "         Sigmoid-222            [2, 64, 64, 64]               0\n",
      "         Sigmoid-223            [2, 64, 64, 64]               0\n",
      "         Sigmoid-224            [2, 64, 64, 64]               0\n",
      "         Sigmoid-225            [2, 64, 64, 64]               0\n",
      "         Sigmoid-226            [2, 64, 64, 64]               0\n",
      "         Sigmoid-227            [2, 64, 64, 64]               0\n",
      "         Sigmoid-228            [2, 64, 64, 64]               0\n",
      "         Sigmoid-229            [2, 64, 64, 64]               0\n",
      "         Sigmoid-230            [2, 64, 64, 64]               0\n",
      "         Sigmoid-231            [2, 64, 64, 64]               0\n",
      "         Sigmoid-232            [2, 64, 64, 64]               0\n",
      "         Sigmoid-233            [2, 64, 64, 64]               0\n",
      "         Sigmoid-234            [2, 64, 64, 64]               0\n",
      "         Sigmoid-235            [2, 64, 64, 64]               0\n",
      "         Sigmoid-236            [2, 64, 64, 64]               0\n",
      "         Sigmoid-237            [2, 64, 64, 64]               0\n",
      "         Sigmoid-238            [2, 64, 64, 64]               0\n",
      "         Sigmoid-239            [2, 64, 64, 64]               0\n",
      "         Sigmoid-240            [2, 64, 64, 64]               0\n",
      "         Sigmoid-241            [2, 64, 64, 64]               0\n",
      "         Sigmoid-242            [2, 64, 64, 64]               0\n",
      "         Sigmoid-243            [2, 64, 64, 64]               0\n",
      "         Sigmoid-244            [2, 64, 64, 64]               0\n",
      "         Sigmoid-245            [2, 64, 64, 64]               0\n",
      "         Sigmoid-246            [2, 64, 64, 64]               0\n",
      "         Sigmoid-247            [2, 64, 64, 64]               0\n",
      "         Sigmoid-248            [2, 64, 64, 64]               0\n",
      "         Sigmoid-249            [2, 64, 64, 64]               0\n",
      "         Sigmoid-250            [2, 64, 64, 64]               0\n",
      "         Sigmoid-251            [2, 64, 64, 64]               0\n",
      "         Sigmoid-252            [2, 64, 64, 64]               0\n",
      "         Sigmoid-253            [2, 64, 64, 64]               0\n",
      "         Sigmoid-254            [2, 64, 64, 64]               0\n",
      "         Sigmoid-255            [2, 64, 64, 64]               0\n",
      "         Sigmoid-256            [2, 64, 64, 64]               0\n",
      "         LIFNode-257         [2, 2, 64, 64, 64]               0\n",
      "      SEWBlock_2-258         [2, 2, 64, 64, 64]               0\n",
      "       MaxPool2d-259         [2, 2, 64, 32, 32]               0\n",
      "          Conv2d-260         [2, 2, 64, 32, 32]          36,864\n",
      "     BatchNorm2d-261         [2, 2, 64, 32, 32]             128\n",
      "         Sigmoid-262            [2, 64, 32, 32]               0\n",
      "         Sigmoid-263            [2, 64, 32, 32]               0\n",
      "         Sigmoid-264            [2, 64, 32, 32]               0\n",
      "         Sigmoid-265            [2, 64, 32, 32]               0\n",
      "         Sigmoid-266            [2, 64, 32, 32]               0\n",
      "         Sigmoid-267            [2, 64, 32, 32]               0\n",
      "         Sigmoid-268            [2, 64, 32, 32]               0\n",
      "         Sigmoid-269            [2, 64, 32, 32]               0\n",
      "         Sigmoid-270            [2, 64, 32, 32]               0\n",
      "         Sigmoid-271            [2, 64, 32, 32]               0\n",
      "         Sigmoid-272            [2, 64, 32, 32]               0\n",
      "         Sigmoid-273            [2, 64, 32, 32]               0\n",
      "         Sigmoid-274            [2, 64, 32, 32]               0\n",
      "         Sigmoid-275            [2, 64, 32, 32]               0\n",
      "         Sigmoid-276            [2, 64, 32, 32]               0\n",
      "         Sigmoid-277            [2, 64, 32, 32]               0\n",
      "         Sigmoid-278            [2, 64, 32, 32]               0\n",
      "         Sigmoid-279            [2, 64, 32, 32]               0\n",
      "         Sigmoid-280            [2, 64, 32, 32]               0\n",
      "         Sigmoid-281            [2, 64, 32, 32]               0\n",
      "         Sigmoid-282            [2, 64, 32, 32]               0\n",
      "         Sigmoid-283            [2, 64, 32, 32]               0\n",
      "         Sigmoid-284            [2, 64, 32, 32]               0\n",
      "         Sigmoid-285            [2, 64, 32, 32]               0\n",
      "         Sigmoid-286            [2, 64, 32, 32]               0\n",
      "         Sigmoid-287            [2, 64, 32, 32]               0\n",
      "         Sigmoid-288            [2, 64, 32, 32]               0\n",
      "         Sigmoid-289            [2, 64, 32, 32]               0\n",
      "         Sigmoid-290            [2, 64, 32, 32]               0\n",
      "         Sigmoid-291            [2, 64, 32, 32]               0\n",
      "         Sigmoid-292            [2, 64, 32, 32]               0\n",
      "         Sigmoid-293            [2, 64, 32, 32]               0\n",
      "         Sigmoid-294            [2, 64, 32, 32]               0\n",
      "         Sigmoid-295            [2, 64, 32, 32]               0\n",
      "         Sigmoid-296            [2, 64, 32, 32]               0\n",
      "         Sigmoid-297            [2, 64, 32, 32]               0\n",
      "         Sigmoid-298            [2, 64, 32, 32]               0\n",
      "         Sigmoid-299            [2, 64, 32, 32]               0\n",
      "         Sigmoid-300            [2, 64, 32, 32]               0\n",
      "         Sigmoid-301            [2, 64, 32, 32]               0\n",
      "         Sigmoid-302            [2, 64, 32, 32]               0\n",
      "         Sigmoid-303            [2, 64, 32, 32]               0\n",
      "         Sigmoid-304            [2, 64, 32, 32]               0\n",
      "         Sigmoid-305            [2, 64, 32, 32]               0\n",
      "         Sigmoid-306            [2, 64, 32, 32]               0\n",
      "         Sigmoid-307            [2, 64, 32, 32]               0\n",
      "         Sigmoid-308            [2, 64, 32, 32]               0\n",
      "         Sigmoid-309            [2, 64, 32, 32]               0\n",
      "         LIFNode-310         [2, 2, 64, 32, 32]               0\n",
      "          Conv2d-311         [2, 2, 64, 32, 32]          36,864\n",
      "     BatchNorm2d-312         [2, 2, 64, 32, 32]             128\n",
      "         Sigmoid-313            [2, 64, 32, 32]               0\n",
      "         Sigmoid-314            [2, 64, 32, 32]               0\n",
      "         Sigmoid-315            [2, 64, 32, 32]               0\n",
      "         Sigmoid-316            [2, 64, 32, 32]               0\n",
      "         Sigmoid-317            [2, 64, 32, 32]               0\n",
      "         Sigmoid-318            [2, 64, 32, 32]               0\n",
      "         Sigmoid-319            [2, 64, 32, 32]               0\n",
      "         Sigmoid-320            [2, 64, 32, 32]               0\n",
      "         Sigmoid-321            [2, 64, 32, 32]               0\n",
      "         Sigmoid-322            [2, 64, 32, 32]               0\n",
      "         Sigmoid-323            [2, 64, 32, 32]               0\n",
      "         Sigmoid-324            [2, 64, 32, 32]               0\n",
      "         Sigmoid-325            [2, 64, 32, 32]               0\n",
      "         Sigmoid-326            [2, 64, 32, 32]               0\n",
      "         Sigmoid-327            [2, 64, 32, 32]               0\n",
      "         Sigmoid-328            [2, 64, 32, 32]               0\n",
      "         Sigmoid-329            [2, 64, 32, 32]               0\n",
      "         Sigmoid-330            [2, 64, 32, 32]               0\n",
      "         Sigmoid-331            [2, 64, 32, 32]               0\n",
      "         Sigmoid-332            [2, 64, 32, 32]               0\n",
      "         Sigmoid-333            [2, 64, 32, 32]               0\n",
      "         Sigmoid-334            [2, 64, 32, 32]               0\n",
      "         Sigmoid-335            [2, 64, 32, 32]               0\n",
      "         Sigmoid-336            [2, 64, 32, 32]               0\n",
      "         Sigmoid-337            [2, 64, 32, 32]               0\n",
      "         Sigmoid-338            [2, 64, 32, 32]               0\n",
      "         Sigmoid-339            [2, 64, 32, 32]               0\n",
      "         Sigmoid-340            [2, 64, 32, 32]               0\n",
      "         Sigmoid-341            [2, 64, 32, 32]               0\n",
      "         Sigmoid-342            [2, 64, 32, 32]               0\n",
      "         Sigmoid-343            [2, 64, 32, 32]               0\n",
      "         Sigmoid-344            [2, 64, 32, 32]               0\n",
      "         Sigmoid-345            [2, 64, 32, 32]               0\n",
      "         Sigmoid-346            [2, 64, 32, 32]               0\n",
      "         Sigmoid-347            [2, 64, 32, 32]               0\n",
      "         Sigmoid-348            [2, 64, 32, 32]               0\n",
      "         Sigmoid-349            [2, 64, 32, 32]               0\n",
      "         Sigmoid-350            [2, 64, 32, 32]               0\n",
      "         Sigmoid-351            [2, 64, 32, 32]               0\n",
      "         Sigmoid-352            [2, 64, 32, 32]               0\n",
      "         Sigmoid-353            [2, 64, 32, 32]               0\n",
      "         Sigmoid-354            [2, 64, 32, 32]               0\n",
      "         Sigmoid-355            [2, 64, 32, 32]               0\n",
      "         Sigmoid-356            [2, 64, 32, 32]               0\n",
      "         Sigmoid-357            [2, 64, 32, 32]               0\n",
      "         Sigmoid-358            [2, 64, 32, 32]               0\n",
      "         Sigmoid-359            [2, 64, 32, 32]               0\n",
      "         Sigmoid-360            [2, 64, 32, 32]               0\n",
      "         LIFNode-361         [2, 2, 64, 32, 32]               0\n",
      "      SEWBlock_2-362         [2, 2, 64, 32, 32]               0\n",
      "       MaxPool2d-363         [2, 2, 64, 16, 16]               0\n",
      "          Conv2d-364        [2, 2, 128, 16, 16]           8,192\n",
      "     BatchNorm2d-365        [2, 2, 128, 16, 16]             256\n",
      "         Sigmoid-366           [2, 128, 16, 16]               0\n",
      "         Sigmoid-367           [2, 128, 16, 16]               0\n",
      "         Sigmoid-368           [2, 128, 16, 16]               0\n",
      "         Sigmoid-369           [2, 128, 16, 16]               0\n",
      "         Sigmoid-370           [2, 128, 16, 16]               0\n",
      "         Sigmoid-371           [2, 128, 16, 16]               0\n",
      "         Sigmoid-372           [2, 128, 16, 16]               0\n",
      "         Sigmoid-373           [2, 128, 16, 16]               0\n",
      "         Sigmoid-374           [2, 128, 16, 16]               0\n",
      "         Sigmoid-375           [2, 128, 16, 16]               0\n",
      "         Sigmoid-376           [2, 128, 16, 16]               0\n",
      "         Sigmoid-377           [2, 128, 16, 16]               0\n",
      "         Sigmoid-378           [2, 128, 16, 16]               0\n",
      "         Sigmoid-379           [2, 128, 16, 16]               0\n",
      "         Sigmoid-380           [2, 128, 16, 16]               0\n",
      "         Sigmoid-381           [2, 128, 16, 16]               0\n",
      "         Sigmoid-382           [2, 128, 16, 16]               0\n",
      "         Sigmoid-383           [2, 128, 16, 16]               0\n",
      "         Sigmoid-384           [2, 128, 16, 16]               0\n",
      "         Sigmoid-385           [2, 128, 16, 16]               0\n",
      "         Sigmoid-386           [2, 128, 16, 16]               0\n",
      "         Sigmoid-387           [2, 128, 16, 16]               0\n",
      "         Sigmoid-388           [2, 128, 16, 16]               0\n",
      "         Sigmoid-389           [2, 128, 16, 16]               0\n",
      "         Sigmoid-390           [2, 128, 16, 16]               0\n",
      "         Sigmoid-391           [2, 128, 16, 16]               0\n",
      "         Sigmoid-392           [2, 128, 16, 16]               0\n",
      "         Sigmoid-393           [2, 128, 16, 16]               0\n",
      "         Sigmoid-394           [2, 128, 16, 16]               0\n",
      "         Sigmoid-395           [2, 128, 16, 16]               0\n",
      "         Sigmoid-396           [2, 128, 16, 16]               0\n",
      "         Sigmoid-397           [2, 128, 16, 16]               0\n",
      "         Sigmoid-398           [2, 128, 16, 16]               0\n",
      "         Sigmoid-399           [2, 128, 16, 16]               0\n",
      "         Sigmoid-400           [2, 128, 16, 16]               0\n",
      "         Sigmoid-401           [2, 128, 16, 16]               0\n",
      "         Sigmoid-402           [2, 128, 16, 16]               0\n",
      "         Sigmoid-403           [2, 128, 16, 16]               0\n",
      "         Sigmoid-404           [2, 128, 16, 16]               0\n",
      "         Sigmoid-405           [2, 128, 16, 16]               0\n",
      "         Sigmoid-406           [2, 128, 16, 16]               0\n",
      "         Sigmoid-407           [2, 128, 16, 16]               0\n",
      "         Sigmoid-408           [2, 128, 16, 16]               0\n",
      "         Sigmoid-409           [2, 128, 16, 16]               0\n",
      "         Sigmoid-410           [2, 128, 16, 16]               0\n",
      "         Sigmoid-411           [2, 128, 16, 16]               0\n",
      "         Sigmoid-412           [2, 128, 16, 16]               0\n",
      "         Sigmoid-413           [2, 128, 16, 16]               0\n",
      "         LIFNode-414        [2, 2, 128, 16, 16]               0\n",
      "          Conv2d-415        [2, 2, 128, 16, 16]         147,456\n",
      "     BatchNorm2d-416        [2, 2, 128, 16, 16]             256\n",
      "         Sigmoid-417           [2, 128, 16, 16]               0\n",
      "         Sigmoid-418           [2, 128, 16, 16]               0\n",
      "         Sigmoid-419           [2, 128, 16, 16]               0\n",
      "         Sigmoid-420           [2, 128, 16, 16]               0\n",
      "         Sigmoid-421           [2, 128, 16, 16]               0\n",
      "         Sigmoid-422           [2, 128, 16, 16]               0\n",
      "         Sigmoid-423           [2, 128, 16, 16]               0\n",
      "         Sigmoid-424           [2, 128, 16, 16]               0\n",
      "         Sigmoid-425           [2, 128, 16, 16]               0\n",
      "         Sigmoid-426           [2, 128, 16, 16]               0\n",
      "         Sigmoid-427           [2, 128, 16, 16]               0\n",
      "         Sigmoid-428           [2, 128, 16, 16]               0\n",
      "         Sigmoid-429           [2, 128, 16, 16]               0\n",
      "         Sigmoid-430           [2, 128, 16, 16]               0\n",
      "         Sigmoid-431           [2, 128, 16, 16]               0\n",
      "         Sigmoid-432           [2, 128, 16, 16]               0\n",
      "         Sigmoid-433           [2, 128, 16, 16]               0\n",
      "         Sigmoid-434           [2, 128, 16, 16]               0\n",
      "         Sigmoid-435           [2, 128, 16, 16]               0\n",
      "         Sigmoid-436           [2, 128, 16, 16]               0\n",
      "         Sigmoid-437           [2, 128, 16, 16]               0\n",
      "         Sigmoid-438           [2, 128, 16, 16]               0\n",
      "         Sigmoid-439           [2, 128, 16, 16]               0\n",
      "         Sigmoid-440           [2, 128, 16, 16]               0\n",
      "         Sigmoid-441           [2, 128, 16, 16]               0\n",
      "         Sigmoid-442           [2, 128, 16, 16]               0\n",
      "         Sigmoid-443           [2, 128, 16, 16]               0\n",
      "         Sigmoid-444           [2, 128, 16, 16]               0\n",
      "         Sigmoid-445           [2, 128, 16, 16]               0\n",
      "         Sigmoid-446           [2, 128, 16, 16]               0\n",
      "         Sigmoid-447           [2, 128, 16, 16]               0\n",
      "         Sigmoid-448           [2, 128, 16, 16]               0\n",
      "         Sigmoid-449           [2, 128, 16, 16]               0\n",
      "         Sigmoid-450           [2, 128, 16, 16]               0\n",
      "         Sigmoid-451           [2, 128, 16, 16]               0\n",
      "         Sigmoid-452           [2, 128, 16, 16]               0\n",
      "         Sigmoid-453           [2, 128, 16, 16]               0\n",
      "         Sigmoid-454           [2, 128, 16, 16]               0\n",
      "         Sigmoid-455           [2, 128, 16, 16]               0\n",
      "         Sigmoid-456           [2, 128, 16, 16]               0\n",
      "         Sigmoid-457           [2, 128, 16, 16]               0\n",
      "         Sigmoid-458           [2, 128, 16, 16]               0\n",
      "         Sigmoid-459           [2, 128, 16, 16]               0\n",
      "         Sigmoid-460           [2, 128, 16, 16]               0\n",
      "         Sigmoid-461           [2, 128, 16, 16]               0\n",
      "         Sigmoid-462           [2, 128, 16, 16]               0\n",
      "         Sigmoid-463           [2, 128, 16, 16]               0\n",
      "         Sigmoid-464           [2, 128, 16, 16]               0\n",
      "         LIFNode-465        [2, 2, 128, 16, 16]               0\n",
      "          Conv2d-466        [2, 2, 128, 16, 16]         147,456\n",
      "     BatchNorm2d-467        [2, 2, 128, 16, 16]             256\n",
      "         Sigmoid-468           [2, 128, 16, 16]               0\n",
      "         Sigmoid-469           [2, 128, 16, 16]               0\n",
      "         Sigmoid-470           [2, 128, 16, 16]               0\n",
      "         Sigmoid-471           [2, 128, 16, 16]               0\n",
      "         Sigmoid-472           [2, 128, 16, 16]               0\n",
      "         Sigmoid-473           [2, 128, 16, 16]               0\n",
      "         Sigmoid-474           [2, 128, 16, 16]               0\n",
      "         Sigmoid-475           [2, 128, 16, 16]               0\n",
      "         Sigmoid-476           [2, 128, 16, 16]               0\n",
      "         Sigmoid-477           [2, 128, 16, 16]               0\n",
      "         Sigmoid-478           [2, 128, 16, 16]               0\n",
      "         Sigmoid-479           [2, 128, 16, 16]               0\n",
      "         Sigmoid-480           [2, 128, 16, 16]               0\n",
      "         Sigmoid-481           [2, 128, 16, 16]               0\n",
      "         Sigmoid-482           [2, 128, 16, 16]               0\n",
      "         Sigmoid-483           [2, 128, 16, 16]               0\n",
      "         Sigmoid-484           [2, 128, 16, 16]               0\n",
      "         Sigmoid-485           [2, 128, 16, 16]               0\n",
      "         Sigmoid-486           [2, 128, 16, 16]               0\n",
      "         Sigmoid-487           [2, 128, 16, 16]               0\n",
      "         Sigmoid-488           [2, 128, 16, 16]               0\n",
      "         Sigmoid-489           [2, 128, 16, 16]               0\n",
      "         Sigmoid-490           [2, 128, 16, 16]               0\n",
      "         Sigmoid-491           [2, 128, 16, 16]               0\n",
      "         Sigmoid-492           [2, 128, 16, 16]               0\n",
      "         Sigmoid-493           [2, 128, 16, 16]               0\n",
      "         Sigmoid-494           [2, 128, 16, 16]               0\n",
      "         Sigmoid-495           [2, 128, 16, 16]               0\n",
      "         Sigmoid-496           [2, 128, 16, 16]               0\n",
      "         Sigmoid-497           [2, 128, 16, 16]               0\n",
      "         Sigmoid-498           [2, 128, 16, 16]               0\n",
      "         Sigmoid-499           [2, 128, 16, 16]               0\n",
      "         Sigmoid-500           [2, 128, 16, 16]               0\n",
      "         Sigmoid-501           [2, 128, 16, 16]               0\n",
      "         Sigmoid-502           [2, 128, 16, 16]               0\n",
      "         Sigmoid-503           [2, 128, 16, 16]               0\n",
      "         Sigmoid-504           [2, 128, 16, 16]               0\n",
      "         Sigmoid-505           [2, 128, 16, 16]               0\n",
      "         Sigmoid-506           [2, 128, 16, 16]               0\n",
      "         Sigmoid-507           [2, 128, 16, 16]               0\n",
      "         Sigmoid-508           [2, 128, 16, 16]               0\n",
      "         Sigmoid-509           [2, 128, 16, 16]               0\n",
      "         Sigmoid-510           [2, 128, 16, 16]               0\n",
      "         Sigmoid-511           [2, 128, 16, 16]               0\n",
      "         Sigmoid-512           [2, 128, 16, 16]               0\n",
      "         Sigmoid-513           [2, 128, 16, 16]               0\n",
      "         Sigmoid-514           [2, 128, 16, 16]               0\n",
      "         Sigmoid-515           [2, 128, 16, 16]               0\n",
      "         LIFNode-516        [2, 2, 128, 16, 16]               0\n",
      "      SEWBlock_2-517        [2, 2, 128, 16, 16]               0\n",
      "       MaxPool2d-518          [2, 2, 128, 8, 8]               0\n",
      "          Conv2d-519          [2, 2, 128, 8, 8]         147,456\n",
      "     BatchNorm2d-520          [2, 2, 128, 8, 8]             256\n",
      "         Sigmoid-521             [2, 128, 8, 8]               0\n",
      "         Sigmoid-522             [2, 128, 8, 8]               0\n",
      "         Sigmoid-523             [2, 128, 8, 8]               0\n",
      "         Sigmoid-524             [2, 128, 8, 8]               0\n",
      "         Sigmoid-525             [2, 128, 8, 8]               0\n",
      "         Sigmoid-526             [2, 128, 8, 8]               0\n",
      "         Sigmoid-527             [2, 128, 8, 8]               0\n",
      "         Sigmoid-528             [2, 128, 8, 8]               0\n",
      "         Sigmoid-529             [2, 128, 8, 8]               0\n",
      "         Sigmoid-530             [2, 128, 8, 8]               0\n",
      "         Sigmoid-531             [2, 128, 8, 8]               0\n",
      "         Sigmoid-532             [2, 128, 8, 8]               0\n",
      "         Sigmoid-533             [2, 128, 8, 8]               0\n",
      "         Sigmoid-534             [2, 128, 8, 8]               0\n",
      "         Sigmoid-535             [2, 128, 8, 8]               0\n",
      "         Sigmoid-536             [2, 128, 8, 8]               0\n",
      "         Sigmoid-537             [2, 128, 8, 8]               0\n",
      "         Sigmoid-538             [2, 128, 8, 8]               0\n",
      "         Sigmoid-539             [2, 128, 8, 8]               0\n",
      "         Sigmoid-540             [2, 128, 8, 8]               0\n",
      "         Sigmoid-541             [2, 128, 8, 8]               0\n",
      "         Sigmoid-542             [2, 128, 8, 8]               0\n",
      "         Sigmoid-543             [2, 128, 8, 8]               0\n",
      "         Sigmoid-544             [2, 128, 8, 8]               0\n",
      "         Sigmoid-545             [2, 128, 8, 8]               0\n",
      "         Sigmoid-546             [2, 128, 8, 8]               0\n",
      "         Sigmoid-547             [2, 128, 8, 8]               0\n",
      "         Sigmoid-548             [2, 128, 8, 8]               0\n",
      "         Sigmoid-549             [2, 128, 8, 8]               0\n",
      "         Sigmoid-550             [2, 128, 8, 8]               0\n",
      "         Sigmoid-551             [2, 128, 8, 8]               0\n",
      "         Sigmoid-552             [2, 128, 8, 8]               0\n",
      "         Sigmoid-553             [2, 128, 8, 8]               0\n",
      "         Sigmoid-554             [2, 128, 8, 8]               0\n",
      "         Sigmoid-555             [2, 128, 8, 8]               0\n",
      "         Sigmoid-556             [2, 128, 8, 8]               0\n",
      "         Sigmoid-557             [2, 128, 8, 8]               0\n",
      "         Sigmoid-558             [2, 128, 8, 8]               0\n",
      "         Sigmoid-559             [2, 128, 8, 8]               0\n",
      "         Sigmoid-560             [2, 128, 8, 8]               0\n",
      "         Sigmoid-561             [2, 128, 8, 8]               0\n",
      "         Sigmoid-562             [2, 128, 8, 8]               0\n",
      "         Sigmoid-563             [2, 128, 8, 8]               0\n",
      "         Sigmoid-564             [2, 128, 8, 8]               0\n",
      "         Sigmoid-565             [2, 128, 8, 8]               0\n",
      "         Sigmoid-566             [2, 128, 8, 8]               0\n",
      "         Sigmoid-567             [2, 128, 8, 8]               0\n",
      "         Sigmoid-568             [2, 128, 8, 8]               0\n",
      "         LIFNode-569          [2, 2, 128, 8, 8]               0\n",
      "          Conv2d-570          [2, 2, 128, 8, 8]         147,456\n",
      "     BatchNorm2d-571          [2, 2, 128, 8, 8]             256\n",
      "         Sigmoid-572             [2, 128, 8, 8]               0\n",
      "         Sigmoid-573             [2, 128, 8, 8]               0\n",
      "         Sigmoid-574             [2, 128, 8, 8]               0\n",
      "         Sigmoid-575             [2, 128, 8, 8]               0\n",
      "         Sigmoid-576             [2, 128, 8, 8]               0\n",
      "         Sigmoid-577             [2, 128, 8, 8]               0\n",
      "         Sigmoid-578             [2, 128, 8, 8]               0\n",
      "         Sigmoid-579             [2, 128, 8, 8]               0\n",
      "         Sigmoid-580             [2, 128, 8, 8]               0\n",
      "         Sigmoid-581             [2, 128, 8, 8]               0\n",
      "         Sigmoid-582             [2, 128, 8, 8]               0\n",
      "         Sigmoid-583             [2, 128, 8, 8]               0\n",
      "         Sigmoid-584             [2, 128, 8, 8]               0\n",
      "         Sigmoid-585             [2, 128, 8, 8]               0\n",
      "         Sigmoid-586             [2, 128, 8, 8]               0\n",
      "         Sigmoid-587             [2, 128, 8, 8]               0\n",
      "         Sigmoid-588             [2, 128, 8, 8]               0\n",
      "         Sigmoid-589             [2, 128, 8, 8]               0\n",
      "         Sigmoid-590             [2, 128, 8, 8]               0\n",
      "         Sigmoid-591             [2, 128, 8, 8]               0\n",
      "         Sigmoid-592             [2, 128, 8, 8]               0\n",
      "         Sigmoid-593             [2, 128, 8, 8]               0\n",
      "         Sigmoid-594             [2, 128, 8, 8]               0\n",
      "         Sigmoid-595             [2, 128, 8, 8]               0\n",
      "         Sigmoid-596             [2, 128, 8, 8]               0\n",
      "         Sigmoid-597             [2, 128, 8, 8]               0\n",
      "         Sigmoid-598             [2, 128, 8, 8]               0\n",
      "         Sigmoid-599             [2, 128, 8, 8]               0\n",
      "         Sigmoid-600             [2, 128, 8, 8]               0\n",
      "         Sigmoid-601             [2, 128, 8, 8]               0\n",
      "         Sigmoid-602             [2, 128, 8, 8]               0\n",
      "         Sigmoid-603             [2, 128, 8, 8]               0\n",
      "         Sigmoid-604             [2, 128, 8, 8]               0\n",
      "         Sigmoid-605             [2, 128, 8, 8]               0\n",
      "         Sigmoid-606             [2, 128, 8, 8]               0\n",
      "         Sigmoid-607             [2, 128, 8, 8]               0\n",
      "         Sigmoid-608             [2, 128, 8, 8]               0\n",
      "         Sigmoid-609             [2, 128, 8, 8]               0\n",
      "         Sigmoid-610             [2, 128, 8, 8]               0\n",
      "         Sigmoid-611             [2, 128, 8, 8]               0\n",
      "         Sigmoid-612             [2, 128, 8, 8]               0\n",
      "         Sigmoid-613             [2, 128, 8, 8]               0\n",
      "         Sigmoid-614             [2, 128, 8, 8]               0\n",
      "         Sigmoid-615             [2, 128, 8, 8]               0\n",
      "         Sigmoid-616             [2, 128, 8, 8]               0\n",
      "         Sigmoid-617             [2, 128, 8, 8]               0\n",
      "         Sigmoid-618             [2, 128, 8, 8]               0\n",
      "         Sigmoid-619             [2, 128, 8, 8]               0\n",
      "         LIFNode-620          [2, 2, 128, 8, 8]               0\n",
      "      SEWBlock_2-621          [2, 2, 128, 8, 8]               0\n",
      "       MaxPool2d-622          [2, 2, 128, 4, 4]               0\n",
      "         Flatten-623               [2, 2, 2048]               0\n",
      "          Linear-624                    [2, 10]          20,490\n",
      "================================================================\n",
      "Total params: 841,994\n",
      "Trainable params: 841,994\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.25\n",
      "Forward/backward pass size (MB): 3280.63\n",
      "Params size (MB): 3.21\n",
      "Estimated Total Size (MB): 3284.09\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model = net, input_size = (2, 128, 128), batch_size = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23ff15a",
   "metadata": {},
   "source": [
    "#### batch_size = 2     \n",
    "Total params: 841,994  \n",
    "Trainable params: 841,994  \n",
    "Non-trainable params: 0  \n",
    "Input size (MB): 0.25  \n",
    "Forward/backward pass size (MB): 3280.63  \n",
    "Params size (MB): 3.21  \n",
    "Estimated Total Size (MB): 3284.09   \n",
    "\n",
    "#### batch_size = 20   \n",
    "Total params: 841,994  \n",
    "Trainable params: 841,994  \n",
    "Non-trainable params: 0  \n",
    "Input size (MB): 2.50  \n",
    "Forward/backward pass size (MB): 32806.25  \n",
    "Params size (MB): 3.21  \n",
    "Estimated Total Size (MB): 32811.96  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a1e350",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1c45e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adad5348",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c116f3e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce5340b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f79ae40",
   "metadata": {},
   "source": [
    "# 从这儿开始训练"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59f7837",
   "metadata": {},
   "source": [
    "##### 服务器上的参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17afc7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from start2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7daec73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_param():\n",
    "    parser = argparse.ArgumentParser(description='Classify CIFAR10DVS')\n",
    "    parser.add_argument('-dataset', default='CIFAR10DVS', type=str, help='本次分类的数据集')\n",
    "    parser.add_argument('-num_classes', default=10, type=int, help='数据类别')\n",
    "    parser.add_argument('-in_channel', default=2, type=int, help='输入数据的通道数')\n",
    "\n",
    "    parser.add_argument('-T', default=20, type=int, help='simulating time-steps')\n",
    "    parser.add_argument('-j', default=4, type=int, metavar='N',\n",
    "                        help='number of data loading workers (default: 4)')\n",
    "\n",
    "    parser.add_argument('-data_type', default=1, type=int, help='0表示数据没有时间维度，1表示数据有时间维度')\n",
    "\n",
    "    parser.add_argument('-epochs', default=20, type=int, metavar='N',\n",
    "                        help='number of total epochs to run')\n",
    "\n",
    "    parser.add_argument('-b', default=64, type=int, help='batch size')\n",
    "\n",
    "    parser.add_argument('-weight_decay', type=float, default=1e-5, help=\"权重衰减因子\")\n",
    "\n",
    "    parser.add_argument('-lr_scheduler', default='mylrsh', type=str, help='use which schedule. StepLR or CosALR')\n",
    "\n",
    "    parser.add_argument('-warmup', default=True, help='是否使用学习率预热')\n",
    "    parser.add_argument('-warmup_epochs', default=5, type=float, help='学习率预热的迭代次数')\n",
    "\n",
    "    parser.add_argument('-lr', default=0.0001, type=float, help='learning rate')\n",
    "\n",
    "    parser.add_argument('-T_train', default=None, type=int,\n",
    "                        help='训练时是否要对时间步进行选择，也就是只用几个时间步，而不是全部的时间步')\n",
    "    parser.add_argument('-T_test', default=None, type=int,\n",
    "                        help='测试时是否要对时间步进行选择，也就是只用几个时间步，而不是全部的时间步')\n",
    "    # parser.add_argument('-T_train', default=4, type=int)\n",
    "    # parser.add_argument('-T_test', default=4, type=int)\n",
    "\n",
    "    # ---------在服务器需要修改的路径\n",
    "    parser.add_argument('-data_dir', type=str, default='../data/CIFAR10DVS',help=\"数据路径\")\n",
    "    parser.add_argument('-out_dir', type=str,default = \"../save_models/CIFAR10DVS\",help='root dir for saving logs and checkpoint')\n",
    "\n",
    "    # 用于模型的训练恢复\n",
    "    parser.add_argument('-resume', type=str, help='resume from the checkpoint path')\n",
    "    # parser.add_argument('-resume', default=r'E:\\mycode\\jupyter\\0.SNN\\test_git2\\sew_resnet\\save_models',\n",
    "    #                     type=str, help='resume from the checkpoint path')\n",
    "\n",
    "    parser.add_argument('-opt', type=str, help='use which optimizer. SDG or Adam or AdamW', default='AdamW')\n",
    "    \n",
    "    parser.add_argument('-momentum', default=0.9, type=float, help='momentum for SGD')\n",
    "    parser.add_argument('-step_size', default=32, type=float, help='step_size for StepLR')\n",
    "    parser.add_argument('-gamma', default=0.0001, type=float, help='gamma for StepLR')\n",
    "    parser.add_argument('-T_max', default=64, type=int, help='T_max for CosineAnnealingLR')\n",
    "\n",
    "    parser.add_argument('-model_name', type=str, default='SEWResNet18',help=\"模型名称\")\n",
    "\n",
    "    args = parser.parse_args([])\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cd05038c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_param():\n",
    "    parser = argparse.ArgumentParser(description='Classify CIFAR10DVS')\n",
    "    parser.add_argument('-dataset', default='CIFAR10DVS', type=str, help='本次分类的数据集')\n",
    "    parser.add_argument('-num_classes', default=10, type=int, help='数据类别')\n",
    "    parser.add_argument('-in_channel', default=2, type=int, help='输入数据的通道数')\n",
    "    parser.add_argument('-T', default=20, type=int, help='simulating time-steps')\n",
    "    parser.add_argument('-data_type', default=1, type=int, help='0表示数据没有时间维度，1表示数据有时间维度')\n",
    "    parser.add_argument('-j', default=4, type=int, metavar='N',\n",
    "                        help='number of data loading workers (default: 4)')\n",
    "\n",
    "    \n",
    "    parser.add_argument('-b', default=16, type=int, help='batch size')  \n",
    "    parser.add_argument('-epochs', default=20, type=int, metavar='N',\n",
    "                        help='number of total epochs to run')\n",
    "    parser.add_argument('-weight_decay', type=float, default=1e-5, help=\"权重衰减因子\")\n",
    "    parser.add_argument('-lr_scheduler', default='mylrsh', type=str, help='use which schedule. StepLR or CosALR')\n",
    "    parser.add_argument('-warmup', default=True, help='是否使用学习率预热')\n",
    "    parser.add_argument('-warmup_epochs', default=10, type=float, help='学习率预热的迭代次数')\n",
    "\n",
    "    # ---------在服务器需要修改的路径\n",
    "    parser.add_argument('-data_dir', type=str, default='../data/CIFAR10DVS',help=\"数据路径\")\n",
    "    parser.add_argument('-out_dir', type=str,default = \"../save_models/CIFAR10DVS\",help='root dir for saving logs and checkpoint')\n",
    "    # 更改训练需要的时间步长\n",
    "#     parser.add_argument('-T_train', default=None, type=int,\n",
    "#                         help='训练时是否要对时间步进行选择，也就是只用几个时间步，而不是全部的时间步')\n",
    "#     parser.add_argument('-T_test', default=None, type=int,\n",
    "#                         help='测试时是否要对时间步进行选择，也就是只用几个时间步，而不是全部的时间步')\n",
    "    parser.add_argument('-T_train', default=4, type=int)\n",
    "    parser.add_argument('-T_test', default=4, type=int)\n",
    "    # 更改模型名字\n",
    "    parser.add_argument('-model_name', type=str, default='SEWResNet_2',help=\"模型名称\")\n",
    "\n",
    "    # 用于模型的训练恢复\n",
    "    parser.add_argument('-resume', type=str, help='resume from the checkpoint path')\n",
    "    # parser.add_argument('-resume', default=r'E:\\mycode\\jupyter\\0.SNN\\test_git2\\sew_resnet\\save_models',\n",
    "    #                     type=str, help='resume from the checkpoint path')\n",
    "\n",
    "    parser.add_argument('-opt', type=str, help='use which optimizer. SDG or Adam or AdamW', default='AdamW')\n",
    "    parser.add_argument('-lr', default=0.1, type=float, help='learning rate')\n",
    "\n",
    "\n",
    "    parser.add_argument('-momentum', default=0.9, type=float, help='momentum for SGD')\n",
    "    parser.add_argument('-step_size', default=32, type=float, help='step_size for StepLR')\n",
    "    parser.add_argument('-gamma', default=0.1, type=float, help='gamma for StepLR')\n",
    "    parser.add_argument('-T_max', default=64, type=int, help='T_max for CosineAnnealingLR')\n",
    "\n",
    "    args = parser.parse_args([])\n",
    "    return args\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3a94abfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Current CUDA device: 0\n",
      "Number of GPU devices available: 1\n",
      "Namespace(dataset='CIFAR10DVS', num_classes=10, in_channel=2, T=20, data_type=1, j=4, b=16, epochs=20, weight_decay=1e-05, lr_scheduler='mylrsh', warmup=True, warmup_epochs=10, data_dir='../data/CIFAR10DVS', out_dir='../save_models/CIFAR10DVS', T_train=4, T_test=4, model_name='SEWResNet_2', resume=None, opt='AdamW', lr=0.1, momentum=0.9, step_size=32, gamma=0.1, T_max=64)\n",
      "../save_models/CIFAR10DVS\\M_SEWResNet_2_B_16_T_20_O_AdamW_lr_0.1_wd_1e-05_epoch_20_Ttrain_4_mylrsh_10_amp\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "374"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "# 查看当前cuda设备号\n",
    "print(\"Current CUDA device:\", torch.cuda.current_device())\n",
    "# 查看可以用的设备数量\n",
    "print(\"Number of GPU devices available:\", torch.cuda.device_count())\n",
    "# 打印初始参数\n",
    "args = init_param()\n",
    "print(args)\n",
    "\n",
    "start_epoch = 0\n",
    "max_test_acc = 0\n",
    "# device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_loader, test_loader = get_cifar10dvs(batch_size=args.b, num_workers = args.j)\n",
    "\n",
    "net = SEWResNet_2(in_channels = 2,num_classes = 10, connect_f = 'ADD',block_type = 'sew').to(device)\n",
    "# net = sew_resnet18(input_channels=args.in_channel, num_classes=args.num_classes, connect_f='ADD', T=args.T,\n",
    "#                    drops=[1, 1, 1, 1],data_type=args.data_type).to(device)\n",
    "# 如果有多个gpu，就并行训练\n",
    "if torch.cuda.device_count() > 1:\n",
    "    # net = nn.DataParallel(net.to(device), device_ids=[0,1], output_device=[0])\n",
    "    net = nn.DataParallel(net).to(device)\n",
    "    print(f\"使用了{torch.cuda.device_count()}个gpu\")\n",
    "\n",
    "pg = get_params_groups(net, weight_decay=args.weight_decay)  # 进行了简单分组的权重 确定了哪些参数需要权重衰减，哪些不需要\n",
    "optimizer = None\n",
    "if args.opt == 'SGD':\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=args.lr, momentum=args.momentum)\n",
    "elif args.opt == 'Adam':\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=args.lr)\n",
    "elif args.opt == 'AdamW':\n",
    "    optimizer = optim.AdamW(pg, lr=args.lr, weight_decay=args.weight_decay)\n",
    "else:\n",
    "    raise NotImplementedError(args.opt)\n",
    "\n",
    "lr_scheduler = None\n",
    "if args.lr_scheduler == 'StepLR':\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=args.step_size, gamma=args.gamma)\n",
    "elif args.lr_scheduler == 'CosALR':\n",
    "    lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.T_max)\n",
    "elif args.lr_scheduler == 'mylrsh':\n",
    "    lr_scheduler = create_lr_scheduler(optimizer, len(train_loader), args.epochs,\n",
    "                                       warmup=args.warmup, warmup_epochs=args.warmup_epochs)\n",
    "else:\n",
    "    raise NotImplementedError(args.lr_scheduler)\n",
    "\n",
    "# loss_function = nn.CrossEntropyLoss()\n",
    "loss_function = F.mse_loss\n",
    "\n",
    "# scaler = None\n",
    "scaler = amp.GradScaler()\n",
    "\n",
    "# 如果之前有训练到一半的模型，就加载这个模型并开始进行训练\n",
    "if args.resume:\n",
    "    checkpoint = torch.load(args.resume, map_location='cpu')\n",
    "    net.load_state_dict(checkpoint['net'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    lr_scheduler.load_state_dict(checkpoint['lr_scheduler'])\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    max_test_acc = checkpoint['max_test_acc']\n",
    "\n",
    "# 创建模型日志记录保存的路径\n",
    "out_dir = os.path.join(args.out_dir, f'M_{args.model_name}_B_{args.b}_T_{args.T}_O_{args.opt}_lr_{args.lr}_wd_{args.weight_decay}_epoch_{args.epochs}_Ttrain_{args.T_train}_')\n",
    "if args.lr_scheduler == 'CosALR':\n",
    "    out_dir += f'CosALR_{args.T_max}'\n",
    "elif args.lr_scheduler == 'StepLR':\n",
    "    out_dir += f'StepLR_{args.step_size}_{args.gamma}'\n",
    "elif args.lr_scheduler == 'mylrsh':\n",
    "    out_dir += f'mylrsh_{args.warmup_epochs}'\n",
    "else:\n",
    "    raise NotImplementedError(args.lr_scheduler)\n",
    "# 是否使用混合精度求导\n",
    "if scaler:\n",
    "    out_dir += '_amp'\n",
    "# 判断路径是否存在\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "    print(f'Mkdir {out_dir}.')\n",
    "else:\n",
    "    print(out_dir)\n",
    "#     assert args.resume is not None\n",
    "\n",
    "# 创建模型保存的路径\n",
    "pt_dir = out_dir + '_pt'\n",
    "if not os.path.exists(pt_dir):\n",
    "    os.makedirs(pt_dir)\n",
    "    print(f'Mkdir {pt_dir}.')\n",
    "\n",
    "# 保存训练参数\n",
    "with open(os.path.join(out_dir, 'args.txt'), 'w', encoding='utf-8') as args_txt:\n",
    "    args_txt.write(str(args))\n",
    "# 使用日志进行记录，可以在tensorboard中可视化查看\n",
    "experiment_id = time.strftime(\"%Y%m%d-%H%M%S\")  # 或任何唯一标识\n",
    "writer = SummaryWriter(os.path.join(out_dir, 'logs', experiment_id), purge_step=start_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e0f7118d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [02:10<00:00,  3.83it/s]\n",
      "epoch = 0, current_lr = 0.010090000000000002\n",
      "train_single_time = 146.7824\n",
      "loss = 0.1012\n",
      "acc = 21.27%\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 125/125 [00:14<00:00,  8.83it/s]\n",
      "test All Acc: 24.00%\n",
      "test All Loss: 0.10\n",
      "2 save_max model param\n",
      "1 save_latest model param\n",
      "D:\\software\\anaconda\\envs\\my_torch\\Lib\\site-packages\\ipykernel_launcher.py -f C:\\Users\\ALiang\\AppData\\Roaming\\jupyter\\runtime\\kernel-b2639e4d-6d1a-4202-a7e0-82d8a38add00.json escape time = 2024-10-21 15:09:40\n",
      "\n",
      "\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [02:10<00:00,  3.84it/s]\n",
      "epoch = 1, current_lr = 0.02008\n",
      "train_single_time = 130.2251\n",
      "loss = 0.0932\n",
      "acc = 22.74%\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 125/125 [00:14<00:00,  8.72it/s]\n",
      "test All Acc: 19.65%\n",
      "test All Loss: 0.16\n",
      "1 save_latest model param\n",
      "D:\\software\\anaconda\\envs\\my_torch\\Lib\\site-packages\\ipykernel_launcher.py -f C:\\Users\\ALiang\\AppData\\Roaming\\jupyter\\runtime\\kernel-b2639e4d-6d1a-4202-a7e0-82d8a38add00.json escape time = 2024-10-21 14:59:09\n",
      "\n",
      "\n",
      "\n",
      "  1%|▋                                                                                 | 4/500 [00:01<03:16,  2.52it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x0000013645F69C60>\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\software\\anaconda\\envs\\my_torch\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1604, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"D:\\software\\anaconda\\envs\\my_torch\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1568, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"D:\\software\\anaconda\\envs\\my_torch\\Lib\\multiprocessing\\process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\software\\anaconda\\envs\\my_torch\\Lib\\multiprocessing\\popen_spawn_win32.py\", line 112, in wait\n",
      "    res = _winapi.WaitForSingleObject(int(self._handle), msecs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[61], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_accs,train_losss,test_accs,test_losss \u001b[38;5;241m=\u001b[39m \u001b[43mtrains\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mmax_test_acc\u001b[49m\u001b[43m,\u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdata_type\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mpt_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpt_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\mycode\\jupyter\\0.SNN\\1.my_snn\\start2.py:323\u001b[0m, in \u001b[0;36mtrains\u001b[1;34m(num_epochs, net, train_loader, test_loader, optimizer, device, loss_function, writer, T_train, T_test, max_test_acc, scaler, encoder, T, num_classes, data_type, pt_dir, lr_scheduler)\u001b[0m\n\u001b[0;32m    321\u001b[0m             loss \u001b[38;5;241m=\u001b[39m loss_function(out_fr, label)\n\u001b[0;32m    322\u001b[0m     scaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m--> 323\u001b[0m     \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    324\u001b[0m     scaler\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\software\\anaconda\\envs\\my_torch\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:457\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[1;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munscale_(optimizer)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    455\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 457\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_opt_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    459\u001b[0m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m OptState\u001b[38;5;241m.\u001b[39mSTEPPED\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[1;32mD:\\software\\anaconda\\envs\\my_torch\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:351\u001b[0m, in \u001b[0;36mGradScaler._maybe_opt_step\u001b[1;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_opt_step\u001b[39m(\n\u001b[0;32m    344\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    345\u001b[0m     optimizer: torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    349\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[0;32m    350\u001b[0m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 351\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(v\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m    352\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[1;32mD:\\software\\anaconda\\envs\\my_torch\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:351\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_opt_step\u001b[39m(\n\u001b[0;32m    344\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    345\u001b[0m     optimizer: torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    349\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[0;32m    350\u001b[0m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 351\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m    352\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_accs,train_losss,test_accs,test_losss = trains(args.epochs,net,train_loader,test_loader, optimizer, \n",
    "                                                     device, loss_function,writer, args.T_train, args.T_test,\n",
    "                                                     max_test_acc,scaler,num_classes = args.num_classes,data_type = args.data_type,\n",
    "                                                     pt_dir = pt_dir,lr_scheduler = lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259c101d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e613a38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e60b88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (my_torch)",
   "language": "python",
   "name": "my_torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
