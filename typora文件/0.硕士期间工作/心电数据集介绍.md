# 数据记录	

​	N Normal beat   正常心搏  
​    J Nodal (junctional) premature beat   交界性早搏
​    V Premature ventricular contraction  室性早搏
​    F Fusion of ventricular and normal beat 心室融合心跳
​    A  Atrial premature   beat  房性早搏(⼼室搏动还未结束新房就开始搏动)
​    E  Ventricular   escape beat 室性逸搏
​    L  Left bundle   branch block beat  左束⽀传导阻滞⼼搏
​    R  Right bundle branch block beat  右束⽀传导阻滞⼼搏
​    S  Supraventricular premature or ectopic   室上性早搏
​    a  Aberrated atrial premature beat  异常房性早搏
​    e  Atrial escape   beat  房性逸搏(被动性异位⼼律)
​    f  Fusion of paced and normal beat   起搏融合⼼跳
​    j  Nodal   (junctional) premature beat  交界性逸搏
​    B: Bundle branch block beat (unspecified)  传导阻滞⼼搏

1. mit-bih-arrhythmia-database：采样率：360hz，==最终下采样到200hz==  mitdb

   48-2 = 46个样本

   numberSet =   ['100', '101', '103', '105', '106', '107', '108',
                  '109', '111', '112', '113', '114', '115', '116', '117', '118',
                  '119', '121', '122', '123', '124', '200', '201', '202', '203',
                  '205', '207', '208', '209', '210', '212', '213', '214', '215',
                  '217', '219', '220', '221', '222', '223', '228', '230', '231',
                  '232', '233', '234']

   ==未进行类别去除前：==

   len_sample = [2274, 1874, 2091, 2691, 2098, 2140, 1824, 2535, 2133, 2550, 1796,
          1890, 1962, 2421, 1539, 2301, 2094, 1876, 2479, 1519, 1634, 2792,
          2039, 2146, 3108, 2672, 2385, 3040, 3052, 2685, 2763, 3294, 2297,
          3400, 2280, 2312, 2069, 2462, 2634, 2643, 2141, 2466, 2011, 1816,
          3152, 2764]
   len_samples = 108144

   a = {'N': 74790, 'L': 8075, 'R': 7259, 'V': 7124, '/': 3620, 'A': 2546, '+': 1241, 'F': 803, '~': 579, '!': 472, ' " ': 437, 'f': 260, 'j': 229, 'x': 193, 'a': 150, '|': 132, 'E': 106, 'J': 83, 'e': 16, 'Q': 15, '[': 6, ']': 6, 'S': 2}

   考虑到信号最大限度利用，同时各个类别也能较为充分利用，我们截取到~即可

   'N': 74790, 'L': 8075, 'R': 7259, 'V': 7124, '/': 3620, 'A': 2546, '+': 1241, 'F': 803, '~': 579,
   'N', 'L', 'R', 'V':, '/', 'A', '+', 'F', '~'  共使用9类

   ==类别去除后==

   a = {0: 74163, 1: 8023, 2: 7188, 3: 7080, 4: 3584, 5: 2518, 6: 1192, 7: 800, 8: 575}

   len_dataset = [2254, 1848, 2071, 2636, 2078, 2120, 1784, 2515, 2113, 2530, 1770,
          1867, 1936, 2401, 1519, 2271, 2074, 1856, 2457, 1499, 1580, 2772,
          1878, 2105, 3056, 2651, 1774, 3008, 3025, 2641, 2742, 3271, 2269,
          3378, 2000, 2155, 2049, 2442, 2401, 2606, 2094, 2445, 1563, 1795,
          3130, 2694]
   len_Dataset = 105123

   

   

   # 最终处理方式

   N类的数量应该和8023一样大，其余不变

   a = {0: 8023, 1: 8023, 2: 7188, 3: 7080, 4: 3584, 5: 2518, 6: 1192, 7: 800, 8: 575}
   共38393
   将300 变为 200

   

   [数据库链接](https://physionet.org/content/mitdb/1.0.0/)   

   

   

2. mit-bih-st-change-database：采样率：360hz，最终下采样到200hz    stdb  

   ==该数据集波形是倒置的，考虑不使用?==

   28个样本

   numberSet = ['300', '301', '302', '303', '304', '305', '306', '307', '308',
                '309', '310', '311', '312', '313', '314', '315', '316', '317',
                '318', '319', '320', '321', '322', '323', '324', '325', '326',
                '327']

   a = {'N': 75038, 'V': 322, 'S': 815, '~': 6}

   # 最终处理方式

   保存下来   N保存1000个
   {0: 1000, 1: 807, 2: 322}  2129

   

   

   ==未进行类别去除前==：

   len_sample = [2558, 2497, 2113, 3005, 1852, 1036, 6527, 2469, 2299, 5149, 2410,
          3009, 2340, 2701, 2121, 3274, 3351, 2776, 3531, 2565, 3135, 2115,
          1508, 5290, 1740, 1465, 2075, 1270]
   len_samples = 76181

   ==只使用NSV==:

   a = Counter({0: 74486, 1: 807, 2: 322}

   len_dataset = [2538, 2477, 2093, 2985, 1832, 1016, 6507, 2449, 2279, 5129, 2390,
          2989, 2320, 2681, 2101, 3254, 3331, 2756, 3511, 2539, 3115, 2095,
          1488, 5270, 1720, 1445, 2055, 1250]
   len_Dataset = 75615

   

   [数据库链接](https://physionet.org/content/stdb/1.0.0/)

   论文使用了28个记录，共3类数据（N、S、 V），用smote进行的数据生成填充，每一类生成7000个，共21000个

3. european-st-t-database:采样率：250hz，最终下采样到200hz  edb  

   共90个样本
   numberSet = ['e0103', 'e0104', 'e0105', 'e0106', 'e0107', 'e0108', 'e0110',
          'e0111', 'e0112', 'e0113', 'e0114', 'e0115', 'e0116', 'e0118',
          'e0119', 'e0121', 'e0122', 'e0123', 'e0124', 'e0125', 'e0126',
          'e0127', 'e0129', 'e0133', 'e0136', 'e0139', 'e0147', 'e0148',
          'e0151', 'e0154', 'e0155', 'e0159', 'e0161', 'e0162', 'e0163',
          'e0166', 'e0170', 'e0202', 'e0203', 'e0204', 'e0205', 'e0206',
          'e0207', 'e0208', 'e0210', 'e0211', 'e0212', 'e0213', 'e0302',
          'e0303', 'e0304', 'e0305', 'e0306', 'e0403', 'e0404', 'e0405',
          'e0406', 'e0408', 'e0409', 'e0410', 'e0411', 'e0413', 'e0415',
          'e0417', 'e0418', 'e0501', 'e0509', 'e0515', 'e0601', 'e0602',
          'e0603', 'e0604', 'e0605', 'e0606', 'e0607', 'e0609', 'e0610',
          'e0611', 'e0612', 'e0613', 'e0614', 'e0615', 'e0704', 'e0801',
          'e0808', 'e0817', 'e0818', 'e1301', 'e1302', 'e1304']

   ==处理完后==

   #### 87个样本

   numberSet_MLIII = ['e0103', 'e0104', 'e0105', 'e0106', 'e0108', 'e0110',
                      'e0111', 'e0112', 'e0113', 'e0114', 'e0116', 'e0118',
                      'e0119', 'e0121', 'e0122', 'e0123', 'e0124', 'e0125', 'e0126',
                      'e0127', 'e0129', 'e0133', 'e0136', 'e0139', 'e0147', 'e0148',
                      'e0151', 'e0154', 'e0155', 'e0159', 'e0161', 'e0162', 'e0163',
                      'e0166', 'e0170', 'e0604',]   36个
   numberSet_V5 = ['e0115','e0202', 'e0203', 'e0204', 'e0205', 'e0206',
          'e0207', 'e0208', 'e0210', 'e0211', 'e0212', 'e0213', 'e0302',
          'e0303', 'e0304', 'e0305', 'e0306', 'e0403', 'e0404', 'e0405',
          'e0406', 'e0408', 'e0409', 'e0410', 'e0411', 'e0413', 'e0415',
          'e0417', 'e0418', 'e0515', 'e0601', 'e0602', 'e0603', 
          'e0605', 'e0606', 'e0607', 'e0609', 'e0610', 'e0611', 'e0612',
          'e0613', 'e0614', 'e0615', 'e0704', 'e0801', 'e0808', 'e0817',
          'e0818', 'e1301', 'e1302', 'e1304']   51个

   ==**MLIII：**==

   a  ={'N': 280036, '~': 3295, 'T': 774, 'S': 696, 's': 519, 'V': 191, '+': 142, '|': 63, '"': 17, 'F': 5, 'Q': 2, 'J': 1}

   len_sample = [ 7336,  7824,  6704,  7217,  6710,  7095,  7654,  5676,  9173,
           5664,  4605,  7270,  8079, 10767, 11414,  9204,  9295,  9136,
           8359,  9487,  5728,  6688,  7141, 10790,  6444,  6790,  7687,
           6837,  8447,  9487,  8946, 10747,  7726,  6456,  9160,  7998]
   len_samples = 285741

   ==**V5:**==

   len_sample = [11365, 10037, 10229, 11593, 12080, 11014,  7252,  8832,  8804,
          15152, 10957, 11268, 10431,  8954,  8386,  9523,  7990,  9344,
           7012, 11214,  9066,  9087, 12904,  7595, 10027,  8215, 11792,
           9263, 11748, 10950,  8963, 11248,  8005, 11726,  9763, 10397,
           9445,  8071,  5957,  7103,  8079, 11425,  7302,  9838,  9682,
          11353,  7878, 10354,  8791,  8461,  7980]
   len_samples = 493905
   a = {'N': 481884, '~': 5329, 'V': 4128, '+': 618, 's': 551, 'T': 550, 'S': 387, 'F': 343, '"': 86, '|': 15, 'Q': 8, 'n': 5, 'a': 1}

   并将他们两个同步读取融合：

   a = {'N'，'~', 'V', '+', 's', 'T', 'S', 'F',}

   a= {0: 10000, 1: 8620, 2: 4313, 5: 1323, 6: 1082, 4: 1070, 3: 672, 7: 348}
   len_dataset = [5123,  148,   76,   69,  116,  122,  119,  556,  244,  297,   91,
           165,  352,  152,   54,   34,   84,   73,   76,   95,  161,  119,
            96,  158,   72,  124,  141,   54,  321,  339,   80,  142,  122,
            57,  363,  185, 5052,  227,  166,  126,  270,  272,   86,  134,
            65,  196,  127,  482,   92,   86,   82,  140,  272,   52,   72,
           125,  124,   49,   22,   67,  558,  724,  414,   33,   48,  255,
           195,  477,   86, 1274,  167,  177,  126,   82,  128,  237,  338,
          1314,  266,  119,  296,  277,  323,  224,   60,  115,  149]
   len_Dataset = 27428

   

   # 最终处理方式

   a= {0: 8700, 1: 8620, 2: 4313, 5: 1323, 6: 1082, 4: 1070, 3: 672, 7: 348}

   由210降为200

   

   [数据库链接](https://physionet.org/content/edb/1.0.0/)

   论文使用了双导联数据，使用了
   在mil导联，共3类数据（['N',  'S' , 'V']），每一类7000，共21000，35个样本
   在V5导联，共4类数据('N',  'S' , 'V', 'F'),每一类7000，共28000，46个样本
   在双导联读取中，依然是采取每一类数据7000.共21000，81个样本

   

4. sudden-cardiac-death-holter-database：采样率250hz，最终下采样到200hz   sddb  23个样本

   ==未进行类别选择：==

   len_sample = [131512,  61364, 121402,  69276,  27310, 100564,  77235,  63698,
           74431,  31394, 109216,  22086, 115575, 124864, 118668,  99452,
           17233,  92813, 147362,  94840,  64254,  82094,  47598]
   len_samples = 1894241
   a = {'N': 1787515, 'r': 58820, 'S': 22085, 'V': 19569, 's': 3577, '?': 1150, '+': 1019, 'E': 417, 'Q': 89}

   ==进行类别选择==

   a = {'N', 'r', 'S', 'V', 's', '+', 'E'}
   

   # 最终处理方式

   a = {0.0: 60000, 1.0: 58793, 2.0: 22082, 3.0: 19553, 4.0: 3577, 5.0: 1018, 6.0: 413}

   

   [数据库链接](https://physionet.org/content/sddb/1.0.0/)

   论文使用了12个记录，共7类数据('N','B', 'F', 'J',  'S', 'V', 'f'),每一类7000个样本，共49000个

5. mit-bih-normal-sinus-rhythm-database：正常窦性心律数据库   nsrdb   ==采样频率为128hz==，数据较多，每个样本暂时选择了500个，共18个样本
   numberSet_nsrdb = ['16265', '16272', '16273', '16420', '16483', '16539', '16773', '16786', '16795',
                      '17052', '17453', '18177', '18184', '19088', '19090', '19093', '19140', '19830']

   ==没有进行类别选取前：==

   len_sample = [100955,97146,90097,102436,104561,108674,112897,101739,87678,
                 88002,101173,117004,102672,117880,81953,83670,96992,111263]
   len_samples = 1806792

   ==进行了类别选取：==  只有N类别

   len_dataset = [98252, 86083, 87850, 100069, 102339, 106278, 80713, 99609, 85034,
                  85364, 98675, 113963, 100346, 96211, 79459, 73389, 94680, 107448]
   len_Dataset = 1695762

   ### 最后处理方式：

   每个样本截取80个点，并上采样到200，每个记录只截取30000个样本

   

   [数据库链接](https://physionet.org/content/nsrdb/1.0.0/)

   采样率预计是和mit-bih其他数据库的采样率是一样的

6. MIT-BIH Atrial Fibrillation Database：心房颤动数据库  afdb   ==采样率为250HZ==  全为心房颤动，共有1128561个记录，样本数有23个

   类别只有N

   len_sample = [49881,59293,47873,45515,42860,56594,39298,43356,
                 36793,39934,59552,55155,61915,44005,61760,45534,
                 55189,36599,58856,39850,53646,34837,60266]
   len_samples = 1128561

   numberSet_afdb =['04015', '04043', '04048', '04126', '04746', '04908', '04936',
                     '05091', '05121', '05261', '06426', '06453', '06995', '07162',
                     '07859', '07879', '07910', '08215', '08219', '08378', '08405',
                     '08434', '08455']

   ### 最终处理方式：

   每个样本截取210个点，并下采样到200，每个记录只截取30000个样本

   

   

   [数据库链接](https://physionet.org/content/afdb/1.0.0/)

7. mit-bih-supraventricular-arrhythmia-database：室上性心律失常数据库  svdb  采样率为128hz

   numberSet_svdb = ['892','893','805','886','856','894','884','845','853','889',
                     '823','806','890','872','878','863','861','877','848','811',
                     '891','860','854','844','871','809','855','879','843','864',
                     '851','883','882','847','802','829','822','800','852','881',
                     '874','869','887','885','866','820','857','850','859','888',
                     '849','868','810','807','867','846','873','876','875','828',
                     '801','824','840','870','821','808','858','826','804','841',
                     '812','862','825','880','865','827','842','803']

   共78个记录

   ==未进行类别选择：==

   len_sample =  [2857, 2528, 2418, 2223, 2876, 2434, 3022, 2887, 2245, 1738, 2864,
                  3023, 2174, 1981, 1927, 3129, 2582, 2038, 4289, 1436, 2779, 2463,
                  3109, 1709, 1803, 2560, 2577, 2089, 2708, 1907, 2769, 1822, 1935,
                  1836, 1679, 1968, 2337, 1921, 2665, 2302, 2240, 2163, 2822, 2054,
                  2666, 2356, 2610, 1840, 3557, 2350, 2161, 3445, 1946, 1954, 3000,
                  1685, 1684, 2142, 2052, 1913, 2577, 2419, 2391, 2791, 3135, 1777,
                  2187, 2661, 2888, 1854, 1873, 2597, 2798, 3487, 3701, 1862, 2559,
                  2071]

   len_samples =187877

   ```
   Counter({'N': 162339, 'S': 12188, 'V': 9943, '|': 2211, '~': 1082, 'Q': 79, 'F': 23, 'J': 9, '+': 1, 'B': 1, 'a': 1})
   ```

   ==进行类别选择，仅保留['N','V','S','|']==：

   len_Dataset = 185134

   a = {0: 160971, 1: 12104, 2: 9867, 3: 2192}

   len_dataset = [2828, 2508, 2398, 2203, 2840, 2350, 2987, 2865, 2213, 1694, 2844,
                  3001, 2154, 1961, 1891, 3104, 2505, 2018, 4243, 1415, 2751, 2423,
                  2993, 1689, 1779, 2533, 2526, 2049, 2688, 1875, 2739, 1802, 1915,
                  1785, 1655, 1948, 2317, 1872, 2644, 2250, 2220, 2141, 2691, 1979,
                  2646, 2335, 2568, 1818, 3523, 2314, 2120, 3322, 1922, 1922, 2980,
                  1663, 1647, 2122, 2031, 1893, 2489, 2399, 2369, 2738, 3111, 1757,
                  2165, 2641, 2818, 1831, 1831, 2556, 2778, 3467, 3643, 1842, 2539,
                  2048]

   ### 最后处理方式

   a = {0: 12104, 1: 12104, 2: 9867, 3: 2192}

   类别上我们依然选择是的这几个样本， 但是对正向样本(N)的最大数量做限制到12104，同时与上面两个数据处理对正样本处理方式一一致，分开截取正样本，

   每个样本截取80个点，并上采样到200

   

   [数据库链接](https://physionet.org/content/svdb/1.0.0/)

8. mit-bih-malignant-ventricular-ectopy-database：恶性室性异位数据库  vfdb  采样频率250hz

   numberSet = ['427', '607', '611', '418', '612', '430', '614', '424', '602',
                '419', '609', '423', '428', '420', '615', '610', '426', '422',
                '425', '429', '421', '605']

   共22个样本

   # ==**由于标签信息位置，不可用**==

   

   

   [数据库链接](https://physionet.org/content/vfdb/1.0.0/)

9. mit-bih-noise-stress-test-database：噪声压力测试数据  nstdb  

   # ==**使用不到**==

   [数据库链接](https://physionet.org/content/nstdb/1.0.0/)

10. mit-bih-long-term-ecg-database：该数据库包含 7 个长期心电图记录（每个 14 至 22 小时），并带有手动检查的心跳注释。    ltdb    采样频率128hz      样本数有7个

    numberSet = ['14157', '14046', '14134', '14184', '14149', '15814', '14172']

    clf = {'N': 600232, 'V': 64095, 'F': 2908, 'S': 1350, '~': 1117, 'J': 149, 'a': 1}

    总数量 669852

    选择使用： N,V,F,S这几类数据

    len_dataset = [ 88085, 115257,  49612, 101523, 144798, 103334,  65838]
    len_Dataset = 668447

    ```
    {N: 600110, S: 1350, V: 64081, F: 2906}
    ```

    

    # 最后处理方式

    将N的数量调整为和V一样并平均分配开

    每个样本截取80个点，并上采样到200

    

    

    [数据库链接](https://physionet.org/content/ltdb/1.0.0/)

11. mit-bih-ecg-compression-test-database:这个数据库包含168个简短的心电图记录(每个20.48秒) ，这些记录对心电图压缩器，特别是有损数据压缩方法提出了各种挑战。   cdb

    采样率 250hz   168个样本

    # ==**没有注释文件，不使用**==

    [数据库链接](https://physionet.org/content/cdb/1.0.0/)

12. aha-database-sample-excluded-record:aha的部分数据   ahadb  

    采样率：250hz  记录2条

    数据集记录的r波位置较为靠后，应该是前边的均为正常，这里我们就根据数据集特点，只截取有标注的数据即可

    a = {'N': 4328, 'V': 228}

    len_sample = [2278, 2278]
    len_samples =4556

    # 最终处理方式

    a = {0: 4290, 1: 226}

    下采样  210到200 ，直接保存即可

    

    

    [数据库链接](https://physionet.org/content/ahadb/1.0.0/)

13. paf-prediction-challenge-database: PAF 预测挑战数据库，==采样率：128HZ==
    这个双通道心电图记录数据库是为2001年心脏病学计算机挑战赛而创建的，这是一项公开竞赛，旨在开发预测阵发性心房颤动（PAF）的自动化方法。有关比赛的信息，请参阅挑战[公告](https://physionet.org/challenge/2001/)，并请参阅[预测心房颤动的发作](https://physionet.org/content/afpdb/1.0.0/paf.shtml)，以简要概述临床问题、其重要性以及进一步阅读该主题的建议。  afpdb

    训练集50个样本，共200个数据  带c的文件是不带c的文件大小的1/6
    测试集50个样板，共100个数据，没有带c的文件

    ==训练集：==
    ['ECG0', 'ECG1']
    len_samples = 271435
    ==**读取完的数据**==

    len_dataset = [2571,  263, 2251,  175, 2294,  215, 2314,  218, 2945,  304, 2806,
            404, 1569,   94, 1676,  112, 2644,  260, 2101,  255, 1918,  152,
           2006,  161, 2021,  185, 2510,  243, 3180,  363, 3124,  355, 1674,
             99, 1631,  116, 1252,   54, 1187,   27, 2019,  127, 2066,  176,
           3096,  338, 2879,    0, 2783,  287, 1801,  143, 1654,    0, 1480,
            199, 2553,  171, 1626,  121, 2216,  181, 2071,  163, 2549,  246,
           2377,  185, 1959,  250, 1864,  134, 2167,  181, 1987,  207, 1701,
            110, 2091,  140, 2148,  197, 1355,   62, 2221,  194, 2126,  152,
           1392,   67, 1527,  116, 1340,   33, 1132,   20, 1940,  157, 1966,
            157, 2135,  192, 2224,  294, 2628,  267, 2327,  325, 2819,  308,
           2906,  328, 1922,  158, 2261,  234, 1768,  132, 1847,  140, 1833,
            130, 1764,  134, 1902,  187, 1503,   92, 2871,  282, 2712,  325,
           1592,   98, 1653,  140, 1887,  157, 2231,  275, 2040,  183, 1950,
            163, 1666,  110, 1603,  132, 2352,  230, 2215,  228, 2171,  205,
           2123,  375, 1502,   78, 1390,  146, 2255,  210, 2535,  207, 2972,
            299, 2897,  324, 1630,  114, 1918,  493, 2135,  192, 2224,  295,
           1922,  142, 1925,  300, 2176,  187, 2219,  401, 2734,  283, 2662,
            335, 2526,  222, 2208,  378, 2834,  297, 2965,  357, 1610,  103,
           1721,  252]
    len_Dataset = 231633

    

    # 最终处理方式

    

    ```
    Counter({0: 130131, 1: 137304})  0为N  P为PFA
    注意我们只用了训练集，因为测试集没有标签，但是后续是否可用于预测呢？
    ```
    
    数据库分为*学习集*（名称为 n* 和 p* 的记录）和*测试集*（名称为 t*** 的记录）。
    
    学习集由 50 个记录集组成。每个记录集包含两个具有连续记录名称的 30 分钟记录（例如，p15 和 p16），以及两个名称以 c 结尾的 5 分钟“延续”记录（例如，p15c 和 p16c）。每个记录集中的所有四条记录都是单个受试者的较长时间连续心电图记录的摘录;50个记录集来自48个不同的主题。
    
    名称以p开头的记录来自患有阵发性心房颤动（PAF）的受试者。每对 30 分钟记录中的第二条（偶数）记录包含紧接在 PAF 发作前的心电图，这可以通过检查相同编号的持续记录来验证。因此，例如，记录p16紧接在记录p16c中的PAF发作之前。该组的第一个（奇数）记录（例如，记录 p15）包含 30 分钟的心电图，该时间段远离任何 PAF 发作（在 30 分钟记录开始之前或结束后的 45 分钟内没有 PAF）。相应的 5 分钟连续记录（例如，记录 p15c）显示（至少！）紧跟在“PAF-远距离”记录之后的分钟不包含 PAF。**注意：**请注意，该组中的一些 30 分钟记录可能包含非常短的 PAF 突发，这些突发在编译学习集时没有引起注意。
    
    名称以n开头的记录来自没有记录心房颤动的受试者，无论是在记录摘录期间还是在任何其他时间。受试者包括健康对照组、转诊进行长期动态心电图监测的患者以及重症监护病房的患者。
    
    测试集同样由 50 个记录集（来自 50 个不同的科目）组成;与学习集不同，没有延续记录。测试集记录命名为 t01、t02、...T100.与学习集一样，成对的连续编号记录来自单个受试者的相同长期心电图记录。测试集中大约一半的记录集来自患有 PAF 的受试者;挑战的第 1 部分是识别这些记录集，第 2 部分是确定每对中的哪条记录紧接在 PAF 之前。
    
    每个记录关联多个文件。名称为***.dat的文件包含数字化ECG（每个样本16位，每对中最低有效字节优先，每秒每个信号128个样本，来自每个通道的样本交替，标称值为每毫伏200 A / D单位）。.hea文件是（文本）头文件，指定相关信号文件的名称和格式;本网站提供的软件需要这些头文件。.qrs文件是机器生成的（二进制）注释文件，为那些不希望使用自己的QRS探测器的人提供方便。请注意，.qrs文件未经审核，包含错误。如果您希望研究对少量QRS检测误差具有鲁棒性的PAF预测方法，则可以以未更正的形式使用这些注释，或者您可以完全忽略这些注释并直接从信号文件中工作。
    
    
    
    [数据库链接](https://physionet.org/content/afpdb/1.0.0/)



# 数据探索



