## 注意

==**心电心音分类论文中，心音的长度以3s的长度进行0%重叠划分。而心音分类论文中，心音的长度以2s的长度进行50%重叠划分，故在心音分类论文中，数据划分完的长度至少为前者的3倍或以上——仅针对C2016数据集。**==

```python
原始采样率为2k。以C2016的异常数据举例，心电心音分类论文的总数量为 3380+1127+1127 = 5634，而在心音分类论文中，总数量为 17101，为前者的3.035倍，符合划分规范。前者的划分过程首先将数据的采样率均变为2k，接着0%重叠截取3s的长度，继而继续降采样3倍，保持数据的长度为2k；后者的划分过程是数据采样率变为2k，按照50%重叠截取2s的长度，此时数据长度为4k，就ok了，对于长度不足2s的数据则直接进行舍弃。
原始采样率为8k。以Y2018的异常数据举例，前者为 (120+40+40)*4 = 800,后者为 (162+35+35)+(131+28+29)+(138+30+30)+(129+28+28) = 232+188+198+185 = 803。此处前者的划分过程是读取数据，直接将长度变为2k，然后就是用了；后者保持和上文一样。而因为该数据集每个长度均为2s-3s之间，所以两者差距不大，仅极个别数据长度超过了3s。
K2016数据集：set_a采样率为44100，set_b采样率为4000。前者为 (217+73+73) + (554+185+185) + (192+64+64) = 363+924+320 = 1607, 后者为 (69+15+15)+(557+120+120)+(196+42+42) = 99+797+280 = 1176。 前者的划分方式是无论对于这两个数据集中的那个，长度小于1s的，我们就直接将其长度重采样至2000，长度大于1s的先将采样率降至2k，接着以1s长度为单位进行切割，得到其余的数据，且长度均为2k；后者去除了set_b中的extrastole类别，接着以前述的同样方法读取数据。因为有部分数据长度小于1s或介于1s-2s之间，所以造成了后者读取到的数据比前者少了一部分。
Mfour数据集：采样率为44100。原始数据是mp3文件，在读取数据时需要先将其转为wav文件。前者长度为(109+37+37)+(421+140+141)+(162+54+54) = 183+702+270 = 1155，后者长度为(125+28+27)+(483+104+104)+(186+40+40) = 180+691+266 = 1137。对于前者来说，我们先将其采样率降至2k，接着以1s的长度为单位进行截取，最终数据的长度均为2k。后者和上文保持一样，但是最终论文并没有使用，因为准确率全到了100%，不太适合发表文章，故去除了。
```



