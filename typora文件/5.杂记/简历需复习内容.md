# ==简历内容复习==

#### 目录：

```
机器学习算法(线性回归、逻辑回归、朴素贝叶斯、支持向量机、决策树、回归树、随机森林、Kmeans、主成分分析、DBSCN、AdaBoost、GBDT、XGBoost、LightGBM)
深度学习经典模型（CNN理解、LeNet、AlexNet、VggNet、GoogLeNet、ResNet、Densenet、MobileNet、卷积神经网络知识总结）
强化学习基础知识
心电心音特征提取（心电特征提取方式、心音特征提取函数、心电心音同步特征提取）
项目内容（山西省研究生创新项目、面向多模态心音心电信号的心脏健康智能诊断系统研究、面向新冠病毒非侵入式心电心音检测系统）
论文内容（Multiclassification for heart sound signals under Multiple networks and Multi-view feature、A Pooling Convolution Model for Multi-classification of ECG and PCG Signals、Improving ECG Classification Performance byUsing an Optimized One-Dimensional ResidualNetwork Model)
竞赛内容
其余小知识
英语的学习
工作
```




1. #### 机器学习算法   [参考链接](https://blog.csdn.net/weixin_41395763/article/details/123112423)

   * ==**线性回归**==

     **线性回归是一种评估自变量X与因变量Y之间的关系**
     画出的图像是直的（二维线性回归是直线，多维线性回归是超平面)
     <img src="../../../AppData/Roaming/Typora/typora-user-images/image-20231208195247476.png" alt="image-20231208195247476" style="zoom: 67%;" />

   * ==**使用最小二乘法求解线性回归问题**==

     最小二乘法是一种常用线性回归方法，用于求解参数向量 $x$，使得预测值与真实值之间平方误差最小化。

     给定一个线性回归问题，其中矩阵 $A$ 是特征矩阵，向量 $y$ 是真实标签向量。我们的目标是找到一个参数向量 $x$，使得预测向量 $\hat{y} = Ax$ 与真实标签向量 $y$ 之间的平方误差最小化。

     最小二乘法的解可以通过以下公式计算得到：

     $$x = (A^TA)^{-1}A^Ty$$

     其中，$A^T$ 是 $A$ 的转置，$(A^TA)^{-1}$ 是 $A^TA$ 的逆矩阵，$y$ 是真实标签向量。

     需要注意的是，上述公式假设 $A^TA$ 是可逆的。如果 $A^TA$ 不可逆，可能是因为特征矩阵 $A$ 的列之间存在线性相关性。在这种情况下，可以使用正则化方法（如岭回归或LASSO回归）来解决问题。

     通过求解最小二乘法，我们可以得到参数向量 $x$，它代表了线性回归模型中各个特征的权重。利用参数向量 $x$，我们可以计算预测向量 $\hat{y} = Ax$，并通过比较 $\hat{y}$ 和真实标签向量 $y$ 来评估预测结果与真实值之间的差距。

     

   * ==**逻辑回归**==
     逻辑回归是机器学习中的一种分类模型，逻辑回归也是一种分类方法。
     逻辑回归的输入就是一个线性回归的结果。
     输出的结果输入到Sigmoid函数当中
     \>输出结果:[0,1]区间的一个概率值，默认0.5为阈值。
     -y(log [hx]) - (1-y)(log [1-hx])

   * ==**朴素贝叶斯**==    [参考原理](https://zhuanlan.zhihu.com/p/534023669)
     ==原理：== 根据特征的先验概率（训练样本分析得到的概率），利用贝叶斯公式计算出其后验概率（要分类对象特征的条件概率），选择概率值最大的类作为该特征所属的类。
     ==朴素：== 为使模型容易求解，朴素贝叶斯假定各特征是相互独立的，由于这是一个较强的假设，朴素贝叶斯也由此得名，这个假设使得朴素贝叶斯更加简单，但有时会牺牲一定的分类准确率。
     ==分类：== 

     1. ***GaussianNB：高斯朴素贝叶斯***

        假设连续变量服从正态分布，高斯朴素贝叶斯公式适用于“样本特征的分布大部分是连续值”，捕捉少数类的能力较差。

     2. ***BernoulliNB：伯努利朴素贝叶斯***
        假设数据服从伯努利分布，即特征都是二值变量(0,1)，伯努利朴素贝叶斯适用于“二分类问题，即样本特征分布以二元离散值为主”，适用于短文档分类，捕捉少数类的能力较好

     3. ***多项式朴素贝叶斯***

        假设各特征在各类别下服从多项式分布，多项式朴素贝叶斯适用于“样本特征的分布大部分是多元离散值”，捕捉少数类的能力最差。

     4. ***ComplementNB：补集朴素贝叶斯***

        是多项式朴素贝叶斯的改进，解决了样本不均衡问题，且在一定程度上逃避了“朴素”假设   即特征之间是有条件独立的，在文本分类上结果通常比多项式朴素贝叶斯好。

   * ==**支持向量机**==   [参考链接](https://zhuanlan.zhihu.com/p/172429274)
     ==key idea1:==SVM的目标就是找到区别正负样本的边界，使得正负样本到达这条边界的范围最大（模型泛化能力最好）。
     ==key idea2:==根据key idea1，我们知道了我们优化的目标就是找到最宽的那条“路”，“站”在路边的样本，我们称其为支持向量。   在**训练集**中，不允许有点在街道的范围内，通过这条路把训练集中的数据分开。
     我们的key idea2 是针对训练集的要求，key idea1是对任何的样本点。

     ==key idea3:== 求法向量，路的宽。同时满足两个式子 min([||w||^2]/2)  and  y(wx+b) - 1 = 0
     ==key idea4:== 拉格朗日求解求导。
     拉格朗日能够把带限制条件的函数极值算法给变成一个不带条件的函数极值算法。
     ==核方法推导==
     上面的决策边界都是线性的，但是大部分的分类问题都是非线性的。。这个时候，如果有一个变换(phi)，将二维坐标系变换成另一个坐标系。将每一个数做非线性变化，在变换后的空间中做一个线性的分类，就能够顺利的将其分开。也就是说，我们要找到一个非线性变换，使得xi，在变换后的空间里线性可分。

     **为什么使用kernel方法会比找变换的函数方法更高效呢?**

     假设我们用的是RBF核函数，非线性变换会将x的维度映射到无穷维高的，这个是无法描述的，但是我们可以求在这个无穷维空间里两个向量点的点乘，所以核方法更为优秀。

     关键就是让优化目标跟决策函数具备一种非线性变换的能力。

   * ==**决策树**==   [参考链接](https://www.jianshu.com/p/9f8639f18b5d)     [信息熵、信息增益和信息增益率](https://zhuanlan.zhihu.com/p/456025594)   [剪枝等内容](https://zhuanlan.zhihu.com/p/635047542)
     决策树之所以叫决策树，就是因为它的结构是树形状的。
     选择最佳分割特征和分割点的过程通常需要一定的衡量标准。在分类问题中，常用的衡量标准包括基尼不纯度（Gini impurity）和信息增益（information gain），在回归问题中，常用的衡量标准是均方误差（mean squared error）。

     * ID3算法  分支属性度量标准为信息增益  Entropy
     * C4.5算法   分支属性度量标准为信息增益率  
     * C5.0算法 是C4.5的商用版本，目的是对含有大量数据的数据集进行分析，使用了boosting，组合了多个决策树来做分析，准确率大大提高。   提供可选项由使用者情况决定，例如是否考虑样本的权重，样本错误分类成本。
     * CART算法  分支属性度量标准为 Gini系数

   * ==**回归树**==

     回归树用于处理输出为连续型的数据，回归在选取划分点，希望划分的两个分支的误差越小越好。
     每个节点的值为当前多个值的平均。

   * ==**随机森林**==  [随机森林解释](https://zhuanlan.zhihu.com/p/610385434)
     随机森林生成n棵决策树。然后这n棵决策树进行投票或平均得出最终结果，而每棵树的生成方式为随机选取样本，随机选取特征。随机森林既可以用于回归也可以用于分类。
     总的来说就是随机选择样本数，随机选取特征，随机选择分类器，建立多颗这样的决策树，然后通过这几课决策树来投票，决定数据属于哪一类(**投票机制有一票否决制、少数服从多数、加权多数**)

   * ==**Kmeans**==  [原理介绍](https://zhuanlan.zhihu.com/p/78798251)
     K-means 是我们最常用的基于欧式距离的聚类算法，其认为两个目标的距离越近，相似度越大。

   * ==**主成分分析**==  [从公式理解](https://zhuanlan.zhihu.com/p/473417003?utm_id=0)   [主成分分析（PCA）原理总结](https://zhuanlan.zhihu.com/p/500326717?utm_medium=social&utm_oi=918604753129340928)   [【高等数学】通过向量和投影来实现函数的降维](https://mp.weixin.qq.com/s?__biz=MzIzMjI0MzYzMA==&mid=2653104498&idx=5&sn=ae04d8a1d57b77276fdf220767109745&chksm=f34061b3c437e8a5e297b1d3e001921fc890eb9c143b723467f402d038591f9af773a06eb7ff&scene=27)
     主成分分析（Principal Component Analysis，PCA）常用于高维数据的降维。主成分分析主要有两种算法：特征值分解和奇异值分解。**特征值分解**基于样本矩阵的协方差矩阵（对称矩阵）进行，而**奇异值分解**则直接对样本矩阵（非对称矩阵）进行。

     **主成分分析 (Principal component analysis) 是为了探究多个可能相关变量间的相关程度（如体重与身高的关系），寻找最大或最小相关方向，达到数据压缩或去噪目的(降维)**。

   * ==**DBSCAN**==   [基于密度的聚类算法（1）——DBSCAN详解](https://zhuanlan.zhihu.com/p/643338798)
     **DBSCAN简介** DBSCAN（Density-Based Spatial Clustering of Applications with Noise，**具有噪声的基于密度的聚类方法**）是一种典型的基于密度的空间聚类算法。和K-Means，BIRCH这些一般只适用于凸样本集的聚类相比，DBSCAN既可以适用于凸样本集，也可以适用于**非凸**样本集。该算法将具有足够密度的区域划分为簇，并在具有噪声的空间数据库中发现任意形状的簇，它将簇定义为密度相连的点的最大集合。

   * ==**AdaBoost**==   [参考链接](https://blog.csdn.net/weixin_42455006/article/details/122072612)
     boosting：用于分类、回归问题，从弱学习器开始加强，通过加权来进行训练，即一种迭代算法，通过不断使用一个弱学习器弥补前一个弱学习器的“不足”的过程，来串行的构造一个较强的学习器，这个学习器能够使目标函数值足够小，boosting是一种串行算法，具有代表的就是adaboost。
     **adaboost**是一种迭代算法，在每一轮中加入一个新的弱分类器，达到某个预定的足够小的错误率才截止。其核心思想是针对同一个训练集训练不同的分类器（弱分类器），然后把这些弱分类器集合起来，构成一个更强的分类器。
     后面的分类器受着两方面的制约：一个是上一轮没分对的数据在这一轮会被增加权重，一个是在最终决策时要保证一个整体分类较高的水平。

     **Adaboost算法优点：**

     1. 不易发生过拟合
     2. 由于AdaBoost并没有限制弱学习器的种类，所以可以使用不同的学习算法来构建弱分类器；
     3. AdaBoost具有很高的精度； 相对于bagging算法和Random Forest算法，AdaBoost充分考虑的每个分类器的权重；
     4. AdaBoost的参数少，实际应用中不需要调节太多的参数。

     **Adaboost算法缺点：**

     1. 数据不平衡导致分类精度下降
     2. 训练耗时，主要由于多个弱分类器的训练耗时
     3. 弱分类器的数目不好设置
     4. 对异常样本敏感，由于adaboost对错误样本会增加其权值，异常样本会获得高权值，影响最终分类器的精度

   * ==**GBDT**==   [GBDT总结](https://blog.csdn.net/qq_39691463/article/details/120626485)

     GBDT，全名为梯度提升树，使用的是boosting的思想。**GBDT的原理很简单，就是所有弱分类器的结果相加等于预测值，然后下一个弱分类器去拟合误差函数对预测值的残差(这个残差就是预测值与真实值之间的误差)。当然了，它里面的弱分类器的表现形式就是各棵树**。 
     ==基本思想：==   拟合残差

   * ==**XGBoost**==   [参考链接](https://zhuanlan.zhihu.com/p/562983875)   [GBDT、xgboost、LightGBM之间的比较](https://blog.csdn.net/qq_39691463/article/details/122256785)

     为何要有XGBoost算法以及其实主要是因为gbdt在每一次迭代的时候都会遍历整个训练数据多次，一旦数据量过大，如果把所有数据内存，可能会限制训练数据的大小，如果不进内存，反复的读写训练数据又会非常耗时，尤其是面对工业级海量的数据，普通gbdt基本上没办法用。

     **XGBoost是一个可拓展的Tree boosting算法，被广泛用于数据科学领域。**
     XGBoost可以说是GBDT（Gradient Boosting Decision Tree）梯度提升树的一个改进版本。XGBoost中的X代表的就是eXtreme（极致），XGBoost能够更快的、更高效率的训练模型。这就是为什么XGBoost可以说似乎GBDT的一个改进版本。正是得益于XGBoost的高效率，使得她成为数据竞赛中的一大杀器。

   * ==**LightGBM**==(参考上面)

     LightGBM 是微软开发的一款快速、分布式、高性能的基于决策树的梯度 Boosting 框架。

     主要有以下优势：

     1. 更快的训练效率
     2. 低内存使用
     3. 更好的准确率（我对比 XGBoost 没太大差别）
     4. 支持并行学习
     5. 可处理大规模数据




2. #### 深度学习经典模型

   ==通俗理解什么是CNN卷积神经网络==   [通俗理解什么是CNN卷积神经网络](https://blog.csdn.net/weixin_39589455/article/details/114949533)

   ​	CNN解决了什么问题：图像处理的效率，图像在数字化过程中的特征识别准确率不高。
   ​    CNN解决的第一个问题就是把大量参数降维成少量参数，再做处理（可以简单理解为图像像素的降低并不影响识别的效果。）———**引申：对比使用低像素的照片和使用卷积降完像素的照片，是否能找到一些区别？**
   ​     人类的视觉原理：几位科学家**发现了视觉系统的信息处理**，从原始信号摄入开始（瞳孔摄入像素 Pixels），接着做初步处理（大脑皮层某些细胞发现边缘和方向），然后抽象（大脑判定，眼前的物体的形状，是圆形的），然后进一步抽象（大脑进一步判定该物体是只气球）。

   ​    那么我们可以很自然的想到：可以不可以模仿人类大脑的这个特点，构造多层的神经网络，较低层的识别初级的图像特征，若干底层特征组成更上一层特征，最终通过多个层级的组合，最终在顶层做出分类呢？**答案是肯定的，这也是许多深度学习算法（包括CNN）的灵感来源。**
   ​     **卷积层**负责提取图像中的局部特征；**池化层**用来大幅降低参数量级(降维)；**全连接层**类似传统神经网络的部分，用来输出想要的结果。
   ​     **池化层相比卷积层可以更有效的降低数据维度，这么做不但可以大大减少运算量，还可以有效的避免过拟合。**==在写论文时用到的池化我解释为有利于提取特征，因为我并没有使用块里面的池化层进行降维，仅仅使用其进行了最大值的提取，最终的降维用的是一个专门的下采样层。==   **但按照池化层作用来说，之所以泛化效果好，还是有防止过拟合的作用的，这个可以基于它的计算本质联想，他每次都是对取快里面的最大值，相当于忽略了周围的像素，进而防止过拟合。**

   * ==**LeNet**==   [深度学习经典卷积网络](https://blog.csdn.net/weixin_39589455/article/details/114950664)
     LeNet5 这个网络虽然很小，但是它包含了深度学习的基本模块：卷积层，池化层，全连接层。

     LeNet-5是一种用于手写体字符识别的非常高效的卷积神经网络。
     卷积神经网络能够很好的利用图像的结构信息。
     卷积层的参数较少，这也是由卷积层的主要特性即局部连接和共享权重所决定。

   * ==**AlexNet**==

     AlexNet是在LeNet的基础上加深了网络的结构，学习更丰富更高维的图像特征。AlexNet的特点:

     1. 更深的网络结构
     2. 使用层叠的卷积层，即卷积层+卷积层+池化层来提取图像的特征  
     3. 层叠池化（在LeNet中池化是不重叠的，即池化的窗口的大小和步长是相等的，在AlexNet中使用的池化却是可重叠的，也就是说，在池化的时候，每次移动的步长小于池化的窗口长度。）
     4. 使用Dropout抑制过拟合
     5. 使用数据增强Data Augmentation抑制过拟合（神经网络由于训练的参数多，表能能力强，所以需要比较多的数据量，不然很容易过拟合。当训练数据有限时，可以通过一些变换从已有的训练数据集中生成一些新的数据，以快速地扩充训练数据。）
     6. 使用Relu替换之前的sigmoid的作为激活函数 (虽然ReLU是一个线性的分段函数，本身没有带来非线性关系，但是**每个训练样本使用的线性变换矩阵Mi是不一样的，经过矩阵累乘，在整个训练样本空间来说，其经历的是非线性变换。**)
     7. 多GPU训练
     8. 局部响应归一化  [参考链接](https://zhuanlan.zhihu.com/p/434773836)   [inter前缀的意思，inter和intar有什么区别](https://kaoyan.xhd.cn/yingyu/173003.html)
        整理来讲分类通道内的局部归一化和通道间的局部归一化，通道内的话就是考虑以当前点为中心的方阵，通道外的话就是其他通道对应位置的值。

   * ==**VGGNet**==

     2014年，牛津大学计算机视觉组（Visual Geometry Group）和Google DeepMind公司的研究员一起研发出了新的深度卷积神经网络：VGGNet，并取得了ILSVRC2014比赛分类项目的第二名（第一名是GoogLeNet，也是同年提出的)。论文主要针对卷积神经网络的深度对大规模图像集识别精度的影响，主要贡献是使用很小的卷积核(3×3)构建各种深度的卷积神经网络结构，并对这些网络结构进行了评估，最终证明16-19层的网络深度，能够取得较好的识别精度。 这也就是常用来提取图像特征的VGG-16和VGG-19。

     VGG可以看成是加深版的AlexNet，整个网络由卷积层和全连接层叠加而成，和AlexNet不同的是，VGG中使用的都是小尺寸的卷积核(3×3)。

     VGG中使用的都是3×3卷积核，并且使用了连续多个卷积层。这样做的好处：
     使用连续的的多个小卷积核(3×3)，来代替一个大的卷积核——例如(5×5)。
     使用小的卷积核的问题是，其感受野必然变小。所以，VGG中就使用连续的3×3卷积核，来增大感受野。VGG认为2个连续的3×3卷积核能够替代一个5×5卷积核，三个连续的3×3能够代替一个7×7。

     ==特点：==  结构简单，小卷积核和连续的卷积层，小池化核，通道数更多，特征度更宽，层数更深，测试阶段全连接转为卷积等

     **VGG优点**

     1. VGGNet的结构非常简洁，整个网络都使用了同样大小的卷积核尺寸（3x3）和最大池化尺寸（2x2）。
     2. 几个小滤波器（3x3）卷积层的组合比一个大滤波器（5x5或7x7）卷积层好：
     3. 验证了通过不断加深网络结构可以提升性能

     **VGG缺点**

     1. VGG耗费更多计算资源，并且使用了更多的参数（这里不是3x3卷积的锅），导致更多的内存占用（140M）。其中绝大多数的参数都是来自于第一个全连接层。VGG可是有3个全连接层啊！

   * ==**GoogLeNet**==

     *V1*:

     1. 一般来说，提升网络性能最直接的办法就是增加网络深度和宽度，这也就意味着巨量的参数。但是，巨量参数容易产生**过拟合**也会大大增加**计算量**。

     2. 这篇文章认为解决上述两个缺点的根本方法是将全连接甚至一般的卷积都转化为稀疏连接。一方面现实生物神经系统的连接也是稀疏的，另一方面有文献1表明：对于大规模稀疏的神经网络，可以通过分析激活值的统计特性和对高度相关的输出进行聚类来逐层构建出一个最优网络。这点表明臃肿的稀疏网络可能被不失性能地简化。 虽然数学证明有着严格的条件限制，但Hebbian准则有力地支持了这一点：fire together,wire together。

     3. 所以，现在的问题是有没有一种方法，**既能保持网络结构的稀疏性，又能利用密集矩阵的高计算性能**。大量的文献表明可以将稀疏矩阵聚类为较为密集的子矩阵来提高计算性能，据此论文提出了名为Inception 的结构来实现此目的。

     4. Inception 结构的主要思路是怎样用密集成分来近似最优的局部稀疏结构。

        对Inception架构图做如下说明：
        1 . 显然GoogLeNet采用了模块化的结构，方便增添和修改；
        2 . 网络最后采用了average pooling来代替全连接层，想法来自NIN,事实证明可以将TOP1 accuracy提高0.6%。但是，实际在最后还是加了一个全连接层，主要是为了方便以后大家finetune；
        3 . 虽然移除了全连接，但是网络中依然使用了Dropout ;
        4 . 为了避免梯度消失，网络额外增加了2个辅助的softmax用于向前传导梯度。文章中说这两个辅助的分类器的loss应该加一个衰减系数，但看caffe中的model也没有加任何衰减。此外，实际测试的时候，这两个额外的softmax会被去掉。

     *V2*

     1. 14年以来，构建更深的网络逐渐成为主流，但是模型的变大也使计算效率越来越低。这里，文章试图找到一种方法在**扩大网络的同时又尽可能地发挥计算性能。**

     2. GoogLeNet的表现很好，但是，如果想要通过简单地放大Inception结构来构建更大的网络，则会立即提高计算消耗。此外，在V1版本中，文章也没给出有关构建Inception结构注意事项的清晰描述。因此，在V2中作者首先给出了一些已经被证明有效的用于放大网络的通用准则和优化方法。这些准则和方法适用但不局限于Inception结构。

     3. **General Design Principles**(下面的准则来源于大量的实验，因此包含一定的推测，但实际证明有效)

        * **1 . 避免表达瓶颈，特别是在网络靠前的地方**。 

          信息流前向传播过程中显然不能经过高度压缩的层，即表达瓶颈。从input到output，feature map的宽和高基本都会逐渐变小，但是不能一下子就变得很小。比如你上来就来个kernel = 7, stride = 5 ,这样显然不合适。另外输出的维度channel，一般来说会逐渐增多(每层的num_output)，否则网络会很难训练。（特征维度并不代表信息的多少，只是作为一种估计的手段）

        * **2 . 高维特征更易处理。** 高维特征更易区分，会加快训练。

        * **3. 可以在低维嵌入上进行空间汇聚而无需担心丢失很多信息。** 比如在进行3x3卷积之前，可以对输入先进行降维而不会产生严重的后果。假设信息可以被简单压缩，那么训练就会加快。

        * **4 . 平衡网络的宽度与深度。** 上述的这些并不能直接用来提高网络质量，而仅用来在大环境下作指导。

        * **5.使用简单的卷积核代替复杂的卷积核。** 于是，任意nxn的卷积都可以通过1xn卷积后接nx1卷积来替代。实际上，作者发现**在网络的前期使用这种分解效果并不好，还有在中度大小的feature map上使用效果才会更好**。（对于mxm大小的feature map,建议m在12到20之间）。

        * ==值得思考的是==：可以在输入数据刚进入网络的时候先使用几个3x3卷积+池化+非线性激活函数来控制一下长和宽

   * ==**ResNet**==
     **前言：**

     1. ResNets要解决的是深度神经网络的“退化”问题。我们知道，对浅层网络逐渐叠加layers，模型在训练集和测试集上的性能会变好，因为模型复杂度更高了，表达能力更强了，可以对潜在的映射关系拟合得更好。而“退化”指的是，给网络叠加更多的层后，性能却快速下降的情况。
     2. 训练集上的性能下降，可以排除过拟合，BN层的引入也基本解决了plain net（纯卷积网络）的梯度消失和梯度爆炸问题。如果不是过拟合以及梯度消失导致的，那原因是什么？
     3. 按道理，给网络叠加更多层，浅层网络的解空间是包含在深层网络的解空间中的，深层网络的解空间至少存在不差于浅层网络的解，因为只需将增加的层变成恒等映射，其他层的权重原封不动copy浅层网络，就可以获得与浅层网络同样的性能。更好的解明明存在，为什么找不到？找到的反而是更差的解？
     4. 显然，这是个优化问题，反映出结构相似的模型，其优化难度是不一样的，且难度的增长并不是线性的，越深的模型越难以优化。
     5. 有两种解决思路，一种是调整求解方法，比如更好的初始化、更好的梯度下降算法等；另一种是调整模型结构，让模型更易于优化——改变模型结构实际上是改变了error surface的形态。
     
     ![在这里插入图片描述](https://img-blog.csdnimg.cn/20210317223853801.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zOTU4OTQ1NQ==,size_16,color_FFFFFF,t_70)
     
     **ResNet的设计有如下特点：**

     1. 与plain net相比，ResNet多了很多“旁路”，即shortcut路径，其首尾圈出的layers构成一个Residual Block；
     2. ResNet中，所有的Residual Block都没有pooling层，降采样是通过conv的stride实现的；
     3. 分别在conv3_1、conv4_1和conv5_1 Residual Block，降采样1倍，同时feature map数量增加1倍，如图中虚线划定的block；
     4. 通过Average Pooling得到最终的特征，而不是通过全连接层；
     5. 每个卷积层之后都紧接着BatchNorm layer，为了简化，图中并没有标出；
     6. ResNet结构非常容易修改和扩展，通过调整block内的channel数量以及堆叠的block数量，就可以很容易地调整网络的宽度和深度，来得到不同表达能力的网络，而不用过多地担心网络的“退化”问题，只要训练数据足够，逐步加深网络，就可以获得更好的性能表现。
     
     **Residual Block的分析与改进**
     
     1. **注意，这里的视角与之前不同，这里将shortcut路径视为主干路径，将残差路径视为旁路。**
     
     2. 新提出的Residual Block结构，具有更强的泛化能力，能更好地避免“退化”，堆叠大于1000层后，性能仍在变好。
     
     3. **通过保持shortcut路径的“纯净”，可以让信息在前向传播和反向传播中平滑传递，这点十分重要。为此，如无必要，不引入1×1卷积等操作，同时将上图灰色路径上的ReLU移到了F(x)路径上。**
     
     4. **在残差路径上，将BN和ReLU统一放在weight前作为pre-activation，获得了“Ease of optimization”以及“Reducing overfitting”的效果。 **
     
     5. 令h(xl)为shortcut路径上的变换，f为addition之后的变换，原Residual Block中f=ReLU，**当h和f均为恒等映射时，可以得到任意两层xL和xl之间的关系，此时信息可以在xl和xL间无损直达。**
     
     6. **需要注意的是，BN层解决了plain net的梯度消失和爆炸，这里的1可以避免short cut 路径上的梯度消失和爆炸。**
     
     7. **shortcut路径将反向传播由连乘形式变为加法形式**
     
     8. **从信息通路上讲尚不彻底——由此也诞生了DenseNet。**
     
     9. 对于残差路径的改进，作者进行了不同的对比实验，最终得到了**将BN和ReLU统一放在weight前的full pre-activation结构。**
     
     10. ResNet的动机在于解决“退化”问题，残差块的设计让学习恒等映射变得容易，即使堆叠了过量的block，ResNet可以让冗余的block学习成恒等映射，性能也不会下降。所以，网络的“实际深度”是在训练过程中决定的，即ResNet具有某种深度自适应的能力。
     
         深度自适应能解释不会“退化”，但为什么可以更好？
     
         通过可视化error surface，我们看到了shortcut的平滑作用，但这只是结果，背后的根由是什么？
     
         也许彻底搞懂ResNet还需要进一步地研究，但已有很多不同的理解角度，
     
         微分方程的角度，[A Proposal on Machine Learning via Dynamical Systems](https://link.springer.com/article/10.1007/s40304-017-0103-z)
         ensemble的角度，[Residual Networks Behave Like Ensembles of Relatively Shallow Networks](https://arxiv.org/pdf/1605.06431.pdf)
         信息/梯度通路的角度，[Identity Mappings in Deep Residual Networks](https://arxiv.org/abs/1603.05027)
         类比泰勒展开、类比小波……
     
   * ==**DenseNet**==  [参考链接](https://blog.csdn.net/weixin_55073640/article/details/128597990)
     **前言**

     ```
     DenseNet模型的基本思路与ResNet一致，但它建立的是前面所有层与后面层的密集连接（即相加变连结），它的名称也是由此而来。
     DenseNet的另一大特色是通过特征在通道上的连接来实现特征重用。这些特点让DenseNet的参数量和计算成本都变得更少了（相对ResNet），效果也更好了。
     ResNet解决了深层网络梯度消失问题，它是从深度方向研究的。宽度方向是GoogleNet的Inception。而DenseNet是从feature入手，通过对feature的极致利用能达到更好的效果和减少参数。
     DenseNet斩获CVPR 2017的最佳论文奖。
     k —— DenseNet中的growth rate(增长率)，这是一个超参数。一般情况下使用较小的k（比如12)，就可以得到较佳的性能。假定输入层的特征图的通道数为k0，那么L层输入的channel数为 k0+k*(L-1)，因此随着层数增加，尽管k设定得较小，DenseBlock中每一层输入依旧会越来越多。
     另外一个特殊的点：DenseBlock中采用BN+ReLU+Conv的结构，平常我们常见的是Conv+BN+ReLU。这么做的原因是：卷积层的输入包含了它前面所有层的输出特征，它们来自不同层的输出，因此数值分布差异比较大，所以它们在输入到下一个卷积层时，必须先经过BN层将其数值进行标准化，然后再进行卷积操作。
     ```

     ### Transition层

         它主要用于连接两个相邻的DenseBlock，整合上一个DenseBlock获得的特征，缩小上一个DenseBlock的宽高，达到下采样效果，特征图的宽高减半。Transition层包括一个1x1卷积（用于调整通道数）和2x2AvgPooling（用于降低特征图大小），结构为BN+ReLU+1x1 Conv+2x2 AvgPooling。因此，Transition层可以起到压缩模型的作用 。
     ## DenseNet优缺点

     ```
     1、优点
     （1）相比ResNet拥有更少的参数量
     参数减少，计算效率更高，效果更好（相较于其他网络）
     （2）传播与预测都保留了低层次的特征
     在以前的卷积神经网络中，最终输出只会利用最高层次的特征。而DenseNet实现特征重用，同时利用低层次和高层次的特征。
     （3）旁路加强了特征的重用，导致直接的监督
     因为每一层都建立起了与前面层的连接，误差信号可以很容易地传播到较早的层,所以较早的层可以从最终分类层获得直接的监督。
     （4）网络更易于训练，并具有一定的正则化效果
     （网上资料都有说这一句，但是我不太清楚他是怎么体现正则化效果的）
     （5）缓解了梯度消失/爆炸和网络退化的问题
     特征重用实现了梯度的提前传播，也至少保留了前面网络的能力，不至于变弱（最少也是个恒等变换）
     
     2、不足
     (1) 由于需要进行多次Concatnate操作，数据需要被复制多次，显存容易增加得很快，需要一定的显存优化技术。因此在训练过程中，训练的时间要比Resnet作为backbone长很多。所以相对而言，ResNet更常用。
     (2) ResNet更加的简洁，变体也多，更加成熟，因此后来更多使用的是ResNet，但是DenseNet的思想贡献也是如今很常见的
     ```

     

   * ==**MobileNet V1**==
     **前言**
     以上现在流行的CNN，如AlexNet、VGG、ResNet，虽然识别效果不错，但是模型的参数量和计算量巨大，不适合在移动端、嵌入式设备上运行。所以就出现了更轻量级更快速的的CNN设计，这里要讲述的是谷歌的MobileNet系列工作。

     paper https://arxiv.org/abs/1704.04861
     MobileNet 由谷歌在 2017 年提出，是一款专注于在移动设备和嵌入式设备上的 轻量级 CNN神经网络，并 迅速 衍生了 v1 v2 v3 三个版本；

     相比于传统的 CNN 网络，在准确率小幅降低的前提下，大大减小模型参数和运算量；一句话概括，**V1 就是 把 vgg 中标准卷积层 换成了 深度可分离卷积；**

     **模型亮点：**

     1. 深度可分离卷积，大大减少参数量
     2. 增加超参 α、β

     **可分离卷积**
     可分离卷积大致可以分为 空间可分离 和 深度可分离；
     **空间可分离**类似于：
     ![在这里插入图片描述](https://img-blog.csdnimg.cn/20210317224808726.png)

     **深度可分离**
     深度可分离 由 深度卷积 + 逐点卷积 组成；

     总结一句话，就是 **V1 效果不输其他网络，但计算量和参数量大大降低；**

   * ==**MobileNet V2**==

     **前言**
     paper https://arxiv.org/abs/1801.04381
     MobileNetV2 是由 谷歌 在 2018 年提出，相比 V1，准确率更好，模型更小；

     **模型亮点：**

     1. Inverted Residuals（==倒残差结构==）——并不是所有的block都加上了残差连接，只有当stride=1且输入特征矩阵与输出特征矩阵相同时才有shortcut连接。

     2. Linear bottlenecks——作者经过研究，发现在 V1 中 depthwise 中有 0 卷积的原因就是 Relu 造成的，换成 Linear 解决了这个问题；

     3. **结论就是 Relu 对低维信号 损失很大**——==考虑在网络初期不使用ReLU激活函数，换用ReLu6？==

     4. 回想一下 深度卷积，深度卷积是单通道卷积，只有 1 维，经过 relu 后，即使是 融合后再 Relu 也只有 3 维，信号损失很大，如果学到的信号完全没有用，那就不用学了， w 自然是 0 ；

        问题又来了，既然 depthwise 时 relue 造成了信号损失，为什么不换 DW 的 relue，而是把 逐点卷积 的 激活函数 换成 Linear 了？

        * 首先 dw 的 relu 造成 大量损失是因为 Input 的 channel 太少了，如果 Input 的 channel 不少呢，就不损失了，那就没问题了，所以重点不是换不换 relue，是解决 低 channel 的问题；
        * 既然 channel 少，我给你增加 channel 不就好了，就是 1x1 升维咯；
        * 升完了，我再降回来，将回来之后， channel 就少了，那就换成 linear 咯；
        * 于是 倒残差结构 形成咯，再就是画道线的事，参考 resnet 而已；

     5. 一句话，又好又快

     6. 深入理解深度可分离卷积  [深度可分离卷积（Depthwise Separable Convolution）](https://blog.csdn.net/m0_37605642/article/details/134174749)

        * ### 标准卷积

          标准卷积，利用若干个多通道卷积核对输入的多通道图像进行处理，输出的feature map既提取了**通道特征**，又提取了**空间特征**。

        * ### 逐深度卷积（Depthwise Convolution）

          逐深度卷积（Depthwise convolution，DWConv）与标准卷积的区别在于，深度卷积的卷积核为单通道模式，需要对输入的每一个通道进行卷积，这样就会得到和输入特征图通道数一致的输出特征图。即有输入特征图通道数=卷积核个数=输出特征图个数。

        * ### 逐点卷积（Pointwise Convolution）

          1. 根据深度卷积可知，输入特征图通道数=卷积核个数=输出特征图个数，这样会导致输出的特征图个数过少（或者说输出特征图的通道数过少，可看成是输出特征图个数为1，通道数为3），从而可能影响信息的有效性。此时，就需要进行逐点卷积。
          2. 逐点卷积（Pointwise Convolution，PWConv）实质上是用1x1的卷积核进行升维。在GoogleNet中大量使用1x1的卷积核，那里主要是用来降维。1x1的卷积核主要作用是对特征图进行升维和降维。

        * ### 深度可分离卷积（Depthwise Separable Convolution）

          深度可分离卷积（Depthwise separable convolution, DSC）由深度卷积和逐点卷积组成，==深度卷积用于提取空间特征，逐点卷积用于提取通道特征。==深度可分离卷积在特征维度上分组卷积，对每个channel进行独立的深度卷积（depthwise convolution），并在输出前使用一个1x1卷积（pointwise convolution）将所有通道进行聚合。
          **depthwise ：在空间上进行卷积**

          **pointwise : 在深度上进行卷积**

          相比于传统的卷积神经网络，深度可分离卷积的显著优势在于：

          - **更少的参数**：可减少输入通道数量，从而有效地减少卷积层所需的参数。
          - **更快的速度**：运行速度比传统卷积快。
          - **更加易于移植**：计算量更小，更易于实现和部署在不同的平台上。
          - **更加精简**：能够精简计算模型，从而在较小的设备上实现高精度的运算。

          **网络的宽度，代表卷积层的维度，也就是channel，例如512，1024**。

          **网络的深度，代表卷积层的层数，也就是网络有多深，例如resnet34、resnet10**

     ## ==**训练一个完全dense的网络，然后在上面剪枝才是最好的方法，unet++如是说。**==

   * ### 比较ResNet 和 DenseNet

     首先谈这两个之间的区别和联系，DenseNet和ResNet都是基于分类任务提出来的网络模型架构，架构思想也基本一致，即从小模块堆积到层，再堆积层到网络。现如今的检测和分割模型都是基于分类的模型来做backbone预训练并提取特征，但是实际上我们可以注意到DenseNet作为比ResNet较新的网络，不仅是每个layer中模块的数量(每个layer中的module数量基本一致，这样适合抽出backbone每层的特征做多尺度)，还是module得设计(module特征重用性很高，更适合检测和分割网络)，实际上都是要比ResNet优越的。

     我认为之所以ResNet用的要比DenseNet多的一个原因是因为ResNet本身是一个较为成熟的网络，关于ResNet的各种变体多，这些变体大都能和ResNet很好的融合，并且预训练文件和代码很多，可以很快的上手。第二个原因是在真正使用中要具体情况具体分析，ResNet并不一定比别的网络模型效果差，效果就算差也不会差很多。第三个原因是有很多基于ResNet的其它任务论文，如检测，分割，想要公平的比较新提出来的模块和思想最好保持backbone不变的情况下比较。

   * # ==卷积神经网络的知识总结==

     * **卷积神经网络CNN（1）——图像卷积与反卷积（后卷积，转置卷积）**  [参考链接](https://blog.csdn.net/Fate_fjh/article/details/52882134?spm=1001.2014.3001.5502)

       1. 以前的图像卷积在进行操作时，需要进行180度的旋转，同时卷积核中心与需计算的图像像素对齐，输出结构为中心对齐像素的一个新的像素值。

       2. ***在信号处理上，反转180度称作卷积，直接滑动计算称作自相关，在大部分深度学习框架上都没有反转180度的操作。***

       3. full(卷积的扩张，增大了特征图的大小)，same(类似于3x3卷积，padding=1，stride = 1)，valid（在卷积中没有对应，5x5(原图),3x3(卷积核),3x3(实际得到的图形)） 三种不同的卷积方式

       4. Kernel convolution usually requires values from pixels outside of the image boundaries. There are a variety of methods for handling image edges.意思就是多出来的部分根据实际情况可以有不同的处理方法。（其实这里的full卷积就是后面要说的反卷积）

       5. 反卷积（后卷积，转置卷积） ————————这个可以理解为与 full 均为反卷积，只不过方式不同

          这里说另外一种反卷积做法，假设原图是3X3，首先使用上采样让图像变成7X7，可以看到图像多了很多空白的像素点。使用一个3X3的卷积核对图像进行滑动步长为1的valid卷积，得到一个5X5的图像，我们知道的是使用上采样扩大图片，使用反卷积填充图像内容，使得图像内容变得丰富，这也是CNN输出end to end结果的一种方法。
     
     * **卷积神经网络CNN（2）—— BN(Batch Normalization) 原理与使用过程详解**  [==参考链接==](https://blog.csdn.net/Fate_fjh/article/details/53375881?spm=1001.2014.3001.5502)
     
       ***在正向传播的时候，通过可学习的γ与β参数求出新的分布值***
     
       ***在反向传播的时候，通过链式求导方式，求出γ与β以及相关权值***
     
       假设通道数为1，batch为4，即大小为[4,1,3,3] (n,c,h,w)。特征图里的值，作为BN的输入，这里简化输出只有一个channel，也就是这一个4x3x3个数值通过BN计算并保存均值与方差，并通过当前均值与方差计算归一化的值，最后根据γ,β以及归一化得值计算BN层输出。假如输入是3个通道，就是在通道的维度上进行bn，所以会有3个γ,β参数。
     
     * **卷积神经网络CNN（3）—— FCN(Fully Convolutional Networks)要点解释**  [==参考链接==](https://blog.csdn.net/Fate_fjh/article/details/53446630?spm=1001.2014.3001.5502)
     
       ### **FCN的upsample**
     
       upsample意思为上采样，简单来说就是pooling的逆过程，所以pooling也就是下采样，采样后数据数量减少，upsample采样后数据数量增多。FCN作者在论文中讨论了3种upsample方法，最后选用的是反卷积的方法（FCN作者称其为后卷积）使图像实现end to end，可以理解upsample就是使大小比原图像小得多的特征图变大，使其大小为原图像大小。
       ![这里写图片描述](https://img-blog.csdn.net/20161203185800920)
     
       ![这里写图片描述](https://img-blog.csdn.net/20161205151212473)
     
       image是原图像，conv1,conv2..,conv5为卷积操作，pool1,pool2,..pool5为pool操作（pool就是使得图片变为原图的1/2），注意con6-7是最后的卷积层，最右边一列是upsample后的end to end结果。必须说明的是图中nx是指对应的特征图上采样n倍（即变大n倍），并不是指有n个特征图，如32x upsampled 中的32x是图像只变大32倍，不是有32个上采样图像，又如2x conv7是指conv7的特征图变大2倍。
     
       第一行对应FCN-32s，第二行对应FCN-16s，第三行对应FCN-8s。
     
       * ***卷积层的作用可以看作是pool的逆过程\***。
       * **FCN-8s均优于FCN-16s，FCN-32s**。
       * 超过FCN-8s之后，结果并不能继续优化。
     
       结合上述的FCN的全卷积与upsample，在upsample最后加上softmax，就可以对不同类别的大小概率进行估计，实现end to end，最后输出的图是一个概率估计，对应像素点的值越大，其像素为该类的结果也越大。FCN的核心贡献在于==提出使用卷积层通过学习让图片实现end to end分类==。事实上，FCN有一些短处，例如使用了较浅层的特征，因为fuse操作会加上较上层的pool特征值，导致高维特征不能很好得以使用，同时也因为使用较上层的pool特征值，导致FCN对图像大小变化有所要求，如果测试集的图像远大于或小于训练集的图像，FCN的效果就会变差。==但是，也由于FCN提出了一种新的语义分割的方法，才使得有后面韩国Hyeonwoo Noh的对称反卷积网络，剑桥的SegNet等优秀用于语义分割的CNN网络。==
     
     * **卷积神经网络CNN（4）—— SegNet**  [参考链接](https://blog.csdn.net/Fate_fjh/article/details/53467948?spm=1001.2014.3001.5502)
     
       参考：http://mi.eng.cam.ac.uk/projects/segnet/tutorial.html
     
       1. SegNet是Cambridge提出旨在解决自动驾驶或者智能机器人的图像语义分割深度网络，开放源码，基于caffe框架。SegNet基于FCN，修改VGG-16网络得到的语义分割网络，有两种SegNet，分别为正常版与贝叶斯版，同时SegNet作者根据网络的深度提供了一个basic版（浅网络）。
     
       2. 在传统的CNN网络中，ReLU通常在全连接之后，结合偏置bias用于计算权值的输出，但是，在SegNet作者的研究中发现，激活层越多越有利于图像语义分割。
     
       3. Bayesian SegNet 分类结果
     
       4. 在Bayesian SegNet中通过DropOut层实现多次采样，多次采样的样本值为最后输出，方差最为其不确定度，方差越大不确定度越大，如图6所示，mean为图像语义分割结果，var为不确定大小。所以在使用Bayesian SegNet预测时，需要多次向前传播采样才能够得到关于分类不确定度的灰度图，Bayesian SegNet预测如图7所示。
          ![这里写图片描述](https://img-blog.csdn.net/20161207184857832?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvRmF0ZV9mamg=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
     
          第一行为输入图像，第二行为ground truth，第三行为Bayesian SegNet语义分割输出，第四行为不确定灰度图。可以看到，
     
          1. 对于分类的边界位置，不确定性较大，即其置信度较低。
          2. 对于图像语义分割错误的地方，置信度也较低。
          3. 对于难以区分的类别，例如人与自行车，road与pavement，两者如果有相互重叠，不确定度会增加。
     
     * **卷积神经网络CNN（5）—— Dilated Convolution**  [参考链接](https://blog.csdn.net/Fate_fjh/article/details/53932602?spm=1001.2014.3001.5502)
     
       #### *前言：* 稀释卷积
     
       在CNN中，Convolution与Pooling可谓最佳搭档，密不可分，在LeNet作者提出基本的CNN框架的时候，普通计算机计算能力并不优秀，所以Pooling作为提取重要特征以及减少计算量的一个重要手段。但是，在图像计算能力发展迅速的时代，Dilated Convolution作者文中一开始就反问” Is it necessary?”。
     
       #### ***Dilated Convolution in 1D 与1维卷积的比较***
     
       ```
       1. Dilated Convolution长度大于一维卷积长度。
       2. Dilated Convolution卷积核感知(计算)区域变大  这可以减少卷积核的大小，从而减少权重数量
       3. Dilated Convolution计算结果总和 与 一维卷积计算结果总和相等;从上面两个例子可以知道，卷积结果的和都是9, 说明总的计算量是一样，只是Dilated Convolution计算分在了更多的区域，直观地看，Dilated Convolution将普通卷积的计算结果重新分布在更多的区域，但是总的结果不变。这一点也是Dilated Convolution局限性所在。
       ```
     
     * **卷积神经网络CNN（6）—— YOLOv2 参数详解**  [参考链接](https://blog.csdn.net/Fate_fjh/article/details/70598510?spm=1001.2014.3001.5502)
     
       #### 前言
     
       You Only Look Once (YOLO，你只需要看一次) 是一个基于GoogleNet的物体检测深度网络，Real-time(实时)与Efficient(有效)一定是YOLO最大的特点与优势。YOLO与其他物体检测的深度网络思路基本相同，学习物体分类以及BoundingBox位置与大小。
       #### YOLOv2参数详解
     
       
     
     * **卷积神经网络CNN（7）—— 限速交通标志分类** [参考链接](https://blog.csdn.net/Fate_fjh/article/details/74784634?spm=1001.2014.3001.5502)
     
       #### 前言：
     
       限速交通标志识别在ADAS或者自动驾驶领域中相对基础的范畴，因此限速交通标志识别的要求都是又快又准，同时使用相对简单的方法实现，本文将整个限速交通标志检测与分类的过程以及实现方法。不过实际场景中，会出现限速交通标志容易被阻挡，或是离当前车道很远无法检测出来等问题有待解决，而且都具有一定挑战性。
       
     * **卷积神经网络CNN（8）—— Pix2Pix Application -- Aerialmap Lane Line Detection (Pix2Pix应用：航拍图车道线检测)**  [参考链接](https://blog.csdn.net/Fate_fjh/article/details/77008064?spm=1001.2014.3001.5502)
     
       #### 前言
     
       GAN(Generative Adversarial Networks–https://arxiv.org/abs/1406.2661)自问世而来热度一直无法退减，生成网络G与判别网络D通过相互对抗（原作者比喻成欺骗）训练网络，最终得到可以生成以假乱真图片的生成网络G。具有半监督学习能力的生成网络引来了大量研究者，同时产生了很多相关变体。Pix2Pix是其中一个。
     
       ### 总结
     
       1.在大部分情况，pix2pix确实能够通过输入生成召回率与准确率的车道线，尤其是直线情况
       2.可以过滤树，车，大部分的非车道线的路面标识
       3.生成的车道线很有可能带有噪点，同时白线黄线分类有出错的情况。
     
     * 

3. #### 强化学习基础知识

   

4. #### 心电心音特征提取

   **(1) 心电特征提取方式：**

   * ==**1.函数说明**==：
     * (1) 心电去噪函数使用了离散小波，经过试验看到无论离散小波函数或是连续小波函数对于心电信号看不到差别，连续小波函数的平滑性更好，但是和原始信号的某些波形趋势对不上，故此处选用离散小波，同时连续小波要求数据的长度为2的(分解层数)的整数倍，较为麻烦，离散小波没有这个需求。
       (2) 一般来说分解层数需要视数据的长度而定，如果数据长度过短，应该使用较小的分解层数，因为此时过多的分解可能导致结果不稳定或者不可靠。  
       (3) 而若数据长度较长，可以使用更多层级的小波分解，这样可以更好地捕捉信号的细节特征。
       (4) 实验用的心电采样率为1k或8k，一般至少有5s的数据了，所以用的就是10层分解，小波基函数为**sym8**。
       (5) 具体的小波系数处理：将低频分量置为0以去除基线漂移，对部分高频分量进行阈值去噪，部分层不可以去除，因为会造成信号失真。
       ==小波去噪原理：==   
       * 小波分解（将信号分解为不同尺度和频率的小波系数，我的理解为输入采样率，例如200hz，接着分解的系数范围依次是 50-100hz，25-50hz，12.5-25hz，6.25-12.5hz，0-6.25hz，这是四层分解）
       * 阈值处理，有软阈值和硬阈值两种最为普遍简单的处理，当然还有双阈值函数等等各种变体，经过试验发现因为我们的心电信号或心音信号并不是太复杂，所以就用的默认的软阈值函数
         **硬阈值处理**的原理在于对小波系数进行截断处理。当小波系数的绝对值小于设定的阈值时，将其置为零；而当小波系数的绝对值大于阈值时，则保留该系数不变。这意味着只有较大的小波系数被保留，而较小的系数则被清除。
         **软阈值处理**的原理在于对小波系数进行缩放压缩。当小波系数的绝对值小于设定的阈值时，将其缩小到零；而当小波系数的绝对值大于阈值时，则通过减去绝对值来实现抑制。这种方法相比硬阈值更加温和，允许保留一些较小的系数但通过缩小来减少其影响。
         ![image-20231217152255033](../../../AppData/Roaming/Typora/typora-user-images/image-20231217152255033.png)
       * **小波重构：** 其实就是把去完噪的各层系数按照分解的逆过程进行。
     * 包络函数：这里使用了python的hilbert函数(希尔伯特变换)，由于需要提取振幅包络，且我们的目的是要找出心跳频率，所以可以尝试多做几次包络来去除多余的高频分量。
       **具体步骤：** for循环里面包括了 hilbert函数和 np.abs()函数。
     * FFT变换函数使用步骤：fft()函数，去绝对值并归一化并将长度减半(变换完是对称的图形)，去除0分量，频率对应值最大的点即为 list1 = np.array(range(0,int(N/2)))    freq1 = smaple_freq*list1/N,  freq1即为每个频率点对应的频率值，f_base = freq1[np.argmax(fft_amp1)]   最终返回的 f_base即为心跳频率。
     * 由f_base可以得到窗口值的大小为 NT_base = int((1/f_base)*sample_freq)

   * ==**2.第一种心电特征提取方式：**==  滤波，三次包络，fft变化，计算窗口，寻找当前窗口内的最大值(信号已经移除了基线漂移，所以不存在其他值会比R波大的情况)，最大值为R波，根据R波确定其余波形，从当前R波滑动窗口寻找下一个R波。
   * ==**3.第二种心电特征提取方式：**== NeuroKit2 是一个用于生物医学信号处理和心理生理学研究的 Python 工具包。它提供了一系列功能，用于处理生物医学信号数据、进行心率变异性分析、执行情绪识别等任务。在使用过程中仅用于心电各种波的提取

   **(2)心音特征提取函数**

   * ==1.函数说明==： 与心电特征提取类似，心音信号的特征也是需要依据心跳频率来确定窗口，进而在窗口内找到其他波点。但是判断心电时因为只有R波是最高的，所以我们找到了最高值就确定是R波，心音却不一样。S1与S2在不同人身上，甚至同一个人一天中的不同时间段，大小都存在着不一样的情况，且即使心音滤完波，对于质量较差的心音仍然存在好多噪点会影响S1，S2,S3的判断，所以最佳的做法就是对当前仪器采集的心音或者某几个仪器采集的心音，进行打补丁式的操作，尽量减小找错的概率
   * ==**2.第二次更改后的心音特征点提取**==  首先寻找窗口内最大值temp，判断是否是边界点，是的话就在下一个窗口内寻找最大值temp；以最大值开始为一个窗口，寻找最大值temp1，接着在temp和temp1之间寻找temp2。接着需要判断temp2是否是波峰点，此处用阈值加以判断，若不是的话，那就认为temp1是S1，在temp1的右边寻找S2；若是波峰点的话，就要判断temp2与temp和temp1的距离，和谁距离近，那他们就是一对S1, S2。
     接着去寻找S1，S2的左右边界，当前这里因为是刚开始的点，所有有可能寻找的不是很准确，大部分还是可以找到的。
     现在开始进入循环，利用找到的S1，S2去寻找下一个S1，S2，注意不要越界。寻找的核心思想是利用上一个S2去寻找下一个S1，接着利用新找到的S1去寻找与他配对的S2，这里要注意的是有可能我们找到的S1是真正的S2，而找到的S2是其余数值，所以需要判断，如果找到的S2很小，那就证明是找错了，S1需要重新寻找，接着利用真正的S2找S3，去寻找S1和S2的边界，结束。

   (3) 心电心音同步特征的提取：

   * ==**说明：**== 对于心电特征提取来说，不管是使用导入的包自动提取还是自己的方法提取，偶尔会存在一点误差，不过相对来说没有影响，但是对于心音特征提取，往往由于噪音过大，异常点过多而导致会存在些许误差，所以需要一个矫正的过程，这里的核心思想是利用同一个心拍心电和心音信号的特征点距离差距不大来判断。
   * ==**具体操作：**== 心电的特征点包括了 P Q R S T 五个波点，心音的特征点包括了 S1L, S1,S1R,S2L,S2,S2R,S3。
     因为使用导入的包寻找的心电特征点，其最后一个Q，S波是nan，所以需要将五个心电特征点的末尾都去除了。接着进行心电心音特征点的对其，举例来说就是查看当前心电R波点和心音S1节点的位置差，如果超过了半个窗口的大小，那一定是错误的了，进行心音或者心电所有特征点的删除，如果S1超过R波半个窗口，就删除心音，反之删除心电。
     经过上述过程后，可能会存在心电特征点个数和心音特征点个数不一致了，这个时候一定是心电或者心音的末尾多了，直接删除多的点即可。
     在得到干净的点之后，我们还需要甄别。
     经过大批量测试，发现出现nan的都是sp，而qp和rp没有出现，但这并不代表有更多的数据进行测试时不会出现nan,所以还是要对 P Q R T四个波点判断，如果存在nan，就删除所有特征定对应的位置，但不删除S3,因为S3和他们不是一一对应的。
     然后在计算qrs间期的时候，对S进行循环判断，出现nan就删除对应位置的Q和S波。
     **至此所有特征点的寻找及判断就结束了，而对应的特征如下所示。**
     ![image-20231217174045779](../../../AppData/Roaming/Typora/typora-user-images/image-20231217174045779.png)

   

5. #### 项目内容

   (1) 山西省研究生创新项目  负责人

   * ==项目背景：== 基于心血管疾病检查的复杂性与滞后性，先前两个心电心音项目的经验积累，对可穿戴设备的市场调研以及同各位老师的会讨论，设立了该课题并申报了山西省研究生教育创新项目。
            关于这个想法，起初只是我自己的一个小实验。课题组因为之前在前两个做调研时就看到了有压电陶瓷采集心音的论文及产品，之后我自己感觉很感兴趣，就去开始查各大网站是否有售卖的成品，显然没有。但是有将压电陶瓷片用于蜂鸣器，也就是将压电片作为输入而产生电势差进而产生的声音，那我想，我或许也可以把他当做输出段，既然他是压电的，那给他压力，他必然能够产生电势差，接着去查看了压电陶瓷片的谐振频率能达到多少以及对应的频率响应曲线，但是商家只给出了谐振频率，之后就买了，正好课题组也有测试心音信号的芯片，之前是用来测试咪头的，按理来说压电式传感器和电容式传感器原理不同，不可以使用同样的电路，但是我们的电路并没有说专门为咪头设计一个前端电路来首先处理信号，而是直接读取电压差值并放大到一定范围，且使用的芯片具有自动调整的功能，那这样来说就不需要考虑所谓的传感器设计原理了，因为抛开原理，他们最后得到的都是电势差，无非就是信号放大倍数和滤波的问题，所以也就开始了测试，结果也还可以，这个项目由此而来。

     ==chat gpt搜索给出的答案==
     咪头和压电片是两种不同的传感器，它们的工作原理和特性不同。因此，通常情况下不能使用同一个电路进行测试。咪头是一种声音传感器，用于接收声音信号并将其转换为电信号。它通常具有较高的灵敏度和宽频响特性，适用于声音的捕捉和分析。压电片是一种压力传感器，可以将压力信号转换为电信号。它通常具有较高的稳定性和可靠性，适用于测量压力、力量和振动等。虽然咪头和压电片都可以通过电路进行信号处理和放大，但由于它们的不同特性和工作原理，需要针对不同的传感器设计不同的电路进行测试和应用。
     ==总结就是：== 放大和滤波不同。但不影响我测到信号，只会影响信号的大小和质量而已。。。。

   * ==项目概述：== 穿戴式心电心音仪器及系统设计，主要任务是研制出一款可以长时间佩戴的心电心音监护设备，结合微信小程序采集到的信号传到云端服务器进行特征提取与分类，最终在小程序端可以看到各种特征及分类结果。
            具体来说，利用设计好的心电心音传感器加上魔术贴，并固定于人体心脏除，确保心电电极贴已经粘住；接着打开微信小程序，开始搜索蓝牙，等待连接，连接成功以后信号会实时显示在手机界面，传输完成以后点击支付即完成采集，稍后即可在小程序的结果界面看到各种特征提取及分类结果。

   * ==项目现状：== 目前该项目经过两代产品的迭代已经成功结题，后续仍需要进行完善的还有电路部分以及封装外壳的设计部分。
            具体来说：第一代产品使用了压电陶瓷，心电三导联线，第二代产品使用了压电复合材料以及心电重排布的方式，其中电路与小程序都进行了迭代升级。但是受限于小程序缓存及性能问题，目前无法做到超长时间的采集，这个有待于后续解决。另外电路部分心电信号的质量仍旧需要提高，心音部分的固定方式仍旧需要改善；最后就是封装外壳需要改进。

   * ==本人在项目中所承担的工作如下：==

     1. 硬件设备与微信小程序的需求分析、测试与程序更改；
     2. 后端管理平台与分类算法的设计，服务器程序部署及维护；
     3. 心音传感器及设备整体封装结构的设计，测试与更改。

   （2) 面向多模态心音心电信号的心脏健康智能诊断系统研究  主要成员

   * ==项目背景：== 该课题为老师的山西省重点研发计划所申请的项目。提出该课题的毕竟主要有：心血管疾病早期检查的重要性，当前检测仪器的繁琐性，复杂性，数字化程度低，人工依赖程度高，用户无法及时进行检测等各种问题。
   * ==项目概述：== 该课题主要任务是研制可医用，可家用的12导联心电与5路心音检测仪。要求具备较高的便携性，智能性，易操作，不易损坏等特性。
   * ==项目现状：== 目前正在准备结题所需要的各种资料，其中仪器及系统方面已经完成，医疗器械认证预计明年上半年即可获取，各类测试均已经通过并获得相关测试机构的高度认可。
   * ==本人在项目中所承担的工作如下：==
     1. 仪器的集成测试与封装，硬件设备运行过程中存在的问题与分析验证。
     2. 数据的采集、整理与分析，心电信号、心音信号及同步信号的特征提取、分析与验证。
     3. 软件调试，服务器交互逻辑的设计，算法模型的设计、训练、测试与部署。

   (3) ⾯向新冠病毒⾮侵⼊式⼼电⼼⾳检测系统  主要成员

   * ==项目背景：== 该课题也为老师的山西省重点研发计划所申请的项目。提出该课题的毕竟主要有：心血管疾病早期检查的重要性，新冠疫情背景下的无接触式检查，心血管疾病快速筛查的紧迫性等各种问题。
   * ==项目概述：== 该课题主要任务是研制可医用，可家用的便携式三导联心电与单独心音检测仪。要求具备较高的便携性，智能性，易操作，人体工学等特性。
   * ==项目现状：== 该课题于2022年12月份已经完成结题。其中仪器及系统方面已经完成，各类测试均已经通过并获得相关测试机构的高度认可。在2023年的一年中，我们又对该设备进行了升级，并将便携式设备和穿戴式设备一同纳入小程序，达到高度的统一化。
   * ==本人在项目中所承担的工作如下：==
     1. 仪器的集成测试与封装。
     2. 配套安卓APP，微信小程序的修改及调试，蓝牙传输问题的解决。
     3. 分类算法设计，整个系统交互逻辑的设计及运行维护。

6. #### 论文内容

   ## (1) Multiclassification for heart sound signals under Multiple networks and Multi-view feature

   * ==概述：==本人为一作；实验，论文写作与修改均自己独立完成；Measurement期刊，二区闭源，IF=5.6,2023-12-10接收。

   * ==论文核心思想介绍：== 基于Transformer结构中的Encoder以及Convnext网络，构建了多个心音分类特征网络并做了多组对比实验来验证模型的可靠性。具体来说：首先基于先前两篇文章的研究，我发现最大池化层对于心电心音信号具有很强的特征提取作用，因为从分类结果看，将部分线性层或卷积层替换为最大池化层后，分类效果明显提升几个百分点，且参数量与计算量均降低了不少。所以在这次的实验中，我对Convnext网络中原始的Block进行了魔改，将卷积后的两个线性层全部替换为了最大池化层，并直接对比了==魔改前(ConvNext1-1d)和魔改后(ConvNext2-1d)==的网络在分类效果，参数量，计算量上的差异，结果确实和想的一样，在三个数据集上的准确率有些许提升，且参数量小了3倍多，计算量小了5M。

     ![image-20231217200851765](../../../AppData/Roaming/Typora/typora-user-images/image-20231217200851765.png)

     ​     接着考虑到Convnext网络是在图像分类上表现效果好，我又基于心音信号提取了四类心音二维图，分别是语谱图，梅尔频谱图，二阶谱图以及心音图。使用迁移学习，将这些图像用于训练和测试。
     ​     做完了我觉得一维Convnext网络应该还有很大的进步空间，只是缺少一些东西，想到了学习过的Transformer结构同样是在图像分类领域具有很好的表现，但我只需要编码器进行特征的提取，不需要解码器进行生成，所以也就只使用了编码器。将其与Convnext的block进行不同方式的结合。如下图所示。
     <img src="../../../AppData/Roaming/Typora/typora-user-images/image-20231217200940729.png" alt="image-20231217200940729" style="zoom:67%;" />

        最终的对比结果显示Conv-Encoder1具有综合的最佳性能，在三个心音数据集上均达到了最佳
        在分布较为均衡，心音类别差异较大，数据量较小的情况下，融合了两个模型的网络的结果(Conv-fusion,使用了图像)甚至可以超过该网络(Conv-Encoder1，仅使用一维心音信号)0.6%。而当数据两变大，类别差异变小，数据分布不均衡时，Conv-Encoder1便展现出了绝佳的分类能力。

   * ==结论：==  当数据量较大时，使用一维心音信号即可，且Encoder+Block具有很高的分类性能。

   ## (2) A Pooling Convolution Model for Multi-classification of ECG and PCG Signals

   * ==概述：== 本人为一作；实验，论文写作与修改均自己独立完成；Computer Methods in Biomechanics and Biomedical Engineering期刊，四区闭源，IF=1.6, 2023-12-08接收。

   * ==论文核心思想介绍：== 在阅读文献的过程中，发现大部分用于心电心音分类的网络都具有较高的繁琐性，且他们仅在一两个数据集上做测试，那么有没有可能，有一种网络既在心电分类上具有较高的性能，也在心音分类上具有较高的性能，同时在心电心音同步数据集上依然具有较高的分类性能，也就是我可以尝试做一个普适性的网络，该网络不一定是说在某个数据集上有最高的性能，但是他在所有数据集上都有着很不错的性能，这应该对后续研究更有用。而在看了众多分类模型后，发现最近的模型都较多复杂，可能不太适合用于相对简单的一维信号，而能注意到残差网络并不是在众多数据集上的最优解，但是他却被很广泛的当做基模型使用，且多数模型均会与其进行效果对比。同时，在第一篇文章的尝试下，我就接着尝试对残差网络进行更多的魔改。
     最终魔改的思路如下图所示。
     ![image-20231217203354452](../../../AppData/Roaming/Typora/typora-user-images/image-20231217203354452.png)

     如上图所示，与原始残差网络最大的不同就是我们直接去除了残差连接，同时使用了池化+卷积+池化的块替代原来的Block块，主体仍然是Resnet-18网络。
     ![image-20231217203626923](../../../AppData/Roaming/Typora/typora-user-images/image-20231217203626923.png)

     结构清晰明了，简单，达到了我们所要的简单，那么结果如何？
            **数据集**：我们收集了非常多的数据集，其中10个较为完整的心电数据集，最终融合而成了一个大的数据集ECGF。因为有众多类数据量都过于少了，所以我们就对11种数量特别少的心电类别进行了融合，把他们归为一类。最终心电融合数据集有6个类别。

     ​      对于心音数据集同样如此，我们收集了四个数据集，将他们进行了融合，其中异常类别全部归为一类，正常类别全部归为一类，总共2个类别，名字叫PCGF

     ​     对于心电心音同步数据集，我们仅收集到了一个数据集，且该数据集采集自健康人，标签类别为不同人的状态。有的是休息，有的是运动。名字是Electro-phono-cardiogram，简称 EPHNOGRAM。 考虑到该数据集不是疾病类型的，我们无法将它与全文中的数据进行比较，故该数据集仅用于进一步验证模型是否具有较高的泛化性。

     ​       **结果**：在融合后的ECGF数据集上，MCM和REC构成的网络并没有太大差异，而当用于PCGF是，MCM就远远超过了REC，在EPHNOGRAM数据集上也是一样，MCM在多个类别及总的准确率上均超过了REC。证明了MCM对于数据分类的有效性。主要是其较简单。

   * ==结论：== 相对于当前规模的数据量，MCM构成的网络即使很简单，也具有很不多的性能，虽然在心电分类上并没有优势，但是在心音分类上却展现出了极大的性能，这一点在同步数据集上得到了进一步验证。

   ## (3) Improving ECG Classification Performance by Using an Optimized One-Dimensional Residual Network Model

   * ==概述：== 本人为二作，一作为本人的实际指导人，2022-12博士毕业；实验，论文写作与修改均自己独立完成；Applied Sciences-Basel.期刊，四区开源，IF=2.7, 2022-12-16见刊。

   * ==论文核心思想介绍：== 初识残差网络，图像分类，接触了课题组关于心电心音的项目，此时硕士师兄在写关于心音的文章，指导我的博士师兄开始告诉我做关于心电分类的方向，此时当然不知道心电分类方向已经被做烂了(经由博士毕业给其写论文才知道，其毕业论文需要有关于心电分类的，心音分类的，这样一来我和另外一个师兄做的工作刚好满足了它)。
     ==正式思想介绍：== 开始了解了心电，完整阅读了一篇关于心电散点图的书，开始学习深度学习，了解了各类网络分类模型，尤其是看到了残差网络的简单，故想着可以魔改残差网络来对心电数据集进行分类。于是经过多次试验，发现最大池化层具有很好的结果，又经过多次试验，最终确定了文章要使用的结构，期间尝试过复杂的结构，但是却没有突出的效果，最后尝试了下面三种块，如下图

     <img src="../../../AppData/Roaming/Typora/typora-user-images/image-20231217210802061.png" alt="image-20231217210802061" style="zoom:67%;" />

     同时搭建了几个网络用于对比，如下图：

     <img src="../../../AppData/Roaming/Typora/typora-user-images/image-20231217210905541.png" alt="image-20231217210905541" style="zoom:67%;" />

     分别为CNN,CNN+RE1,RsNet-18（RE2）,ORDN（RE3）

        **数据集：**4个经典的心电数据集，病例数比较少，但是分段以后还是比较多的，去除了一些数量很少的类别，最终使用的是下面这些。
     <img src="../../../AppData/Roaming/Typora/typora-user-images/image-20231217211335557.png" alt="image-20231217211335557" style="zoom:80%;" />

        **结果：** 如我们所想，只看到了一点点的提升，和原始残差网络相比其实没有太大的区别，只是训练时间有所减少，平均准确率较高一点。
     ![image-20231217212039697](../../../AppData/Roaming/Typora/typora-user-images/image-20231217212039697.png)

   * ==结论：== 池化层的能力还有待发掘，从这篇论文可以看出其对减少网络训练时间还是很有帮助的，且可能是本文设计的结构不太合理，才导致池化层没有发挥出应用的作用。（不过后续的另外一篇文章也确实证明了池化层在心电分类上和残差较为接近，所以其作用主要是减少训练时间，）

7. #### 竞赛内容

   研究生期间各类竞赛所采用的作品大部分来自于课题组的相关项目，得到各个老师的准许。其中互联网+金奖为耗时最长的比赛。

   本科期间的竞赛均为个人知识类的竞赛。

8. #### 其余小知识

   * 最小生成树的概念，特点     [参考链接](https://zhuanlan.zhihu.com/p/136387766)

     <img src="https://pic3.zhimg.com/80/v2-a89c87ebaf244377c48db2516df35096_720w.jpg" alt="img" style="zoom:67%;" />

     生成树概念以及它的特性？

     - 一个连通图可以有多个生成树；
     - 一个连通图的所有生成树都包含相同的顶点个数和边数；
     - 生成树当中不存在环；
     - 移除生成树中的任意一条边都会导致图的不连通， 生成树的边最少特性；
     - 在生成树中添加一条边会构成环。
     - 对于包含n个顶点的连通图，生成树包含n个顶点和n-1条边；
     - 对于包含n个顶点的无向完全图最多包含 nn−2 颗生成树。

     最小生成树算法有很多，其中最经典的就是==克鲁斯卡尔（Kruskal）算法==和 ==普里姆（Prim）算法==，也是我们考试、面试当中经常遇到的两个算法。最小生成树的性质：

     1. 定义在一棵树里添加一条边，并在产生的圈里删除一条边叫一次操作。（也就是说换掉一条边并且保存结果是树），则树A和B是无向图的两个生成树，则A可以通过若干次操作变成B。
        证明：把树看作边的集合，如果B中有一条A没有的边，则把这条边加到A上，A产生一个圈中至少有一条是B中没有的边，把这条删除，则A仍然是生成树，A，B集合相同的边多了一条，重复这个过程直到A B包含的边相同。
     2. 把一个连通无向图的生成树边按权值递增排序，称排好序的边权列表，则任意两棵最小生成树的有序边权列表是相同的。
     3. A,B是同一个无向连通图的两棵不同的最小生成树，则A可以通过若干次（1）中定义的换边操作，并且保证每次结果仍然是最小生成树，最终转换成B。
     4. 对于一个连通无向图的生成树，只考虑它的边权，形成的有序边权列表中，最小生成树是有序边权列表字典序最小的。（字典序就是通常的定义，两个序列A,B的字典序相同当且仅当A=B。否则，序列A,B出现最早位置的不相等的元素时，如果序列A的该位置元素更小，则序列A字典序小，反之，则序列1. B的字典序更小。如果直到一个序列结束都没有这样的位置，则较短的序列字典序小）。

   * 卷积神经网络，做完一个batchnorm之后的均值和方差是相对于==通道数==而言的。

   * 一个函数可导（differentiable）需要满足以下条件：

     1. 函数在该点存在：函数必须在某个点或某个区间内定义。
     2. 左右导数存在且相等：如果函数在某一点的导数存在，那么它的左导数和右导数也需要存在，并且它们相等。这是确保函数在该点处具有良好的连续性的条件。
     3. 极限存在：函数在该点处的导数需要存在极限。这表示函数在这个点附近的变化是可测量的，不会出现奇异或非法的情况。
     4. 连续性：函数在该点处必须是连续的，也就是说函数在该点的函数值和导数都是有限的。

     只有满足以上条件的函数才能被认为是可导的。这意味着函数在该点处有定义、连续、且可微。如果函数在某一点不满足上述条件，那么它在该点处不可导。

   * 强化学习概念
     
     强化学习是一种机器学习方法，主要用于解决智能体（agent）在与环境交互的过程中，如何通过试错学习来最大化累积奖励的问题。在强化学习中，智能体通过与环境交互来获取观测值（observation）、执行动作（action）和获取奖励（reward），并根据这些信息来学习如何在未来的交互中做出更好的决策。
     
     以下是强化学习中的一些基础概念：
     
     1. **智能体（agent）**：在强化学习中，智能体是指一个可以感知环境、执行动作并获得奖励的实体。智能体的目标是通过与环境的交互来最大化累积奖励。
     
     2. **环境（environment）**：环境是智能体所处的外部世界，包括智能体能够感知的状态和智能体能够执行的动作。环境的状态可能是可观测的或不可观测的，动作可能是离散的或连续的。
     
     3. **状态（state）**：状态是环境的一种表示，它描述了环境在某一时刻的特定情况。在强化学习中，智能体的决策通常基于当前状态。
     
     4. **动作（action）**：动作是智能体对状态做出的响应，它会影响环境的状态，并导致智能体获得奖励。
     
     5. **奖励（reward）**：奖励是智能体在执行某个动作后获得的信号，它用来评估动作的好坏。在强化学习中，智能体的目标是最大化累积奖励。
     
     6. **策略（policy）**：策略是智能体在某个状态下选择动作的规则。策略可以是确定性的或随机的，它决定了智能体在不同状态下采取不同动作的概率。
     
     7. **价值函数（value function）**：价值函数是用来评估状态或状态-动作对的好坏的函数。在强化学习中，价值函数通常被定义为累积奖励的期望值。
     
     8. **Q值函数（Q-value function）**：Q值函数是一种特殊的价值函数，它评估在某个状态下采取某个动作的好坏。Q值函数可以用来指导智能体在不同状态下选择哪个动作。
     
     9. **马尔可夫决策过程（Markov Decision Process，MDP）**：马尔可夫决策过程是强化学习中常用的模型，它描述了智能体与环境交互的过程。MDP包括状态空间、动作空间、状态转移概率、奖励函数等元素。
     
     这些基础概念是理解强化学习的关键，掌握它们可以帮助我们更好地理解强化学习算法的原理和应用。
     
   * 生成网络GAN

     1. 请解释一下什么是生成对抗网络（GAN）以及其工作原理。      
        回答：生成对抗网络（GAN）是由生成器和判别器组成的博弈模型。生成器从随机噪声中生成样本，并试图欺骗  判别器，使其无法准确判断样本的真实性。判别器作为对抗方试图辨别出生成器生成的样本与真实样本的区别。这两个网络通过反复博弈和迭代的过程相互竞争，最终生成器得到提升，能够生成更接近真实样本的结果。
     2. GAN 的损失函数是什么以及为什么使用这种损失函数？
        回答：GAN 一般使用的损失函数包括生成器损失函数和判别器损失函数。生成器损失函数通常使用对数似然损失或 Jensen-Shannon 散度，目标是使生成样本更接近真实样本。判别器损失函数通过最小化真实样本和生成样本之间的区分度，促使判别器准确判断样本的真实性。这种损失函数的选择可以推动网络中的博弈过程，使生成器和判别器能够逐渐提升。
        具体公式？
     3. GAN 的训练过程是怎样的？
        回答：GAN 的训练过程涉及两个关键步骤：生成器更新和判别器更新。在每个训练步骤中，先从真实数据中抽取一批样本，并从噪声中生成一批虚假样本。然后，分别用真实样本和生成样本作为输入，分别更新判别器和生成器的权重。生成器通过生成样本来骗过判别器，而判别器则试图识别真实和虚假样本。这个过程通过重复迭代进行，直到达到预定的迭代次数或其他终止条件。

   * ==矩阵，特征向量==

     ![image-20231228214914299](../../../AppData/Roaming/Typora/typora-user-images/image-20231228214914299.png)

     ![image-20231228214843841](../../../AppData/Roaming/Typora/typora-user-images/image-20231228214843841.png)

   * ==Leetcode刷题，保证自己的算法水平==

     目前还没有开动。。。。。

   * ==梯度下降算法及常用优化算法解释：==

     * 梯度下降算法是一种常用的优化算法，它在机器学习和深度学习中被广泛应用。通俗来讲，梯度下降算法是一种迭代算法，它的目的是最小化一个函数的值。

       具体来说，假设我们要最小化一个函数 $f(x)$，其中 $x$ 是函数的参数。我们可以通过梯度下降算法来寻找函数的最小值。梯度下降算法的基本思路是：从一个初始点 $x_0$ 开始，沿着函数的负梯度方向（即函数下降最快的方向）不断迭代，直到达到函数的最小值。

       具体来说，梯度下降算法的迭代公式如下：

       $$x_{n+1} = x_n - \eta \nabla f(x_n)$$

       其中，$x_n$ 是第 $n$ 次迭代的参数值，$\eta$ 是学习率（learning rate），$\nabla f(x_n)$ 是函数 $f(x)$ 在点 $x_n$ 处的梯度。

       学习率 $\eta$ 控制着每一步迭代的步长，它的取值通常需要手动调整。如果学习率过大，可能会导致迭代过程不稳定，甚至发散；如果学习率过小，可能会导致迭代过程收敛缓慢。

       梯度下降算法的优点是简单易懂，容易实现；缺点是可能会陷入局部最优解，而无法找到全局最优解。因此，在实际应用中，通常需要结合其他优化算法来解决这个问题。

       总之，梯度下降算法是一种常用的优化算法，它通过迭代的方式不断更新参数，从而达到最小化函数的目的。在机器学习和深度学习中，梯度下降算法被广泛应用于模型训练和参数优化。

     * **深度学习中常用的优化算法包括：**

       1. **梯度下降算法（Gradient Descent）**：梯度下降算法是一种基础的优化算法，它通过不断迭代，沿着函数梯度的相反方向更新参数，使得损失函数不断减小。梯度下降算法有三种变体：批量梯度下降、随机梯度下降和小批量梯度下降。

       2. **动量优化算法（Momentum）**：动量优化算法是基于梯度下降算法的一种优化方法，它在梯度下降的基础上增加了动量项，使得参数更新具有惯性，从而加速收敛。

       3. **自适应学习率算法（Adagrad、Adadelta、RMSprop、Adam等）**：自适应学习率算法是一类基于梯度下降算法的优化方法，它们通过自适应地调整学习率，使得参数更新更加稳定、快速。

       4. **L-BFGS算法（Limited-memory Broyden-Fletcher-Goldfarb-Shanno）**：L-BFGS算法是一种基于牛顿法的优化算法，它通过估计函数的海森矩阵来更新参数。相比于梯度下降算法，L-BFGS算法收敛更快，但计算量更大。
   
       具体来说，动量优化算法通过引入动量项，使得参数更新具有惯性，从而加速收敛。动量项可以看作是历史梯度的加权平均，它可以平滑梯度的变化，避免了梯度下降算法中的震荡现象。动量优化算法的更新公式如下：
   
       $$v_{t}=\gamma v_{t-1}+\eta \nabla_{\theta} J(\theta)$$
   
       $$\theta_{t+1}=\theta_{t}-v_{t}$$
   
       其中，$v_t$ 是历史梯度的加权平均，$\gamma$ 是动量系数，$\eta$ 是学习率，$\nabla_{\theta} J(\theta)$ 是损失函数 $J(\theta)$ 对参数 $\theta$ 的梯度。
   
       自适应学习率算法通过自适应地调整学习率，使得参数更新更加稳定、快速。Adagrad算法是一种自适应学习率算法，它通过累加梯度的平方和来调整学习率，使得梯度较大的参数的学习率较小，梯度较小的参数的学习率较大。Adadelta算法和RMSprop算法是Adagrad算法的改进版，它们通过引入衰减因子，使得学习率更加稳定。Adam算法是一种结合了动量优化算法和自适应学习率算法的优化算法，它在梯度下降的基础上引入了动量项和自适应学习率，从而更加稳定、快速地更新参数。
   
       L-BFGS算法是一种基于牛顿法的优化算法，它通过估计函数的海森矩阵来更新参数。相比于梯度下降算法，L-BFGS算法收敛更快，但计算量更大。
   
       总之，深度学习中常用的优化算法有梯度下降算法、动量优化算法、自适应学习率算法和L-BFGS算法等。不同的优化算法具有不同的优缺点，具体选择哪种算法需要根据具体的情况来决定。
   
   * ==傅里叶变换知识：==  傅里叶函数，傅里叶级数，傅里叶变换
   
     傅里叶函数、傅里叶级数和傅里叶变换都是数学中的重要概念，它们在信号处理、图像处理、物理学等领域有广泛的应用。
   
     1. **傅里叶函数**：傅里叶函数是一组正交函数，它们的周期是无限的。正弦函数和余弦函数是最常见的傅里叶函数。傅里叶函数的重要性在于，它们可以用来表示任何周期函数，也就是说，==任何周期函数都可以表示为傅里叶函数的线性组合。==
   
     2. **傅里叶级数**：傅里叶级数是一种将==周期函数表示为傅里叶函数的线性组合==的方法。傅里叶级数表示为：
   
     $$f(x)=\frac{a_0}{2}+\sum_{n=1}^{\infty}(a_n\cos(nx)+b_n\sin(nx))$$
   
     其中，$a_0$、$a_n$ 和 $b_n$ 是系数，可以通过函数 $f(x)$ 的傅里叶系数公式计算得到。傅里叶级数的意义在于，它将一个周期函数表示为一组正弦和余弦函数的线性组合，从而可以更好地理解周期函数的频域特性。
   
     3. **傅里叶变换**：傅里叶变换是一种将==非周期函数表示为傅里叶函数的线性组合==的方法。傅里叶变换表示为：
   
     $$F(\omega)=\int_{-\infty}^{\infty}f(t)e^{-i\omega t}dt$$
   
     其中，$f(t)$ 是输入信号，$F(\omega)$ 是输出信号，$\omega$ 是频率。傅里叶变换的意义在于，它将一个信号从时域（时间域）转换到频域，从而可以更好地理解信号的频域特性，比如频率成分、幅度、相位等。
   
     总之，傅里叶函数、傅里叶级数和傅里叶变换的主要作用是将一个周期函数或非周期函数表示为一组正弦和余弦函数的线性组合，从而更好地理解信号的频域特性。
   
   * ==随机过程：== 
   
     * 主要讲述内容：随机过程的基本概念，平稳过程，平稳时间序列的线性模型和预报，马尔科夫过程
   
     * ![image-20231228213949272](../../../AppData/Roaming/Typora/typora-user-images/image-20231228213949272.png)
   
     * 


     ==矩阵分析：== 
    
     * 主要讲述内容：线性空间和线性变换，内积空间，矩阵的标准形，矩阵函数及其应用，特征值的估计和广义逆矩阵，非负矩阵。
     * 
    
     ==信号处理，图像处理：== 
    
        ## 信号处理
    
     * 数学基础：包括微积分、线性代数、复数理论和概率统计。
     * 信号与系统：了解信号的分类、时域和频域分析、卷积等基本概念。
     * 傅里叶变换：理解傅里叶级数和傅里叶变换的原理，以及在信号处理中的应用。
     * 滤波器设计：熟悉滤波器的类型、设计方法和频率响应。
     * 采样和重构：了解采样定理、插值方法和数字信号的重构技术。
     * 信号处理算法：掌握常见的信号处理算法，如离散傅里叶变换（DFT）、快速傅里叶变换（FFT）等。
     * 数字信号处理硬件：对数字信号处理器（DSP）和其他相关硬件的基本原理和应用有一定了解
    
     ## 图像处理
    
     * 数学基础：包括线性代数、微积分、概率统计和离散数学。
     * 数字图像基础：了解数字图像的表示方法、颜色空间、像素操作和直方图均衡化等基本概念。
     * 滤波与增强：熟悉图像滤波技术、边缘检测、噪声去除和图像增强的方法。
     * 变换与特征提取：理解傅里叶变换、小波变换、特征点提取和特征描述符等技术。
     * 图像压缩：了解图像编码原理、JPEG、PNG 等常见格式的压缩算法以及无损压缩和有损压缩的区别。
     * 分割与识别：熟悉图像分割算法、目标检测、图像识别和分类的基本原理。
     * 机器学习与深度学习：对监督学习、非监督学习、卷积神经网络（CNN）等机器学习和深度学习技术有一定了解。


​     

~~~python
 ==心电波形：== 心电每个波点对应的发生位置，心电散点图对应的病症

 * **基础概念：**心电图记录了心脏肌肉的去极化和复极化过程。这些电学变化通过放置在四肢和胸壁上的电极被记录下来，并转录到图纸上，形成心电图（ECG）。心电图显示了心脏在每个心跳周期中的电学活动。

 ​     **具体来说，心电图中的不同波形和散点图可以帮助医生诊断以下疾病和问题：**

 * P波：P波代表心房去极化的过程，异常的P波可能提示房颤、房扑等==心律失常==问题。
 * QRS波：QRS波代表心室去极化的过程，异常的QRS波可能提示==心室肥大、心室内传导阻滞==等问题。
 * T波：T波代表==心室复极化==的过程，异常的T波可能提示==心室肌肉缺血、心肌梗死==等问题。

    **心电散点图**

 * 正常窦性心律：位于45度线中段，呈棒球拍形的一分布稳态吸子图形；
 * 窦性心律伴室上性早搏(包括联律性早搏)：多数窦性心律伴室上性早搏的图形呈三分步，少数呈现四分步
 * 持续性房颤：45度附仅的一个三角形

 ==python基础知识：==  自己常用的包以及作用，字典的增删改查,为何字符串要加R(保证什么？转译？)

 * python中常用的包：os, random, shutil, gc, torch, pywt, wfdb, soundfile, numpy, pandas, math, scipy.signal
      **os系列**

   * Get the current working directory: `os.getcwd()`
   * List files in a directory: `os.listdir(path)`
   * Create a new directory: `os.mkdir(path)`
   * Remove a file: `os.remove(path)`

      **random系列**

   * Generate a random integer within a range: `random.randint(start, end)`
   * Choose a random element from a sequence: `random.choice(sequence)`,`random.choices(sequence,k = 2)`
   * Shuffle a list in place: `random.shuffle(list)`,无返回值，但已经对该list乱序排完了。

      shutil系列，对文件和文件集合提供了多个高级操作

   * Copy files or directories: `shutil.copy(src, dest)` 复制文件
   * Move files or directories: `shutil.move(src, dest)` 移动文件
   * Remove an entire directory tree: `shutil.rmtree(path)`  删除改路径下的所有文件

      **gc包**

   * However, you can manually trigger garbage collection using `gc.collect().`

      **torch包**

   * Creating a tensor: `torch.tensor(data)`
   * Performing matrix multiplication: `torch.mm(tensor1, tensor2)`
   * Training a neural network model using PyTorch's APIs

      **pywt包**  PyWavelets 

   * 它提供了一系列功能强大的小波变换工具，可以用于信号处理、图像处理和数据压缩等领域. 多种小波滤波器；一维，二维以及多维离散小波变换，连续小波变换。PyWavelets还支持超过100种内置小波滤波器，并且可以使用自定义小波滤波器。

   * ```python
     import numpy as np
     # 创建一个示例输入信号
     data = np.array([1, 2, 3, 4, 5, 6, 7, 8])
     # 执行一维离散小波变换
     cA, cD = pywt.dwt(data, 'haar')
     
     import numpy as np
     # 创建一个示例二维输入数据
     data = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12], [13, 14, 15, 16]])
     # 执行二维离散小波变换
     cA, (cH, cV, cD) = pywt.dwt2(data, 'haar')
     ```

   * DWT通常要求输入信号的长度是2的幂次方。这种要求是为了确保变换的有效性和可逆性。如果你的数据长度不是2的幂次方，你可以使用信号扩展的方法来处理超出信号边界的样本。常见的做法是对称扩展，这样可以保证变换的可逆性而不会添加任何不必要的系数。另外，如果你使用了lifting scheme（提升方案），对于Haar小波来说，处理起来会更加简单。

   * `pywt.cwt` 函数是 PyWavelets 库中用于执行单层连续小波变换的函数。它的参数包括输入信号 `data`、要使用的小波 `wavelet`，以及可选的 `sampling_period` 参数。这个函数返回连续小波变换的系数 `coefs`，以及频率 `frequencies`。

   **wfdb包**

   * WFDB是波形数据库软件包（Waveform Database Software Package）的缩写，是一个用于读取、写入和处理生理信号和注释的Python库。这些生理信号包括心电图（ECG）、脑电图（EEG）、肌电图（EMG）等。这些信号包含了可以用来了解健康状况的信息。WFDB软件包旨在提供一系列工具，以便用户能够有效地存储、处理和分析这些生理信号。

   * ```python
     record = wfdb.rdrecord(root+i)  # 读取一条心电记录
     annotation = wfdb.rdann(root+i, 'atr') # 读取该记录的注释文件
     ```

      **soundfile包**

   * 它提供了读取和写入音频文件的功能。soundfile 可以读取和写入许多不同采样音频文件格式，例如 WAV、FLAC、OGG 和 MAT 文件。要使用 soundfile 包，你需要安装 Python 包 CFFI 和 NumPy，以及系统库 libsndfile。使用 soundfile 包，你可以使用 `soundfile.write()` 将数据写入文件，或使用 `soundfile.read()` 从文件中读取数据。

   * ```python
     audio_data, fs = sf.read(path_data) # 返回的是数据以及采样频率
     ```

      **numpy包**

   * NumPy的核心数据结构是多维数组对象，也称为`ndarray`
     ```python
     # 从Python列表创建一维数组
     arr1 = np.array([1, 2, 3, 4, 5])
     # 从嵌套列表创建二维数组
     arr2 = np.array([[1, 2, 3], [4, 5, 6]])
     # 生成随机数组
     rand_arr = np.random.rand(3, 3)  # 创建一个3x3的随机数组
     # 改变数组形状的操作
     numpy.reshape：改变数组形状。
     numpy.ravel：返回一个扁平化的数组。
     numpy.ndarray.flat：返回数组的一维迭代器。
        numpy.ndarray.flatten：返回数组的一维拷贝。
     # 转置操作：
        numpy.moveaxis：移动数组的轴到新的位置。
     numpy.rollaxis：将指定的轴向后滚动，直到它位于给定位置。
        numpy.swapaxes：交换数组的两个轴。
     ndarray.T：数组的转置视图。
        numpy.transpose：返回数组的轴转置。
     # 连接数组：
        numpy.concatenate：沿现有轴连接一系列数组。
     numpy.stack：沿新轴连接一系列数组。
        numpy.block：从嵌套块的列表中组装一个nd-array。
     numpy.vstack：沿垂直方向（行）堆叠数组。
        numpy.hstack：沿水平方向（列）堆叠数组。
     numpy.dstack：沿深度方向（沿第三轴）堆叠数组。
        # 分割数组：
        numpy.split：将数组沿特定轴分割为多个子数组。
        numpy.array_split：将数组沿特定轴分割为多个子数组。
        numpy.dsplit：沿第三轴（深度）分割数组为多个子数组。
        numpy.hsplit：沿水平方向（列）分割数组为多个子数组。
        numpy.vsplit：沿垂直方向（行）分割数组为多个子数组。
        # 数组重复：
        numpy.tile：通过重复A的次数构造一个数组。
        numpy.repeat：重复数组的每个元素。
        # 添加和删除元素：
        numpy.delete：删除数组中的子数组。
        numpy.insert：在给定索引之前沿指定轴插入值。
        numpy.append：将值附加到数组的末尾。
        numpy.resize：返回具有指定形状的新数组		
     ```
~~~


​         
​          **pandas包**
​         
​          * 创建数组：使用`pandas.array`函数创建数组。
​          * 访问元素：使用`[]`操作符或`.iloc`和`.loc`属性来访问数组中的元素。
​          * 修改元素：可以使用`.at`和`.iat`属性来修改数组中的元素。
​          * 数据类型转换：使用`.astype`方法将数组中的数据类型进行转换。
​          * 数据统计：可以使用`.sum()`、`.mean()`、`.max()`、`.min()`等方法对数组进行统计计算。
​          * 数据筛选：使用布尔索引、`.isin()`、`.query()`等方法对数组进行筛选。
​          * 数据排序：使用`.sort_values()`和`.sort_index()`方法对数组进行排序操作。
​          * 数据填充：使用`.fillna()`方法对数组中的缺失值进行填充。
​          * 数据拼接：使用`.concat()`、`.append()`等方法对数组进行拼接操作。
​          * 数据分组：使用`.groupby()`方法对数组进行分组操作。
​         
​          **math包**
​         
​          * Python中的`math`模块是一个内置的数学函数库，提供了许多用于数学计算的函数。这些函数包括对数字进行取整、幂运算、三角函数、绝对值、阶乘、最大公约数、最小公倍数等操作。下面我将详细介绍`math`模块中的一些常用函数。
​         
​          * ```python
​            首先，math模块中的ceil(x)函数返回大于或等于x的最小整数，即向上取整。floor(x)函数返回小于或等于x的最大整数，即向下取整。fabs(x)函数返回x的绝对值。
​            其次，math模块中的factorial(n)函数返回n的阶乘。fmod(x, y)函数返回x除以y的余数，与Python中的%操作符不同，fmod(x, y)的结果的符号与x相同。
​            此外，math模块还包括了三角函数，如sin(x)、cos(x)、tan(x)等，以及反三角函数，如asin(x)、acos(x)、atan(x)等。
​            math模块还提供了一些常用的数学常数，如π和自然对数的底e，可以通过math.pi和math.e来访问。
​            最后，math模块中还包括了一些其他函数，如gcd()用于计算最大公约数，isfinite()用于判断一个数是否为有限数，isnan()用于判断一个数是否为NaN（非数），等等。
​            ```
​         
​          **scipy.signal包**
​         
​          * 我目前主要使用这个包来进行一些fft变换，重采样，降采样，滤波等操作。


​          
​         

     ==函数中的问题：== 形参，实参有何区别，传参数的问题
    
     * ![image-20231228092612863](../../../AppData/Roaming/Typora/typora-user-images/image-20231228092612863.png)
     * 在Python中，函数的参数传递方式分为传值（pass by value）和传引用（pass by reference）两种情况。
       对于不可变对象（如数字、字符串、元组等），函数的参数传递方式是传值。这意味着在函数内部对参数进行操作，不会影响到原始变量的值。
       对于可变对象（如列表、字典等），函数的参数传递方式是传引用。这意味着在函数内部对参数进行操作，会影响到原始变量的值。因此，当你传递一个数组（可变对象）给函数，并在函数内部对该数组进行操作时，数组的值会随之改变。但是，当你传递一个不可变对象（如数字）给函数时，函数内部对该对象的操作不会影响到原始变量的值。
    
     ==python中对字典的操作：==  
    
     * ```python
       # 创建一个字典
       my_dict = {'key1': 'value1', 'key2': 'value2', 'key3': 'value3'}
       # 使用 dict() 函数创建字典
       another_dict = dict(key1='value1', key2='value2', key3='value3')
       # 访问字典中的值
       value1 = my_dict['key1']
       value2 = my_dict.get('key2')
       # 添加键值对
       my_dict['key4'] = 'value4'
       # 更新键值对
       my_dict['key2'] = 'new value2'
       # 删除键值对
       del my_dict['key3']
       my_dict = {'key1': 'value1', 'key2': 'value2'}
       # 获取所有键
       keys = my_dict.keys()
       # 获取所有值
       values = my_dict.values()
       # 获取所有键值对
       items = my_dict.items()
       my_dict = {'key1': 'value1', 'key2': 'value2'}
       # 遍历键
       for key in my_dict:
           print(key)
       # 遍历值
       for value in my_dict.values():
           print(value)
       # 遍历键值对
       for key, value in my_dict.items():
           print(key, value)
       
       ```
    
     * 

* BatchNorm 和 LayerNorm的区别

  BatchNorm作用在特征维度，对一个批量的数据的同一通道计算均值和方差，适用于不用数据之间的联系
  LayerNorm作用在Batch维度，对一个数据的所有通道计算均值和方差，适用于词向量之间的联系

  [参考链接](https://www.zhihu.com/question/487766088/answer/3094052709)

  首先，最根本的不同即BatchNorm和LaverNorm的作用对象不同——BatchNorm认为相同维的特征具有相同分布，因此在特征维度上开展归一化操作，归一化的结果保持样本之间的可比较性。而LayerNorm认为每个样本内的特征具有相同分布，因此针对每一个样本进行归一化处理，保持相同样本内部不同对象的可比较性。由于上述根本差异的存在，引出了一系列使用方法的不同BatchNorm在批次中执行跨样本的归一化操作，这就意味着批次的构成和规模会直接影响BatchNorm的效果。BatchNorm需要平衡小批次统计量和整体样本统计量之间的关系，还需要考虑利用批次统计量更新全局统计量的方法，这也涉及训练和测试阶段使用的统计量有“批次版”和“全局版”的问题...等等。而这些问题到了LayerNorm就都不再是问题——LayerNorm的归一化操作只在样本内部独立开展，因此实际可以完全忽略批次的存在。因此也不用考虑保存和更新的问题且训练和测试应用模式完全一致，均值和标准差随算随用。

  

* 1x1卷积层的作用
  增加或减小通道数，特征融合和特征选择等

* 强化学习中的价值梯度
  ```python
  在强化学习中，价值梯度（Value Gradient）是指相对于价值函数的梯度。它在许多强化学习算法中起着重要的作用，特别是在基于值函数的方法中，如值迭代、策略迭代和深度强化学习中。
  在强化学习中，价值函数用于评估状态或状态动作对的价值，表示在当前策略下，从给定状态或状态动作对开始，预期未来的累积奖励。通过优化价值函数，智能体可以学习选择最优的动作来最大化累积奖励。
  价值梯度是指相对于价值函数的梯度，它指导了价值函数的更新方向。通过计算价值梯度，可以更新价值函数的参数，使其逼近真实的价值函数。通常，这涉及使用梯度下降或其他优化算法来最小化预测值和实际值之间的差异。
  具体来说，在值函数迭代算法中，如Q-learning和深度Q网络（DQN），价值梯度用于更新值函数的参数。在策略梯度算法中，如REINFORCE和Proximal Policy Optimization（PPO），价值梯度用于计算策略的更新方向，以改进策略的性能。
  总结起来，价值梯度是指相对于价值函数的梯度，在强化学习中用于指导价值函数的更新或策略的改进。它是强化学习算法中重要的概念之一，用于优化智能体的决策策略。
  ```
  
* RNN了解
  LSTM，


9. ### 英语的学习

   

10. ## 工作

    * 公积金计算公式：

      最低工资（当地去年平均工资） * 比例（10%）
      实际工资 * 最低比例或某一比例（10%）

      无论何种情况，比例共为20%，公司交的比例多，我就交的少。
      公积金有贷款上限，超过的部分要自己负担。

    * 社保计算

      公司出大头（75%），自己交25%。一般比例。  
      五险，六险，七险。

    * 二金（企业年金），有的国企也有，有的私企也有。

    * 私企吃住问题，公司有没有等等，管的话管几年。

    * 户口问题，有户口的话公司大概率工资会压的低一点。

    * 实习期多长时间，转正等等。

    * 培训制度，就业前景，晋升空间。

    * 工资调薪的次数，考核方式，调薪幅度。

    ——————————————————————————————————————————————

    * 联影，20-22k，14.5薪-15薪，实习期工资和正式期一样。按照现在水平来看，能给到29w到33w。工作地点：上海嘉定区。每年年终(中)进行考核，提供调薪机会。
    * 

11. ![image-20240106172132478](../../../AppData/Roaming/Typora/typora-user-images/image-20240106172132478.png)

