1. 在测试心电心音同步数据时，注意标签和数据修改时，一定要对应到文件夹的名字，而不是序号，否则就会出现删除或者添加错误的情况。  
   ```python
   filenames = os.listdir(root_path)  #文件名字
   filenames.sort(key=lambda x: int(x))
   error2 = []
   for i in range(len(outputs)):
       if outputs[i] != targets[i] and int(targets[i]) == 2:
           error2.append([filenames[i],outputs[i],targets[i]]) # append的是文件夹名字，输出以及真实值
           np.array(error2).shape
           from copy import deepcopy
           randlst = np.array(error2)[:,0]
           test_path = r"E:\data_ecg_pcg\test0\test.csv"
           datas = pd.read_csv(test_path)
           DF = deepcopy(datas)
           for i in randlst:
               DF = DF.drop(index = datas.loc[datas["序列"] == int(i)].index)
               save_path = r"E:\data_ecg_pcg\test0\test1.csv"
               DF.to_csv(save_path,index = None,encoding = "utf_8_sig")
   ```

2. 重采样和降采样

   ```python
   import scipy.signal as signal
   re_pcg = signal.resample_poly(pcg_signal,1000,8000) # 降采样
   
   from scipy.signal import resample
   a = resample(a, 2000, axis=0) # 重采样，原长度默认为就是最原始的采样率
   ```

3. 使用for循环并加入匿名函数
   ```python
   # 匿名函数中使用 for 循环
   result = (lambda x: [i * x for i in range(10)])(5)
   print(result)  # 输出结果为 [0, 5, 10, 15, 20, 25, 30, 35, 40, 45]
   ```

4. 下载的镜像源添加
   ```python
   # 查看当前下载源
   conda config --show-sources
   # 添加下载源
   # 清华镜像源
   conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/
   conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/
   # 中科大镜像源
   conda config --add channels https://mirrors.ustc.edu.cn/anaconda/pkgs/main/
   conda config --add channels https://mirrors.ustc.edu.cn/anaconda/pkgs/free/
   conda config --add channels https://mirrors.ustc.edu.cn/anaconda/cloud/conda-forge/
   conda config --add channels https://mirrors.ustc.edu.cn/anaconda/cloud/msys2/
   conda config --add channels https://mirrors.ustc.edu.cn/anaconda/cloud/bioconda/
   conda config --add channels https://mirrors.ustc.edu.cn/anaconda/cloud/menpo/
   # 添加下载源后，设置搜索时显示通道地址
   conda config --set show_channel_urls yes
   # 删除下载源
   conda config --remove channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/
   # 换回默认源
   conda config --remove-key channels
   ```

5. python读取mp3并转换为wav文件
   ```python
   # 自己实际改动的代码
   def readMp3_convert_wav(read_mp3, save_wav):
       """
       读取MP3文件，并将MP3文件转换为wav文件并进行保存
       """
       sound = AudioSegment.from_mp3(read_mp3)
       left = sound.split_to_mono()[0]
       bit_depth = left.sample_width * 8
       array_type = get_array_type(bit_depth)
       left_numeric_array = array.array(array_type, left._data)
       # left_channel即为转换出来的数据，可以直接进行绘图
       left_channel = np.array(left_numeric_array) / 32768
       wave_data = np.vstack([left_channel])
       sf.write(save_wav,  wave_data.T, 44100)
       return left_channel
   
   # # 测试代码
   # read_mp3 =  r'F:/pytorch_data/hs_data/Michigan_four/Normal/mp3/01.mp3'
   # save_wav =  r'F:/pytorch_data/hs_data/Michigan_four/Normal/01.wav'
   # data = readMp3(read_mp3, save_wav)
   
   
   
   #作者源代码 暂时没有弄清楚为啥是双通道(left和right)，以及目前不懂代码转换的原理
   import array
   import numpy as np
   import soundfile as sf
   from pydub import AudioSegment
   from pydub.utils import get_array_type
    
   def readMp3(filename):
       sound = AudioSegment.from_mp3(filename)
       left = sound.split_to_mono()[0]
       right = sound.split_to_mono()[1]
    
       bit_depth = left.sample_width * 8
       array_type = get_array_type(bit_depth)
       left_numeric_array = array.array(array_type, left._data)
       right_numeric_array = array.array(array_type, right._data)
       left_channel = np.array(left_numeric_array) / 32768
       right_channel = np.array(right_numeric_array) / 32768
       wave_data = np.vstack([left_channel, right_channel])
       sf.write('Test.wav',  wave_data.T, 44100)
       return left_channel, right_channel
    
   test_path =  'F:\\Test.mp3'
   data = readMp3(test_path)
   ```

6. 统计代码量
   ```python
   from json import load
   from sys import argv
   
   def loc(nb):
       with open(nb, encoding='utf-8') as data_file:
           cells = load(data_file)['cells']
           return sum(len(c['source']) for c in cells if c['cell_type'] == 'code')
   
   def run(ipynb_files):
       return sum(loc(nb) for nb in ipynb_files)
   
   if __name__ == '__main__':
   #     print(r"This file can count the code lines number in .ipynb files.")
   #     print(r"usage:python countIpynbLine.py xxx.ipynb")
   #     print(r"example:python countIpynbLine.py .\\test_folder\\test.ipynb")
   #     print(r"it can also count multiple code.ipynb lines.")
   #     print(r"usage:python countIpynbLine.py code_1.ipynb code_2.ipynb")
   #     print(r"start to count line number")
       print(run(["data_processing2.ipynb"]))
   #     print(run(["data_edit.ipynb"]))
   #     print(run(["test_other.ipynb"]))
   #     print(run(["train_val_test1.ipynb"]))
   #     print(run(["train_val_test2.ipynb"]))
   #     print(run(["train_val_test3.ipynb"]))
   #     print(run(["train_val_test4.ipynb"]))
   #     print(run(["train_val_test5.ipynb"]))
   #     print(run(["train_val_test6.ipynb"]))
   #     print(run(["train_val_test7.ipynb"]))
   ```

7. 对其信号的代码
   ```python
   # 在Python中，可以使用fastdtw库来实现将两个波形进行对齐的操作。fastdtw库提供了一个函数fastdtw，它可以通过动态时间规整（DTW）算法来对两个序列进行对齐，返回对齐后的序列以及它们之间的距离。fastdtw库的优势在于其实现了一种优化的快速DTW算法，能够有效地加速计算过程。
   
   # 下面是一个简单的例子:
   from scipy.spatial.distance import euclidean
   from fastdtw import fastdtw
   import numpy as np
   
   # 两个时间序列
   s1 = np.array([1, 2, 3, 4, 5])
   s2 = np.array([2, 3, 4, 5, 6])
   
   # 使用fastdtw函数对波形进行对齐
   aligned_s1, aligned_s2 = fastdtw(s1, s2, dist=euclidean)
   
   print(aligned_s1)
   print(aligned_s2)
   
   # Python的Scipy库中提供了一个名为scipy.spatial.distance.cdist的函数，可以用来计算两个时间序列之间的DTW距离。具体可以通过metric='dtw'来指定计算DTW距离。
   from scipy.spatial.distance import cdist
   import numpy as np
   
   # 两个时间序列
   s1 = np.array([1, 2, 3, 4, 5])
   s2 = np.array([2, 3, 4, 5, 6])
   
   # 计算DTW距离
   distance = cdist(s1.reshape(-1, 1), s2.reshape(-1, 1), metric='dtw')
   print(distance)
   ```

8. python使用tqdm进度条
   ```python
   from tqdm import tqdm
   import time
   
   # 使用tqdm进行循环迭代时的示例
   for i in tqdm(range(100)):
       time.sleep(0.1)  # 模拟耗时操作
   ```

9. ```python
   设置使用两张显卡跑深度学习
   import torch
   import torch.nn as nn
   from torch.utils.data import DataLoader
   from torchvision import datasets, transforms
   import os
   os.environ["CUDA_VISIBLE_DEVICES"] = "0,1"  # 这样，PyTorch 将只识别 GPU 0 和 1。
   # 假设model是您的模型实例
   model = YourModel()
   if torch.cuda.device_count() > 1:
       model = nn.DataParallel(model)
   model.to('cuda')
   # 加载数据
   transform = transforms.Compose([transforms.ToTensor(),
                                 transforms.Normalize((0.5,), (0.5,))])
   train_set = datasets.MNIST('./data', train=True, download=True, transform=transform)
   train_loader = DataLoader(train_set, batch_size=64, shuffle=True)
   # 训练模型
   criterion = nn.CrossEntropyLoss()
   optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)
   for epoch in range(10):  # 多次循环遍历数据集
       running_loss = 0.0
       for i, data in enumerate(train_loader, 0):
           inputs, labels = data[0].to('cuda'), data[1].to('cuda')
           optimizer.zero_grad()
           outputs = model(inputs)
           loss = criterion(outputs, labels)
           loss.backward()
           optimizer.step()
           running_loss += loss.item()
       print(f'Epoch {epoch + 1}, Loss: {running_loss / len(train_loader)}')
      
   ```

   [参考链接](https://mp.weixin.qq.com/s?__biz=MzU0NjgzMDIxMQ==&mid=2247620657&idx=1&sn=69330189c9ec774ec15dfdbecb7b6ca5&chksm=fa45255ef880177b1876d7713fe6e3a080017bb032966d7ee39c9fbfdaf51aa1f400ad68cfac&scene=27)

   [参考链接2](https://mp.weixin.qq.com/s?__biz=MzU1NjEwMTY0Mw==&mid=2247595023&idx=1&sn=e4e666646464d39097f293f324cf2f0d&chksm=fbc90d6bccbe847da77702408df755b60782e8ac1fa0e4d2902fd063133a56460c6507b110f6&scene=27)

   ```python
   import torch
   import torch.nn as nn
   import torch.optim as optim
   import torchvision
   import torchvision.transforms as transforms
   import torch.nn.functional as F
   
   # 定义简单的卷积神经网络
   class SimpleCNN(nn.Module):
       def __init__(self):
           super(SimpleCNN, self).__init__()
           self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)
           self.pool = nn.MaxPool2d(kernel_size=2, stride=2)
           self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
           self.fc1 = nn.Linear(64 * 8 * 8, 128)
           self.fc2 = nn.Linear(128, 10)
   
       def forward(self, x):
           x = self.pool(F.relu(self.conv1(x)))
           x = self.pool(F.relu(self.conv2(x)))
           x = x.view(-1, 64 * 8 * 8)
           x = F.relu(self.fc1(x))
           x = self.fc2(x)
           return x
   
   # 数据预处理
   transform = transforms.Compose([
       transforms.ToTensor(),
       transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
   ])
   
   # 加载 CIFAR-10 数据集
   trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
   trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)
   
   # 初始化模型和指定的设备
   device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
   
   # 检查是否有多个GPU可用
   if torch.cuda.device_count() > 1:
       print(f"Using {torch.cuda.device_count()} GPUs")
       model = SimpleCNN().to(device)
       model = nn.DataParallel(model, device_ids=[0, 1])  # 使用GPU 0 和 GPU 1
   else:
       print("Using single GPU")
       model = SimpleCNN().to(device)
   
   # 定义损失函数和优化器
   criterion = nn.CrossEntropyLoss()
   optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)
   
   # 训练模型
   num_epochs = 10
   for epoch in range(num_epochs):
       running_loss = 0.0
       for i, data in enumerate(trainloader, 0):
           inputs, labels = data
           inputs, labels = inputs.to(device), labels.to(device)
   
           # 前向传播
           optimizer.zero_grad()
           outputs = model(inputs)
           loss = criterion(outputs, labels)
           
           # 反向传播和优化
           loss.backward()
           optimizer.step()
   
           running_loss += loss.item()
           if i % 100 == 99:  # 每 100 个小批量输出一次
               print(f"[{epoch + 1}, {i + 1}] loss: {running_loss / 100:.3f}")
               running_loss = 0.0
   
   print("Finished Training")
   
   # 保存模型
   torch.save(model.state_dict(), 'model.pth')
   
   ```

   

10. 



